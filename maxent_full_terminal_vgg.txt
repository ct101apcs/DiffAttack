
******Attack based on Diffusion, Attacked Dataset: imagenet_compatible*********
Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]Loading pipeline components...:  33%|███▎      | 2/6 [00:00<00:00, 13.77it/s]Loading pipeline components...:  67%|██████▋   | 4/6 [00:00<00:00,  9.06it/s]Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 13.99it/s]

Accuracy on benign examples: 100.0%
gt_label: 388 pred_label: 388 pred_clean_logit 0.999265730381012
prompt generate:  giant panda  	labels:  [[388]]
decoder:  [49406, 4687, 12952, 49407] [49406, 49407]
DDIM_inverse:   0%|          | 0/19 [00:00<?, ?it/s]DDIM_inverse:  11%|█         | 2/19 [00:00<00:02,  7.19it/s]DDIM_inverse:  16%|█▌        | 3/19 [00:00<00:02,  6.13it/s]DDIM_inverse:  21%|██        | 4/19 [00:00<00:02,  5.70it/s]DDIM_inverse:  26%|██▋       | 5/19 [00:00<00:02,  5.63it/s]DDIM_inverse:  32%|███▏      | 6/19 [00:01<00:02,  5.62it/s]DDIM_inverse:  37%|███▋      | 7/19 [00:01<00:02,  5.85it/s]DDIM_inverse:  42%|████▏     | 8/19 [00:01<00:01,  6.08it/s]DDIM_inverse:  47%|████▋     | 9/19 [00:01<00:01,  6.23it/s]DDIM_inverse:  53%|█████▎    | 10/19 [00:01<00:01,  6.28it/s]DDIM_inverse:  58%|█████▊    | 11/19 [00:01<00:01,  6.32it/s]DDIM_inverse:  63%|██████▎   | 12/19 [00:01<00:01,  6.34it/s]DDIM_inverse:  68%|██████▊   | 13/19 [00:02<00:00,  6.37it/s]DDIM_inverse:  74%|███████▎  | 14/19 [00:02<00:00,  6.02it/s]DDIM_inverse:  79%|███████▉  | 15/19 [00:02<00:00,  5.75it/s]DDIM_inverse:  84%|████████▍ | 16/19 [00:02<00:00,  5.70it/s]DDIM_inverse:  89%|████████▉ | 17/19 [00:02<00:00,  5.50it/s]DDIM_inverse:  95%|█████████▍| 18/19 [00:03<00:00,  5.36it/s]DDIM_inverse: 100%|██████████| 19/19 [00:03<00:00,  5.26it/s]DDIM_inverse: 100%|██████████| 19/19 [00:03<00:00,  5.82it/s]
Optimize_uncond_embed:   0%|          | 0/5 [00:00<?, ?it/s]Optimize_uncond_embed:  20%|██        | 1/5 [00:04<00:16,  4.14s/it]Optimize_uncond_embed:  40%|████      | 2/5 [00:08<00:12,  4.23s/it]Optimize_uncond_embed:  60%|██████    | 3/5 [00:13<00:09,  4.67s/it]Optimize_uncond_embed:  80%|████████  | 4/5 [00:19<00:05,  5.02s/it]Optimize_uncond_embed: 100%|██████████| 5/5 [00:26<00:00,  5.91s/it]Optimize_uncond_embed: 100%|██████████| 5/5 [00:26<00:00,  5.33s/it]
Iterations:   0%|          | 0/30 [00:00<?, ?it/s]Iterations:   0%|          | 0/30 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 167, in <module>
    adv_image, clean_acc, adv_acc = run_diffusion_attack(tmp_image, label[ind:ind + 1],
  File "main.py", line 72, in run_diffusion_attack
    adv_image, clean_acc, adv_acc = diff_latent_attack.diffattack(diffusion_model, label, controller,
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/datastore/clc_hcmus/npctri/DiffAttack/diff_latent_attack.py", line 644, in diffattack
    latents = diffusion_step(model, latents, context[ind], t, guidance_scale)
  File "/datastore/clc_hcmus/npctri/DiffAttack/diff_latent_attack.py", line 453, in diffusion_step
    noise_pred = model.unet(latents_input, t, encoder_hidden_states=context)["sample"]
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/diffusers/models/unets/unet_2d_condition.py", line 1281, in forward
    sample = upsample_block(
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/diffusers/models/unets/unet_2d_blocks.py", line 2551, in forward
    hidden_states = attn(
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/diffusers/models/transformers/transformer_2d.py", line 442, in forward
    hidden_states = block(
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/diffusers/models/attention.py", line 530, in forward
    ff_output = self.ff(norm_hidden_states)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/diffusers/models/attention.py", line 1166, in forward
    hidden_states = module(hidden_states)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/diffusers/models/activations.py", line 123, in forward
    return hidden_states * self.gelu(gate)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/diffusers/models/activations.py", line 109, in gelu
    return F.gelu(gate)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 6.16 GiB already allocated; 11.56 MiB free; 6.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
