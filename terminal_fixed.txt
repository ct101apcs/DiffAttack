
******Attack based on Diffusion, Attacked Dataset: imagenet_compatible*********

==================================================
FIXED TIMESTEP WEIGHTS ENABLED
==================================================
Schedule type: learned
Weights: [0.064, 0.103, 0.158, 0.269, 0.406]
==================================================


✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 388 pred_label: 388 pred_clean_logit 0.9999761581420898
prompt generate:  giant panda  	labels:  [[388]]
decoder:  [49406, 4687, 12952, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([370], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([388], device='cuda:0') tensor(8.6334e-16, device='cuda:0')
L1: [7239.0977]	L2: [28.394156]	Linf: [0.56078434]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000010, Std=0.000005, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 576 pred_label: 576 pred_clean_logit 0.9961865544319153
prompt generate:  gondola  	labels:  [[576]]
decoder:  [49406, 1854, 38005, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([525], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([576], device='cuda:0') tensor(4.4088e-23, device='cuda:0')
L1: [10826.706]	L2: [41.020668]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 326 pred_label: 326 pred_clean_logit 0.9948904514312744
prompt generate:  lycaenid  	labels:  [[326]]
decoder:  [49406, 1251, 772, 524, 1014, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([322], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([326], device='cuda:0') tensor(2.4753e-14, device='cuda:0')
L1: [11192.313]	L2: [42.027946]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 137 pred_label: 137 pred_clean_logit 0.9999957084655762
prompt generate:  American coot  	labels:  [[137]]
decoder:  [49406, 2151, 1664, 339, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([344], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([137], device='cuda:0') tensor(1.3608e-17, device='cuda:0')
L1: [10817.475]	L2: [39.730835]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 90 pred_label: 90 pred_clean_logit 0.999975323677063
prompt generate:  lorikeet  	labels:  [[90]]
decoder:  [49406, 20164, 643, 875, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([90], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([90], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [4803.2905]	L2: [21.991747]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.4%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.4%
Timestep  4: Avg Loss=0.000002, Std=0.000000, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 981 pred_label: 981 pred_clean_logit 0.9789443016052246
prompt generate:  ballplayer  	labels:  [[981]]
decoder:  [49406, 3807, 2477, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([768], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([981], device='cuda:0') tensor(3.8246e-13, device='cuda:0')
L1: [7687.691]	L2: [30.2677]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=16.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=40.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 40.3% (timestep 4)
Min contribution: 7.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 9 pred_label: 9 pred_clean_logit 0.9999983310699463
prompt generate:  ostrich  	labels:  [[9]]
decoder:  [49406, 47640, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([355], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([9], device='cuda:0') tensor(2.4856e-08, device='cuda:0')
L1: [9053.64]	L2: [34.71241]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.0%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 471 pred_label: 880 pred_clean_logit 0.03641903027892113
prompt generate:  cannon  	labels:  [[880]]
decoder:  [49406, 15661, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([880], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([471], device='cuda:0') tensor(5.1253e-12, device='cuda:0')
L1: [7185.474]	L2: [25.934925]	Linf: [0.6862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000018, Std=0.000005, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 303 pred_label: 303 pred_clean_logit 0.9998551607131958
prompt generate:  long-horned beetle  	labels:  [[303]]
decoder:  [49406, 1538, 268, 34526, 16534, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([300], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([303], device='cuda:0') tensor(1.2231e-08, device='cuda:0')
L1: [5040.294]	L2: [19.906105]	Linf: [0.5176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 967 pred_label: 967 pred_clean_logit 0.9999995231628418
prompt generate:  espresso  	labels:  [[967]]
decoder:  [49406, 17098, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([967], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([967], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3821.816]	L2: [15.977025]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000000, Contribution=13.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=27.0%
Timestep  4: Avg Loss=0.000006, Std=0.000001, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 450 pred_label: 450 pred_clean_logit 0.999992847442627
prompt generate:  bobsled  	labels:  [[450]]
decoder:  [49406, 8444, 28438, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([744], device='cuda:0') tensor(0.9994, device='cuda:0')
after_true: tensor([450], device='cuda:0') tensor(9.6720e-22, device='cuda:0')
L1: [6940.42]	L2: [29.75233]	Linf: [0.8156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000007, Std=0.000004, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 326 pred_label: 307 pred_clean_logit 0.012216628529131413
prompt generate:  lycaenid  	labels:  [[307]]
decoder:  [49406, 1251, 772, 524, 1014, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([307], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([326], device='cuda:0') tensor(1.0038e-19, device='cuda:0')
L1: [6903.13]	L2: [29.11969]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.0% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 579 pred_label: 579 pred_clean_logit 0.9999785423278809
prompt generate:  grand piano  	labels:  [[579]]
decoder:  [49406, 2991, 7894, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([526], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([579], device='cuda:0') tensor(2.9083e-19, device='cuda:0')
L1: [4916.067]	L2: [23.943762]	Linf: [0.72156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 974 pred_label: 974 pred_clean_logit 0.4764682650566101
prompt generate:  geyser  	labels:  [[974]]
decoder:  [49406, 619, 33121, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([33], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([974], device='cuda:0') tensor(2.3101e-19, device='cuda:0')
L1: [5812.576]	L2: [21.459137]	Linf: [0.5921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=21.8%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=63.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 63.0% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 624 pred_label: 884 pred_clean_logit 0.21167829632759094
prompt generate:  library  	labels:  [[884]]
decoder:  [49406, 3519, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([538], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([624], device='cuda:0') tensor(4.1215e-13, device='cuda:0')
L1: [7429.3696]	L2: [30.864508]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=46.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.8% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 17 pred_label: 17 pred_clean_logit 0.5130999684333801
prompt generate:  jay  	labels:  [[17]]
decoder:  [49406, 4155, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([758], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([17], device='cuda:0') tensor(8.7039e-09, device='cuda:0')
L1: [4381.6157]	L2: [23.904272]	Linf: [0.9843137]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=21.4%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 663 pred_label: 663 pred_clean_logit 0.8715879917144775
prompt generate:  monastery  	labels:  [[663]]
decoder:  [49406, 21850, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([698], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([663], device='cuda:0') tensor(1.0668e-15, device='cuda:0')
L1: [4996.349]	L2: [20.552494]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 967 pred_label: 967 pred_clean_logit 0.999982476234436
prompt generate:  espresso  	labels:  [[967]]
decoder:  [49406, 17098, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([968], device='cuda:0') tensor(0.9956, device='cuda:0')
after_true: tensor([967], device='cuda:0') tensor(2.2154e-09, device='cuda:0')
L1: [2902.322]	L2: [11.966736]	Linf: [0.43529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 425 pred_label: 425 pred_clean_logit 0.9992275238037109
prompt generate:  barn  	labels:  [[425]]
decoder:  [49406, 10942, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([425], device='cuda:0') tensor(2.8497e-12, device='cuda:0')
L1: [6701.4673]	L2: [26.425888]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 652 pred_label: 652 pred_clean_logit 0.8967668414115906
prompt generate:  military uniform  	labels:  [[652]]
decoder:  [49406, 4323, 11075, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([557], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([652], device='cuda:0') tensor(2.4830e-22, device='cuda:0')
L1: [7074.8706]	L2: [30.893879]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 464 pred_label: 816 pred_clean_logit 0.17598950862884521
prompt generate:  buckle  	labels:  [[816]]
decoder:  [49406, 21948, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([816], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([464], device='cuda:0') tensor(7.5883e-16, device='cuda:0')
L1: [5418.3374]	L2: [20.961231]	Linf: [0.58431375]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=49.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.8% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 809 pred_label: 809 pred_clean_logit 0.9941885471343994
prompt generate:  soup bowl  	labels:  [[809]]
decoder:  [49406, 7077, 3814, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([925], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([809], device='cuda:0') tensor(8.0702e-11, device='cuda:0')
L1: [3030.3533]	L2: [10.685884]	Linf: [0.30980393]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.7%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 107 pred_label: 107 pred_clean_logit 0.9999765157699585
prompt generate:  jellyfish  	labels:  [[107]]
decoder:  [49406, 30988, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([903], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([107], device='cuda:0') tensor(6.5267e-18, device='cuda:0')
L1: [5882.4395]	L2: [25.457623]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.7%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=57.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.9% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 672 pred_label: 917 pred_clean_logit 0.0008617190178483725
prompt generate:  mountain tent  	labels:  [[917]]
decoder:  [49406, 3965, 10782, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([692], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([672], device='cuda:0') tensor(4.2760e-25, device='cuda:0')
L1: [8027.4907]	L2: [33.731792]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 253 pred_label: 253 pred_clean_logit 0.9790931940078735
prompt generate:  basenji  	labels:  [[253]]
decoder:  [49406, 1244, 524, 2697, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([158], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([253], device='cuda:0') tensor(1.0795e-23, device='cuda:0')
L1: [12007.2]	L2: [41.92243]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 853 pred_label: 853 pred_clean_logit 0.9998495578765869
prompt generate:  thatch  	labels:  [[853]]
decoder:  [49406, 6303, 634, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([462], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([853], device='cuda:0') tensor(1.0369e-22, device='cuda:0')
L1: [8794.843]	L2: [33.819794]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 972 pred_label: 972 pred_clean_logit 0.741553783416748
prompt generate:  cliff  	labels:  [[972]]
decoder:  [49406, 10625, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([500], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([972], device='cuda:0') tensor(5.8331e-14, device='cuda:0')
L1: [7484.5103]	L2: [30.76846]	Linf: [0.654902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=56.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.9% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 703 pred_label: 765 pred_clean_logit 0.22384493052959442
prompt generate:  park bench  	labels:  [[765]]
decoder:  [49406, 1452, 8771, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([706], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([703], device='cuda:0') tensor(4.9376e-17, device='cuda:0')
L1: [8807.456]	L2: [34.81963]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.8%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=48.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.7% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 107 pred_label: 107 pred_clean_logit 0.4076721966266632
prompt generate:  jellyfish  	labels:  [[107]]
decoder:  [49406, 30988, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([801], device='cuda:0') tensor(0.9994, device='cuda:0')
after_true: tensor([107], device='cuda:0') tensor(8.3811e-08, device='cuda:0')
L1: [2617.1338]	L2: [10.149106]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.8%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 963 pred_label: 941 pred_clean_logit 0.058770451694726944
prompt generate:  pizza  	labels:  [[941]]
decoder:  [49406, 4474, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([941], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([963], device='cuda:0') tensor(9.7797e-22, device='cuda:0')
L1: [10280.862]	L2: [40.448242]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 353 pred_label: 353 pred_clean_logit 0.9999136924743652
prompt generate:  gazelle  	labels:  [[353]]
decoder:  [49406, 4837, 4765, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([352], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([353], device='cuda:0') tensor(5.7735e-10, device='cuda:0')
L1: [5425.2983]	L2: [19.90151]	Linf: [0.5529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000002, Contribution=11.6%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=23.8%
Timestep  4: Avg Loss=0.000011, Std=0.000006, Contribution=55.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.8% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 605 pred_label: 605 pred_clean_logit 0.9101880788803101
prompt generate:  iPod  	labels:  [[605]]
decoder:  [49406, 17889, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([487], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([605], device='cuda:0') tensor(4.3032e-12, device='cuda:0')
L1: [3597.851]	L2: [16.203354]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.8%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 759 pred_label: 759 pred_clean_logit 0.9991193413734436
prompt generate:  reflex camera  	labels:  [[759]]
decoder:  [49406, 36050, 3934, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([622], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([759], device='cuda:0') tensor(7.7664e-15, device='cuda:0')
L1: [5799.4937]	L2: [26.658411]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 982 pred_label: 982 pred_clean_logit 0.7787193655967712
prompt generate:  groom  	labels:  [[982]]
decoder:  [49406, 22813, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([523], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([982], device='cuda:0') tensor(2.2020e-31, device='cuda:0')
L1: [6562.985]	L2: [25.247122]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 483 pred_label: 483 pred_clean_logit 0.9999613761901855
prompt generate:  castle  	labels:  [[483]]
decoder:  [49406, 3540, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([483], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([483], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7119.9297]	L2: [28.38211]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.8%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 733 pred_label: 733 pred_clean_logit 0.9946756362915039
prompt generate:  pole  	labels:  [[733]]
decoder:  [49406, 8170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([724], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([733], device='cuda:0') tensor(1.8948e-11, device='cuda:0')
L1: [4588.345]	L2: [23.9836]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=7.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=9.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=46.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.9% (timestep 4)
Min contribution: 7.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 560 pred_label: 560 pred_clean_logit 0.9892776012420654
prompt generate:  football helmet  	labels:  [[560]]
decoder:  [49406, 1882, 11122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([670], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([560], device='cuda:0') tensor(3.3779e-21, device='cuda:0')
L1: [7552.2095]	L2: [34.240467]	Linf: [0.92156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 483 pred_label: 483 pred_clean_logit 0.9994887113571167
prompt generate:  castle  	labels:  [[483]]
decoder:  [49406, 3540, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([708], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([483], device='cuda:0') tensor(8.5816e-18, device='cuda:0')
L1: [6606.4873]	L2: [27.812794]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.7%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=58.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.3% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 560 pred_label: 541 pred_clean_logit 0.0017817472107708454
prompt generate:  football helmet  	labels:  [[541]]
decoder:  [49406, 1882, 11122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([541], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([560], device='cuda:0') tensor(1.7562e-27, device='cuda:0')
L1: [14596.717]	L2: [53.891956]	Linf: [0.95686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.7%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 565 pred_label: 519 pred_clean_logit 0.08398216217756271
prompt generate:  freight car  	labels:  [[519]]
decoder:  [49406, 17023, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([525], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([565], device='cuda:0') tensor(8.6072e-28, device='cuda:0')
L1: [8626.503]	L2: [30.636726]	Linf: [0.56470585]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 718 pred_label: 718 pred_clean_logit 0.8794013857841492
prompt generate:  pier  	labels:  [[718]]
decoder:  [49406, 11348, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([821], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([718], device='cuda:0') tensor(2.5850e-12, device='cuda:0')
L1: [4791.8154]	L2: [21.53005]	Linf: [0.89411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 305 pred_label: 305 pred_clean_logit 0.8291129469871521
prompt generate:  dung beetle  	labels:  [[305]]
decoder:  [49406, 33712, 16534, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([302], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([305], device='cuda:0') tensor(7.2707e-12, device='cuda:0')
L1: [5617.7847]	L2: [19.824804]	Linf: [0.43529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000015, Std=0.000003, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 483 pred_label: 483 pred_clean_logit 0.9997243285179138
prompt generate:  castle  	labels:  [[483]]
decoder:  [49406, 3540, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([708], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([483], device='cuda:0') tensor(3.1333e-17, device='cuda:0')
L1: [5503.016]	L2: [23.51866]	Linf: [0.5803921]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.5%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=61.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 61.7% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 972 pred_label: 972 pred_clean_logit 0.7421599626541138
prompt generate:  cliff  	labels:  [[972]]
decoder:  [49406, 10625, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([383], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([972], device='cuda:0') tensor(8.1575e-24, device='cuda:0')
L1: [11782.945]	L2: [41.241287]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.3%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 770 pred_label: 770 pred_clean_logit 0.9997656941413879
prompt generate:  running shoe  	labels:  [[770]]
decoder:  [49406, 2761, 7342, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([597], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([770], device='cuda:0') tensor(2.1786e-17, device='cuda:0')
L1: [4567.933]	L2: [22.913197]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 570 pred_label: 570 pred_clean_logit 0.999969482421875
prompt generate:  gasmask  	labels:  [[570]]
decoder:  [49406, 5047, 8306, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([678], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([570], device='cuda:0') tensor(1.3063e-34, device='cuda:0')
L1: [9988.0205]	L2: [43.219822]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=26.4%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=46.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.9% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 323 pred_label: 323 pred_clean_logit 0.9999911785125732
prompt generate:  monarch  	labels:  [[323]]
decoder:  [49406, 22619, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([323], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([323], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [9440.56]	L2: [39.843616]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=26.6%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 815 pred_label: 815 pred_clean_logit 0.9626708626747131
prompt generate:  spider web  	labels:  [[815]]
decoder:  [49406, 7622, 4601, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([815], device='cuda:0') tensor(4.7346e-23, device='cuda:0')
L1: [9617.705]	L2: [36.189724]	Linf: [0.5921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=27.3%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 961 pred_label: 961 pred_clean_logit 0.9996494054794312
prompt generate:  dough  	labels:  [[961]]
decoder:  [49406, 14983, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([995], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([961], device='cuda:0') tensor(2.9669e-17, device='cuda:0')
L1: [5454.212]	L2: [21.855898]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=23.8%
Timestep  4: Avg Loss=0.000011, Std=0.000005, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 538 pred_label: 538 pred_clean_logit 0.5959685444831848
prompt generate:  dome  	labels:  [[538]]
decoder:  [49406, 9827, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([861], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([538], device='cuda:0') tensor(3.9885e-18, device='cuda:0')
L1: [10072.098]	L2: [33.54268]	Linf: [0.43921572]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.8%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=45.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.2% (timestep 4)
Min contribution: 8.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 113 pred_label: 113 pred_clean_logit 0.9999963045120239
prompt generate:  snail  	labels:  [[113]]
decoder:  [49406, 23132, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([113], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([113], device='cuda:0') tensor(1., device='cuda:0')
L1: [4578.4595]	L2: [16.425528]	Linf: [0.4666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 877 pred_label: 760 pred_clean_logit 0.17782972753047943
prompt generate:  turnstile  	labels:  [[760]]
decoder:  [49406, 5522, 522, 989, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([675], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([877], device='cuda:0') tensor(2.4935e-18, device='cuda:0')
L1: [6216.843]	L2: [25.343027]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=48.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.8% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 821 pred_label: 821 pred_clean_logit 0.9962553977966309
prompt generate:  steel arch bridge  	labels:  [[821]]
decoder:  [49406, 4726, 8557, 2465, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([752], device='cuda:0') tensor(0.9994, device='cuda:0')
after_true: tensor([821], device='cuda:0') tensor(1.0147e-11, device='cuda:0')
L1: [4877.062]	L2: [19.230253]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=21.9%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 366 pred_label: 366 pred_clean_logit 0.9999909400939941
prompt generate:  gorilla  	labels:  [[366]]
decoder:  [49406, 21994, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([373], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([366], device='cuda:0') tensor(9.2328e-14, device='cuda:0')
L1: [6841.059]	L2: [24.191599]	Linf: [0.6431372]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 762 pred_label: 779 pred_clean_logit 0.0791083350777626
prompt generate:  restaurant  	labels:  [[779]]
decoder:  [49406, 4489, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([779], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([762], device='cuda:0') tensor(1.9106e-22, device='cuda:0')
L1: [8732.965]	L2: [33.63045]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 752 pred_label: 752 pred_clean_logit 0.8864291310310364
prompt generate:  racket  	labels:  [[752]]
decoder:  [49406, 37691, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([890], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([752], device='cuda:0') tensor(7.2098e-16, device='cuda:0')
L1: [4565.3296]	L2: [19.313633]	Linf: [0.6509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 759 pred_label: 759 pred_clean_logit 0.9999091625213623
prompt generate:  reflex camera  	labels:  [[759]]
decoder:  [49406, 36050, 3934, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([704], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([759], device='cuda:0') tensor(9.5877e-18, device='cuda:0')
L1: [5692.133]	L2: [25.30814]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 743 pred_label: 698 pred_clean_logit 0.0007994522457011044
prompt generate:  prison  	labels:  [[698]]
decoder:  [49406, 6622, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([698], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([743], device='cuda:0') tensor(1.7107e-14, device='cuda:0')
L1: [10722.154]	L2: [42.259872]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 893 pred_label: 893 pred_clean_logit 0.4368836283683777
prompt generate:  wallet  	labels:  [[893]]
decoder:  [49406, 12154, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([626], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([893], device='cuda:0') tensor(3.3841e-16, device='cuda:0')
L1: [7235.656]	L2: [29.181705]	Linf: [0.90588236]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=57.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.5% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 49 pred_label: 49 pred_clean_logit 0.9981182813644409
prompt generate:  African crocodile  	labels:  [[49]]
decoder:  [49406, 4736, 24757, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([50], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([49], device='cuda:0') tensor(1.2442e-17, device='cuda:0')
L1: [10004.804]	L2: [39.960403]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 22 pred_label: 22 pred_clean_logit 0.9888076186180115
prompt generate:  bald eagle  	labels:  [[22]]
decoder:  [49406, 14875, 7517, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([21], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([22], device='cuda:0') tensor(8.3985e-13, device='cuda:0')
L1: [4109.616]	L2: [19.994726]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=21.4%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.5% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 825 pred_label: 825 pred_clean_logit 0.9365487098693848
prompt generate:  stone wall  	labels:  [[825]]
decoder:  [49406, 2441, 2569, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([611], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([825], device='cuda:0') tensor(9.5762e-22, device='cuda:0')
L1: [13316.995]	L2: [46.42964]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=25.8%
Timestep  4: Avg Loss=0.000018, Std=0.000005, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 476 pred_label: 792 pred_clean_logit 1.4199355064192787e-05
prompt generate:  carousel  	labels:  [[792]]
decoder:  [49406, 36665, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([792], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([476], device='cuda:0') tensor(1.0064e-22, device='cuda:0')
L1: [5116.02]	L2: [23.696157]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 458 pred_label: 458 pred_clean_logit 0.9929064512252808
prompt generate:  brass  	labels:  [[458]]
decoder:  [49406, 11655, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([509], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([458], device='cuda:0') tensor(3.8142e-15, device='cuda:0')
L1: [7952.7695]	L2: [27.221056]	Linf: [0.4627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 470 pred_label: 470 pred_clean_logit 0.9999986886978149
prompt generate:  candle  	labels:  [[470]]
decoder:  [49406, 12674, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([470], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([470], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2735.306]	L2: [15.204407]	Linf: [0.67450976]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 97 pred_label: 97 pred_clean_logit 0.997694194316864
prompt generate:  drake  	labels:  [[97]]
decoder:  [49406, 8958, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([7], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([97], device='cuda:0') tensor(6.7059e-16, device='cuda:0')
L1: [13032.953]	L2: [45.668095]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=27.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 814 pred_label: 814 pred_clean_logit 0.999995231628418
prompt generate:  speedboat  	labels:  [[814]]
decoder:  [49406, 6860, 4440, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([814], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([814], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [1813.7609]	L2: [8.7775755]	Linf: [0.5372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=17.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=26.8%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=44.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 582 pred_label: 582 pred_clean_logit 0.9996342658996582
prompt generate:  grocery store  	labels:  [[582]]
decoder:  [49406, 13826, 2183, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([762], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([582], device='cuda:0') tensor(1.6267e-13, device='cuda:0')
L1: [11213.286]	L2: [43.309242]	Linf: [0.94509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=25.4%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 580 pred_label: 580 pred_clean_logit 0.8767382502555847
prompt generate:  greenhouse  	labels:  [[580]]
decoder:  [49406, 20819, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([580], device='cuda:0') tensor(1.1821e-26, device='cuda:0')
L1: [13658.926]	L2: [47.700397]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.9%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 619 pred_label: 611 pred_clean_logit 0.001399543834850192
prompt generate:  lampshade  	labels:  [[611]]
decoder:  [49406, 26700, 10097, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([905], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([619], device='cuda:0') tensor(8.6233e-17, device='cuda:0')
L1: [7297.5605]	L2: [32.494133]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=59.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.0% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 875 pred_label: 875 pred_clean_logit 0.9964978694915771
prompt generate:  trombone  	labels:  [[875]]
decoder:  [49406, 44423, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([603], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([875], device='cuda:0') tensor(3.5207e-17, device='cuda:0')
L1: [4839.7803]	L2: [28.69755]	Linf: [0.972549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 609 pred_label: 436 pred_clean_logit 0.1649796962738037
prompt generate:  jeep  	labels:  [[436]]
decoder:  [49406, 11286, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([436], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([609], device='cuda:0') tensor(9.4198e-13, device='cuda:0')
L1: [8414.628]	L2: [29.587173]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=56.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.4% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 421 pred_label: 421 pred_clean_logit 0.9511080980300903
prompt generate:  bannister  	labels:  [[421]]
decoder:  [49406, 1159, 36640, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([567], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([421], device='cuda:0') tensor(1.1352e-32, device='cuda:0')
L1: [7234.917]	L2: [31.639654]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 513 pred_label: 513 pred_clean_logit 0.9999873638153076
prompt generate:  cornet  	labels:  [[513]]
decoder:  [49406, 851, 2315, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([558], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([513], device='cuda:0') tensor(7.3414e-27, device='cuda:0')
L1: [7279.118]	L2: [30.661713]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=45.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.3% (timestep 4)
Min contribution: 6.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 775 pred_label: 775 pred_clean_logit 0.9971038699150085
prompt generate:  sarong  	labels:  [[775]]
decoder:  [49406, 1808, 846, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([514], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([775], device='cuda:0') tensor(8.9956e-27, device='cuda:0')
L1: [12691.572]	L2: [43.750175]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000011, Std=0.000002, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 701 pred_label: 701 pred_clean_logit 0.9999696016311646
prompt generate:  parachute  	labels:  [[701]]
decoder:  [49406, 30122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([417], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([701], device='cuda:0') tensor(2.0074e-11, device='cuda:0')
L1: [2848.894]	L2: [13.076108]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 922 pred_label: 922 pred_clean_logit 0.9999139308929443
prompt generate:  menu  	labels:  [[922]]
decoder:  [49406, 6225, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([922], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([922], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [4761.5254]	L2: [20.96169]	Linf: [0.56078434]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.2%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=10.6%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.0%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 468 pred_label: 436 pred_clean_logit 0.12694910168647766
prompt generate:  cab  	labels:  [[436]]
decoder:  [49406, 11912, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([562], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([468], device='cuda:0') tensor(1.8556e-21, device='cuda:0')
L1: [8352.435]	L2: [33.533398]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 94 pred_label: 94 pred_clean_logit 0.629352867603302
prompt generate:  hummingbird  	labels:  [[94]]
decoder:  [49406, 33072, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([95], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([94], device='cuda:0') tensor(9.5154e-12, device='cuda:0')
L1: [4207.569]	L2: [16.924585]	Linf: [0.4901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 978 pred_label: 978 pred_clean_logit 0.7827085852622986
prompt generate:  seashore  	labels:  [[978]]
decoder:  [49406, 567, 31194, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([203], device='cuda:0') tensor(0.9190, device='cuda:0')
after_true: tensor([978], device='cuda:0') tensor(2.4910e-11, device='cuda:0')
L1: [4709.996]	L2: [19.576027]	Linf: [0.454902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 141 pred_label: 141 pred_clean_logit 0.9998656511306763
prompt generate:  redshank  	labels:  [[141]]
decoder:  [49406, 1893, 24685, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([142], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([141], device='cuda:0') tensor(1.2231e-09, device='cuda:0')
L1: [4876.478]	L2: [19.8241]	Linf: [0.5568627]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.1%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 227 pred_label: 227 pred_clean_logit 0.7454649806022644
prompt generate:  kelpie  	labels:  [[227]]
decoder:  [49406, 2825, 5319, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([269], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([227], device='cuda:0') tensor(3.8592e-17, device='cuda:0')
L1: [6097.031]	L2: [24.026917]	Linf: [0.5294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=25.2%
Timestep  4: Avg Loss=0.000012, Std=0.000005, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 565 pred_label: 779 pred_clean_logit 3.6322679079603404e-05
prompt generate:  freight car  	labels:  [[779]]
decoder:  [49406, 17023, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([779], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([565], device='cuda:0') tensor(3.3106e-21, device='cuda:0')
L1: [5142.129]	L2: [23.30946]	Linf: [0.8784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.6%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 555 pred_label: 555 pred_clean_logit 0.9998262524604797
prompt generate:  fire engine  	labels:  [[555]]
decoder:  [49406, 1769, 5857, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([407], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([555], device='cuda:0') tensor(1.1793e-17, device='cuda:0')
L1: [6287.3647]	L2: [31.44895]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=26.0%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=43.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.1% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 965 pred_label: 965 pred_clean_logit 0.9312538504600525
prompt generate:  burrito  	labels:  [[965]]
decoder:  [49406, 23473, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([935], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([965], device='cuda:0') tensor(1.4427e-25, device='cuda:0')
L1: [8187.695]	L2: [31.978003]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 990 pred_label: 990 pred_clean_logit 0.6793997287750244
prompt generate:  buckeye  	labels:  [[990]]
decoder:  [49406, 34549, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([113], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([990], device='cuda:0') tensor(3.4503e-22, device='cuda:0')
L1: [8725.64]	L2: [31.918203]	Linf: [0.5882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 858 pred_label: 858 pred_clean_logit 0.9375647306442261
prompt generate:  tile roof  	labels:  [[858]]
decoder:  [49406, 8227, 6449, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([858], device='cuda:0') tensor(7.6523e-17, device='cuda:0')
L1: [9310.195]	L2: [36.846817]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=49.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.3% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 517 pred_label: 517 pred_clean_logit 0.9975014328956604
prompt generate:  crane  	labels:  [[517]]
decoder:  [49406, 14626, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([724], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([517], device='cuda:0') tensor(1.2992e-12, device='cuda:0')
L1: [6904.5176]	L2: [28.500973]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 814 pred_label: 814 pred_clean_logit 0.9999502897262573
prompt generate:  speedboat  	labels:  [[814]]
decoder:  [49406, 6860, 4440, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([814], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([814], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2571.243]	L2: [16.15023]	Linf: [0.9098039]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=12.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=14.3%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=17.5%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=20.8%
Timestep  4: Avg Loss=0.000000, Std=0.000000, Contribution=34.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 34.5% (timestep 4)
Min contribution: 12.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 760 pred_label: 760 pred_clean_logit 0.9999169111251831
prompt generate:  refrigerator  	labels:  [[760]]
decoder:  [49406, 36662, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([771], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([760], device='cuda:0') tensor(5.6718e-12, device='cuda:0')
L1: [5224.632]	L2: [24.975136]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=11.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=12.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=15.3%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=21.2%
Timestep  4: Avg Loss=0.000002, Std=0.000002, Contribution=40.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 40.0% (timestep 4)
Min contribution: 11.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 777 pred_label: 777 pred_clean_logit 0.9999723434448242
prompt generate:  scabbard  	labels:  [[777]]
decoder:  [49406, 31716, 17514, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([597], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([777], device='cuda:0') tensor(9.9814e-17, device='cuda:0')
L1: [5375.42]	L2: [21.604939]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=22.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 984 pred_label: 984 pred_clean_logit 0.9997513890266418
prompt generate:  rapeseed  	labels:  [[984]]
decoder:  [49406, 46099, 6488, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([704], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([984], device='cuda:0') tensor(8.5500e-21, device='cuda:0')
L1: [13111.715]	L2: [44.047485]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 854 pred_label: 881 pred_clean_logit 0.11427261680364609
prompt generate:  theater curtain  	labels:  [[881]]
decoder:  [49406, 6128, 17223, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([881], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([854], device='cuda:0') tensor(4.9525e-22, device='cuda:0')
L1: [6661.773]	L2: [31.586489]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=57.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.8% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 931 pred_label: 931 pred_clean_logit 0.6596606969833374
prompt generate:  bagel  	labels:  [[931]]
decoder:  [49406, 28777, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([666], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([931], device='cuda:0') tensor(1.0695e-16, device='cuda:0')
L1: [3493.3374]	L2: [12.330803]	Linf: [0.33333337]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 607 pred_label: 607 pred_clean_logit 0.9977635145187378
prompt generate:  jack-o'-lantern  	labels:  [[607]]
decoder:  [49406, 3267, 268, 334, 262, 268, 17185, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([844], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([607], device='cuda:0') tensor(1.0556e-18, device='cuda:0')
L1: [5526.797]	L2: [31.552061]	Linf: [0.94509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 869 pred_label: 869 pred_clean_logit 0.9990527033805847
prompt generate:  trench coat  	labels:  [[869]]
decoder:  [49406, 23846, 7356, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([652], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([869], device='cuda:0') tensor(7.6493e-11, device='cuda:0')
L1: [3773.6155]	L2: [19.754063]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.2%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=58.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.8% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 656 pred_label: 656 pred_clean_logit 0.5572025775909424
prompt generate:  minivan  	labels:  [[656]]
decoder:  [49406, 1810, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([717], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([656], device='cuda:0') tensor(5.2208e-15, device='cuda:0')
L1: [6640.915]	L2: [27.246517]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 897 pred_label: 589 pred_clean_logit 0.0016921766800805926
prompt generate:  washer  	labels:  [[589]]
decoder:  [49406, 24085, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([589], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([897], device='cuda:0') tensor(0., device='cuda:0')
L1: [9276.208]	L2: [37.516235]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 959 pred_label: 959 pred_clean_logit 0.9973006844520569
prompt generate:  carbonara  	labels:  [[959]]
decoder:  [49406, 14038, 3340, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([923], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([959], device='cuda:0') tensor(4.3804e-15, device='cuda:0')
L1: [9531.953]	L2: [37.661972]	Linf: [0.8745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.4%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 959 pred_label: 959 pred_clean_logit 0.8642897009849548
prompt generate:  carbonara  	labels:  [[959]]
decoder:  [49406, 14038, 3340, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([947], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([959], device='cuda:0') tensor(6.7639e-20, device='cuda:0')
L1: [7807.3057]	L2: [29.325785]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.7%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 422 pred_label: 422 pred_clean_logit 0.9980229139328003
prompt generate:  barbell  	labels:  [[422]]
decoder:  [49406, 1040, 3718, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([409], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([422], device='cuda:0') tensor(2.8887e-15, device='cuda:0')
L1: [4037.1023]	L2: [20.554344]	Linf: [0.93333334]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 859 pred_label: 859 pred_clean_logit 1.0
prompt generate:  toaster  	labels:  [[859]]
decoder:  [49406, 39061, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([859], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([859], device='cuda:0') tensor(1., device='cuda:0')
L1: [3663.7686]	L2: [16.437935]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.8%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.7%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=22.2%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 640 pred_label: 640 pred_clean_logit 0.9999562501907349
prompt generate:  manhole cover  	labels:  [[640]]
decoder:  [49406, 723, 5341, 2202, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([892], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([640], device='cuda:0') tensor(8.7511e-18, device='cuda:0')
L1: [10260.412]	L2: [36.79302]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=24.7%
Timestep  4: Avg Loss=0.000011, Std=0.000006, Contribution=57.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.4% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 649 pred_label: 649 pred_clean_logit 0.9936981797218323
prompt generate:  megalith  	labels:  [[649]]
decoder:  [49406, 37650, 1757, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([354], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([649], device='cuda:0') tensor(2.8815e-18, device='cuda:0')
L1: [5162.4595]	L2: [20.57757]	Linf: [0.54901963]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.0%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 57 pred_label: 57 pred_clean_logit 0.9991514682769775
prompt generate:  garter snake  	labels:  [[57]]
decoder:  [49406, 48420, 8798, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([311], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([57], device='cuda:0') tensor(2.0189e-16, device='cuda:0')
L1: [10171.145]	L2: [37.305016]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=27.4%
Timestep  4: Avg Loss=0.000018, Std=0.000005, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 1.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 409 pred_label: 409 pred_clean_logit 0.5246387720108032
prompt generate:  analog clock  	labels:  [[409]]
decoder:  [49406, 19963, 6716, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([826], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([409], device='cuda:0') tensor(7.4924e-22, device='cuda:0')
L1: [7930.3296]	L2: [36.37061]	Linf: [0.9607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.7%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=48.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.6% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 472 pred_label: 472 pred_clean_logit 0.9619584083557129
prompt generate:  canoe  	labels:  [[472]]
decoder:  [49406, 23503, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([693], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([472], device='cuda:0') tensor(7.3403e-11, device='cuda:0')
L1: [6867.3027]	L2: [29.036657]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=15.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.0% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 430 pred_label: 430 pred_clean_logit 0.7333475351333618
prompt generate:  basketball  	labels:  [[430]]
decoder:  [49406, 3835, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([793], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([430], device='cuda:0') tensor(6.4032e-38, device='cuda:0')
L1: [9953.755]	L2: [39.915657]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 421 pred_label: 421 pred_clean_logit 0.4874691963195801
prompt generate:  bannister  	labels:  [[421]]
decoder:  [49406, 1159, 36640, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([839], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([421], device='cuda:0') tensor(2.2681e-19, device='cuda:0')
L1: [11273.667]	L2: [42.901257]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 140 pred_label: 140 pred_clean_logit 0.9996304512023926
prompt generate:  red-backed sandpiper  	labels:  [[140]]
decoder:  [49406, 736, 268, 12721, 2147, 16293, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([142], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([140], device='cuda:0') tensor(3.4044e-11, device='cuda:0')
L1: [6419.7217]	L2: [27.081139]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 498 pred_label: 498 pred_clean_logit 0.9737256765365601
prompt generate:  cinema  	labels:  [[498]]
decoder:  [49406, 6443, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([727], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([498], device='cuda:0') tensor(1.1715e-21, device='cuda:0')
L1: [4176.7725]	L2: [20.064884]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=57.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.6% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 565 pred_label: 565 pred_clean_logit 0.9999967813491821
prompt generate:  freight car  	labels:  [[565]]
decoder:  [49406, 17023, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([565], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([565], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6093.664]	L2: [29.286545]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.1%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 404 pred_label: 404 pred_clean_logit 0.796248197555542
prompt generate:  airliner  	labels:  [[404]]
decoder:  [49406, 1281, 11618, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([786], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([404], device='cuda:0') tensor(2.0923e-24, device='cuda:0')
L1: [5304.2]	L2: [21.827679]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=12.7%
Timestep  3: Avg Loss=0.000009, Std=0.000004, Contribution=26.0%
Timestep  4: Avg Loss=0.000019, Std=0.000007, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 581 pred_label: 581 pred_clean_logit 0.9992809891700745
prompt generate:  grille  	labels:  [[581]]
decoder:  [49406, 34748, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([717], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([581], device='cuda:0') tensor(7.3415e-11, device='cuda:0')
L1: [9358.282]	L2: [44.017567]	Linf: [0.9529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.7%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=47.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.3% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 415 pred_label: 949 pred_clean_logit 0.10014360398054123
prompt generate:  bakery  	labels:  [[949]]
decoder:  [49406, 13377, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([943], device='cuda:0') tensor(0.9940, device='cuda:0')
after_true: tensor([415], device='cuda:0') tensor(8.9996e-12, device='cuda:0')
L1: [7380.0044]	L2: [29.97439]	Linf: [0.6862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 538 pred_label: 538 pred_clean_logit 0.9873365759849548
prompt generate:  dome  	labels:  [[538]]
decoder:  [49406, 9827, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([406], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([538], device='cuda:0') tensor(1.2940e-10, device='cuda:0')
L1: [11521.099]	L2: [42.668842]	Linf: [0.8745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=10.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=16.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=38.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 38.3% (timestep 4)
Min contribution: 10.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 768 pred_label: 701 pred_clean_logit 0.0005935734952799976
prompt generate:  rugby ball  	labels:  [[701]]
decoder:  [49406, 4964, 1069, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([837], device='cuda:0') tensor(0.9993, device='cuda:0')
after_true: tensor([768], device='cuda:0') tensor(3.8097e-33, device='cuda:0')
L1: [6488.424]	L2: [27.586987]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000018, Std=0.000004, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 819 pred_label: 819 pred_clean_logit 0.928184449672699
prompt generate:  stage  	labels:  [[819]]
decoder:  [49406, 2170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([420], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([819], device='cuda:0') tensor(2.4076e-29, device='cuda:0')
L1: [5432.1177]	L2: [21.352762]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.2%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=25.9%
Timestep  4: Avg Loss=0.000019, Std=0.000006, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 439 pred_label: 439 pred_clean_logit 0.9990158081054688
prompt generate:  bearskin  	labels:  [[439]]
decoder:  [49406, 6375, 3575, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([645], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([439], device='cuda:0') tensor(2.9068e-21, device='cuda:0')
L1: [8120.5723]	L2: [34.870342]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 336 pred_label: 336 pred_clean_logit 0.9687944650650024
prompt generate:  marmot  	labels:  [[336]]
decoder:  [49406, 675, 15452, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([166], device='cuda:0') tensor(0.9967, device='cuda:0')
after_true: tensor([336], device='cuda:0') tensor(1.6141e-17, device='cuda:0')
L1: [10096.091]	L2: [33.99711]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 50 pred_label: 50 pred_clean_logit 0.9998533725738525
prompt generate:  American alligator  	labels:  [[50]]
decoder:  [49406, 2151, 28574, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([71], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([50], device='cuda:0') tensor(3.0639e-16, device='cuda:0')
L1: [6295.9224]	L2: [22.418621]	Linf: [0.42352942]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000014, Std=0.000003, Contribution=58.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.1% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 303 pred_label: 303 pred_clean_logit 0.999924898147583
prompt generate:  long-horned beetle  	labels:  [[303]]
decoder:  [49406, 1538, 268, 34526, 16534, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([302], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([303], device='cuda:0') tensor(1.4095e-08, device='cuda:0')
L1: [4089.2593]	L2: [17.450426]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.7%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 33 pred_label: 33 pred_clean_logit 0.9924934506416321
prompt generate:  loggerhead  	labels:  [[33]]
decoder:  [49406, 549, 12367, 1375, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([123], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([33], device='cuda:0') tensor(3.5330e-19, device='cuda:0')
L1: [7732.4243]	L2: [28.951637]	Linf: [0.58431375]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.8%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 708 pred_label: 708 pred_clean_logit 0.9683083295822144
prompt generate:  pedestal  	labels:  [[708]]
decoder:  [49406, 12862, 5535, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([873], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([708], device='cuda:0') tensor(6.3931e-15, device='cuda:0')
L1: [7604.2227]	L2: [29.382465]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 475 pred_label: 475 pred_clean_logit 0.8436539173126221
prompt generate:  car mirror  	labels:  [[475]]
decoder:  [49406, 1615, 7220, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([454], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([475], device='cuda:0') tensor(1.3703e-15, device='cuda:0')
L1: [6943.8984]	L2: [29.803038]	Linf: [0.65098035]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 441 pred_label: 441 pred_clean_logit 0.9957113265991211
prompt generate:  beer glass  	labels:  [[441]]
decoder:  [49406, 2544, 3313, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([438], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([441], device='cuda:0') tensor(8.0765e-22, device='cuda:0')
L1: [6152.066]	L2: [23.699827]	Linf: [0.61176467]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=13.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=48.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.2% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 308 pred_label: 308 pred_clean_logit 0.9999992847442627
prompt generate:  fly  	labels:  [[308]]
decoder:  [49406, 3228, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([309], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([308], device='cuda:0') tensor(2.0206e-09, device='cuda:0')
L1: [6796.0317]	L2: [27.27786]	Linf: [0.9372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000009, Std=0.000005, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 990 pred_label: 990 pred_clean_logit 0.9986425042152405
prompt generate:  buckeye  	labels:  [[990]]
decoder:  [49406, 34549, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([626], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([990], device='cuda:0') tensor(8.5846e-07, device='cuda:0')
L1: [10954.917]	L2: [46.076965]	Linf: [0.9843137]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 511 pred_label: 511 pred_clean_logit 0.9980359673500061
prompt generate:  convertible  	labels:  [[511]]
decoder:  [49406, 19608, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([436], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([511], device='cuda:0') tensor(3.1940e-12, device='cuda:0')
L1: [8454.719]	L2: [35.842224]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=48.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.9% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 644 pred_label: 644 pred_clean_logit 0.9999889135360718
prompt generate:  matchstick  	labels:  [[644]]
decoder:  [49406, 7733, 4987, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([644], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([644], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [1782.2705]	L2: [11.26165]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=17.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 341 pred_label: 341 pred_clean_logit 0.9999947547912598
prompt generate:  hog  	labels:  [[341]]
decoder:  [49406, 13255, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([195], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([341], device='cuda:0') tensor(1.1245e-16, device='cuda:0')
L1: [5644.9956]	L2: [20.509047]	Linf: [0.47058827]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=55.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 582 pred_label: 582 pred_clean_logit 0.9999464750289917
prompt generate:  grocery store  	labels:  [[582]]
decoder:  [49406, 13826, 2183, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([509], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([582], device='cuda:0') tensor(3.6611e-20, device='cuda:0')
L1: [11069.633]	L2: [42.5178]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 698 pred_label: 698 pred_clean_logit 0.6386620998382568
prompt generate:  palace  	labels:  [[698]]
decoder:  [49406, 6381, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([624], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([698], device='cuda:0') tensor(1.1515e-19, device='cuda:0')
L1: [5710.451]	L2: [21.633856]	Linf: [0.5764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 919 pred_label: 919 pred_clean_logit 0.9713510274887085
prompt generate:  street sign  	labels:  [[919]]
decoder:  [49406, 2012, 2292, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([737], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([919], device='cuda:0') tensor(1.5701e-13, device='cuda:0')
L1: [5537.863]	L2: [22.489618]	Linf: [0.5333333]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 974 pred_label: 974 pred_clean_logit 0.9999333620071411
prompt generate:  geyser  	labels:  [[974]]
decoder:  [49406, 619, 33121, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([977], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([974], device='cuda:0') tensor(2.3998e-11, device='cuda:0')
L1: [5991.7607]	L2: [24.301903]	Linf: [0.5568627]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.5%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=61.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 61.2% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 310 pred_label: 310 pred_clean_logit 0.9997653365135193
prompt generate:  ant  	labels:  [[310]]
decoder:  [49406, 773, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([599], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([310], device='cuda:0') tensor(7.9114e-21, device='cuda:0')
L1: [18129.818]	L2: [63.60569]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000009, Std=0.000002, Contribution=27.8%
Timestep  4: Avg Loss=0.000017, Std=0.000004, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 881 pred_label: 881 pred_clean_logit 0.9991846680641174
prompt generate:  upright  	labels:  [[881]]
decoder:  [49406, 29818, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([699], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([881], device='cuda:0') tensor(5.2591e-42, device='cuda:0')
L1: [8788.189]	L2: [31.913034]	Linf: [0.5686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 897 pred_label: 897 pred_clean_logit 0.9986914992332458
prompt generate:  washer  	labels:  [[897]]
decoder:  [49406, 24085, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([787], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([897], device='cuda:0') tensor(1.4265e-09, device='cuda:0')
L1: [2832.423]	L2: [14.53308]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 973 pred_label: 327 pred_clean_logit 0.16259407997131348
prompt generate:  coral reef  	labels:  [[327]]
decoder:  [49406, 12054, 15624, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([327], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([973], device='cuda:0') tensor(1.6785e-23, device='cuda:0')
L1: [11081.203]	L2: [38.977608]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 480 pred_label: 480 pred_clean_logit 0.9999616146087646
prompt generate:  cash machine  	labels:  [[480]]
decoder:  [49406, 5131, 4169, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([480], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([480], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3798.0198]	L2: [17.365952]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.1%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=49.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.8% (timestep 4)
Min contribution: 6.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 309 pred_label: 309 pred_clean_logit 0.9999958276748657
prompt generate:  bee  	labels:  [[309]]
decoder:  [49406, 5028, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([309], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([309], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [4588.553]	L2: [21.535442]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.4%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.3%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 619 pred_label: 786 pred_clean_logit 0.022109828889369965
prompt generate:  lampshade  	labels:  [[786]]
decoder:  [49406, 26700, 10097, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([665], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([619], device='cuda:0') tensor(5.8547e-19, device='cuda:0')
L1: [7836.384]	L2: [36.428917]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=26.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 114 pred_label: 114 pred_clean_logit 0.9981143474578857
prompt generate:  slug  	labels:  [[114]]
decoder:  [49406, 34190, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([45], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([114], device='cuda:0') tensor(1.1976e-14, device='cuda:0')
L1: [16006.165]	L2: [53.226513]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=3.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.1%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=24.6%
Timestep  4: Avg Loss=0.000018, Std=0.000007, Contribution=60.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.3% (timestep 4)
Min contribution: 1.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 475 pred_label: 575 pred_clean_logit 0.47145891189575195
prompt generate:  car mirror  	labels:  [[575]]
decoder:  [49406, 1615, 7220, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([575], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([475], device='cuda:0') tensor(3.4224e-21, device='cuda:0')
L1: [3197.3489]	L2: [11.841206]	Linf: [0.45882356]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=21.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=57.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.1% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 971 pred_label: 971 pred_clean_logit 1.0
prompt generate:  bubble  	labels:  [[971]]
decoder:  [49406, 10799, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([971], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([971], device='cuda:0') tensor(1., device='cuda:0')
L1: [7807.204]	L2: [27.010792]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.5%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=27.1%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=46.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.3% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 478 pred_label: 478 pred_clean_logit 0.9523612260818481
prompt generate:  carton  	labels:  [[478]]
decoder:  [49406, 41812, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([561], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([478], device='cuda:0') tensor(1.0503e-15, device='cuda:0')
L1: [4733.1377]	L2: [20.668787]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 707 pred_label: 707 pred_clean_logit 0.9693230390548706
prompt generate:  pay-phone  	labels:  [[707]]
decoder:  [49406, 3345, 268, 1951, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([528], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([707], device='cuda:0') tensor(4.5312e-13, device='cuda:0')
L1: [4799.224]	L2: [20.558155]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.4%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 873 pred_label: 873 pred_clean_logit 0.9999966621398926
prompt generate:  triumphal arch  	labels:  [[873]]
decoder:  [49406, 14782, 1037, 8708, 8557, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([886], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([873], device='cuda:0') tensor(2.9229e-23, device='cuda:0')
L1: [7348.663]	L2: [29.862566]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.6%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 544 pred_label: 544 pred_clean_logit 0.6786356568336487
prompt generate:  Dutch oven  	labels:  [[544]]
decoder:  [49406, 7991, 12579, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([938], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([544], device='cuda:0') tensor(3.2755e-25, device='cuda:0')
L1: [7001.3804]	L2: [28.263252]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 436 pred_label: 436 pred_clean_logit 0.8622145652770996
prompt generate:  beach wagon  	labels:  [[436]]
decoder:  [49406, 2117, 13260, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([436], device='cuda:0') tensor(1.2993e-19, device='cuda:0')
L1: [7157.9253]	L2: [31.32932]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=41.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.7% (timestep 4)
Min contribution: 8.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 853 pred_label: 853 pred_clean_logit 0.9991968274116516
prompt generate:  thatch  	labels:  [[853]]
decoder:  [49406, 6303, 634, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([448], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([853], device='cuda:0') tensor(3.3966e-16, device='cuda:0')
L1: [5240.659]	L2: [21.537016]	Linf: [0.5647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.4% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 479 pred_label: 479 pred_clean_logit 0.8860898017883301
prompt generate:  car wheel  	labels:  [[479]]
decoder:  [49406, 1615, 6744, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([817], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([479], device='cuda:0') tensor(6.3218e-13, device='cuda:0')
L1: [7665.7456]	L2: [31.464092]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.5% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 912 pred_label: 912 pred_clean_logit 0.9958374500274658
prompt generate:  worm fence  	labels:  [[912]]
decoder:  [49406, 10945, 12679, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([730], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([912], device='cuda:0') tensor(6.7186e-15, device='cuda:0')
L1: [8366.475]	L2: [33.34171]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=58.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.2% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 879 pred_label: 879 pred_clean_logit 0.9997814297676086
prompt generate:  umbrella  	labels:  [[879]]
decoder:  [49406, 17143, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([701], device='cuda:0') tensor(0.9945, device='cuda:0')
after_true: tensor([879], device='cuda:0') tensor(4.6391e-13, device='cuda:0')
L1: [6806.1416]	L2: [27.64479]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=22.8%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=48.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.2% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 307 pred_label: 307 pred_clean_logit 0.9932476282119751
prompt generate:  weevil  	labels:  [[307]]
decoder:  [49406, 716, 3000, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([304], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([307], device='cuda:0') tensor(6.3176e-16, device='cuda:0')
L1: [7430.89]	L2: [31.750864]	Linf: [0.6666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=57.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.2% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 470 pred_label: 470 pred_clean_logit 1.0
prompt generate:  candle  	labels:  [[470]]
decoder:  [49406, 12674, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([902], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([470], device='cuda:0') tensor(1.7913e-20, device='cuda:0')
L1: [2345.5022]	L2: [9.515561]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=21.9%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=57.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.1% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 457 pred_label: 457 pred_clean_logit 1.0
prompt generate:  bow tie  	labels:  [[457]]
decoder:  [49406, 4040, 3422, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([457], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([457], device='cuda:0') tensor(1., device='cuda:0')
L1: [3058.679]	L2: [15.425657]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.8%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 360 pred_label: 360 pred_clean_logit 0.9999902248382568
prompt generate:  otter  	labels:  [[360]]
decoder:  [49406, 22456, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([356], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([360], device='cuda:0') tensor(2.1485e-19, device='cuda:0')
L1: [6301.9062]	L2: [23.34958]	Linf: [0.5647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 79 pred_label: 79 pred_clean_logit 0.9998062252998352
prompt generate:  centipede  	labels:  [[79]]
decoder:  [49406, 48889, 19560, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([599], device='cuda:0') tensor(0.9983, device='cuda:0')
after_true: tensor([79], device='cuda:0') tensor(1.0075e-10, device='cuda:0')
L1: [15835.447]	L2: [52.117516]	Linf: [0.72156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.7%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 649 pred_label: 863 pred_clean_logit 1.2027113598378492e-06
prompt generate:  megalith  	labels:  [[863]]
decoder:  [49406, 37650, 1757, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([899], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([649], device='cuda:0') tensor(1.4108e-38, device='cuda:0')
L1: [7088.7876]	L2: [27.658302]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 442 pred_label: 442 pred_clean_logit 0.28843700885772705
prompt generate:  bell cote  	labels:  [[442]]
decoder:  [49406, 3718, 20751, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([863], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([442], device='cuda:0') tensor(1.5522e-23, device='cuda:0')
L1: [5855.357]	L2: [25.20086]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=47.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.1% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 107 pred_label: 107 pred_clean_logit 0.9990320205688477
prompt generate:  jellyfish  	labels:  [[107]]
decoder:  [49406, 30988, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([749], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([107], device='cuda:0') tensor(3.0846e-25, device='cuda:0')
L1: [4390.212]	L2: [19.815973]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 637 pred_label: 637 pred_clean_logit 0.5035318732261658
prompt generate:  mailbox  	labels:  [[637]]
decoder:  [49406, 31482, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([860], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([637], device='cuda:0') tensor(1.0446e-12, device='cuda:0')
L1: [7247.0034]	L2: [30.791553]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=46.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.1% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 970 pred_label: 970 pred_clean_logit 0.9996525049209595
prompt generate:  alp  	labels:  [[970]]
decoder:  [49406, 39342, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([99], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([970], device='cuda:0') tensor(7.3527e-22, device='cuda:0')
L1: [5881.326]	L2: [23.813717]	Linf: [0.67450976]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000009, Std=0.000005, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 785 pred_label: 785 pred_clean_logit 0.38467782735824585
prompt generate:  seat belt  	labels:  [[785]]
decoder:  [49406, 4922, 7373, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([748], device='cuda:0') tensor(0.9735, device='cuda:0')
after_true: tensor([785], device='cuda:0') tensor(1.8070e-09, device='cuda:0')
L1: [2775.7805]	L2: [12.14209]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=21.8%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 933 pred_label: 933 pred_clean_logit 0.9997177720069885
prompt generate:  cheeseburger  	labels:  [[933]]
decoder:  [49406, 41200, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([441], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([933], device='cuda:0') tensor(3.0404e-16, device='cuda:0')
L1: [6337.6787]	L2: [27.017714]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.3%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=43.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.7% (timestep 4)
Min contribution: 7.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 656 pred_label: 656 pred_clean_logit 0.999908447265625
prompt generate:  minivan  	labels:  [[656]]
decoder:  [49406, 1810, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([675], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([656], device='cuda:0') tensor(1.7565e-17, device='cuda:0')
L1: [7068.8823]	L2: [27.202085]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=47.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.1% (timestep 4)
Min contribution: 6.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 521 pred_label: 124 pred_clean_logit 0.007873756811022758
prompt generate:  Crock Pot  	labels:  [[124]]
decoder:  [49406, 1192, 868, 5168, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([932], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([521], device='cuda:0') tensor(8.2140e-21, device='cuda:0')
L1: [7746.3804]	L2: [30.96424]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 510 pred_label: 510 pred_clean_logit 0.8898465037345886
prompt generate:  container ship  	labels:  [[510]]
decoder:  [49406, 14913, 1158, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([536], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([510], device='cuda:0') tensor(7.6886e-11, device='cuda:0')
L1: [10157.75]	L2: [42.412174]	Linf: [0.8666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 865 pred_label: 865 pred_clean_logit 0.9999620914459229
prompt generate:  toyshop  	labels:  [[865]]
decoder:  [49406, 14387, 1557, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([760], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([865], device='cuda:0') tensor(2.6991e-22, device='cuda:0')
L1: [9908.757]	L2: [37.211113]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=47.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.7% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 23 pred_label: 85 pred_clean_logit 0.32775434851646423
prompt generate:  vulture  	labels:  [[85]]
decoder:  [49406, 34593, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([85], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([23], device='cuda:0') tensor(5.4012e-24, device='cuda:0')
L1: [8768.078]	L2: [39.13468]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 857 pred_label: 857 pred_clean_logit 0.9999997615814209
prompt generate:  throne  	labels:  [[857]]
decoder:  [49406, 15999, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([857], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([857], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7450.228]	L2: [28.689373]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.1%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.8%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=27.8%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=46.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.0% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 498 pred_label: 498 pred_clean_logit 0.9988260865211487
prompt generate:  cinema  	labels:  [[498]]
decoder:  [49406, 6443, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([733], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([498], device='cuda:0') tensor(4.4159e-20, device='cuda:0')
L1: [5318.7256]	L2: [22.905647]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 518 pred_label: 518 pred_clean_logit 0.9924168586730957
prompt generate:  crash helmet  	labels:  [[518]]
decoder:  [49406, 5033, 11122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([746], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([518], device='cuda:0') tensor(7.5232e-14, device='cuda:0')
L1: [8976.127]	L2: [40.27204]	Linf: [0.9411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=28.2%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=46.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.9% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 762 pred_label: 762 pred_clean_logit 0.9736002683639526
prompt generate:  restaurant  	labels:  [[762]]
decoder:  [49406, 4489, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([782], device='cuda:0') tensor(0.9968, device='cuda:0')
after_true: tensor([762], device='cuda:0') tensor(9.5393e-25, device='cuda:0')
L1: [10445.611]	L2: [40.149933]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 865 pred_label: 865 pred_clean_logit 0.9338913559913635
prompt generate:  toyshop  	labels:  [[865]]
decoder:  [49406, 14387, 1557, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([160], device='cuda:0') tensor(0.4751, device='cuda:0')
after_true: tensor([865], device='cuda:0') tensor(2.6658e-08, device='cuda:0')
L1: [12816.345]	L2: [49.97625]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 480 pred_label: 480 pred_clean_logit 0.9750290513038635
prompt generate:  cash machine  	labels:  [[480]]
decoder:  [49406, 5131, 4169, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([827], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([480], device='cuda:0') tensor(2.0825e-21, device='cuda:0')
L1: [3926.7966]	L2: [16.519918]	Linf: [0.69019604]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 873 pred_label: 873 pred_clean_logit 0.999998927116394
prompt generate:  triumphal arch  	labels:  [[873]]
decoder:  [49406, 14782, 1037, 8708, 8557, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([873], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([873], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5999.4863]	L2: [27.129148]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.0%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 476 pred_label: 724 pred_clean_logit 0.14773455262184143
prompt generate:  carousel  	labels:  [[724]]
decoder:  [49406, 36665, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([724], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([476], device='cuda:0') tensor(3.3954e-17, device='cuda:0')
L1: [7616.3843]	L2: [36.906475]	Linf: [0.94509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 315 pred_label: 315 pred_clean_logit 0.5958958864212036
prompt generate:  mantis  	labels:  [[315]]
decoder:  [49406, 39946, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([312], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([315], device='cuda:0') tensor(1.7231e-10, device='cuda:0')
L1: [4208.738]	L2: [19.368532]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=47.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.8% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 609 pred_label: 609 pred_clean_logit 0.9999547004699707
prompt generate:  jeep  	labels:  [[609]]
decoder:  [49406, 11286, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([717], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([609], device='cuda:0') tensor(6.6011e-13, device='cuda:0')
L1: [6997.495]	L2: [30.807838]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 911 pred_label: 574 pred_clean_logit 0.0004941265215165913
prompt generate:  wool  	labels:  [[574]]
decoder:  [49406, 13283, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([936], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([911], device='cuda:0') tensor(1.5210e-21, device='cuda:0')
L1: [4674.9653]	L2: [17.09232]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 497 pred_label: 497 pred_clean_logit 0.9978299736976624
prompt generate:  church  	labels:  [[497]]
decoder:  [49406, 2735, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([663], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([497], device='cuda:0') tensor(2.2164e-11, device='cuda:0')
L1: [8656.562]	L2: [33.824944]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.7%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=43.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.5% (timestep 4)
Min contribution: 8.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 346 pred_label: 730 pred_clean_logit 0.035400208085775375
prompt generate:  water buffalo  	labels:  [[730]]
decoder:  [49406, 1573, 8054, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([856], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([346], device='cuda:0') tensor(1.1129e-15, device='cuda:0')
L1: [12513.988]	L2: [43.34754]	Linf: [0.6509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 825 pred_label: 825 pred_clean_logit 0.972687304019928
prompt generate:  stone wall  	labels:  [[825]]
decoder:  [49406, 2441, 2569, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([500], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([825], device='cuda:0') tensor(1.0159e-12, device='cuda:0')
L1: [9501.749]	L2: [34.166233]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=11.7%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=25.9%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 738 pred_label: 738 pred_clean_logit 0.9999055862426758
prompt generate:  pot  	labels:  [[738]]
decoder:  [49406, 5168, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([937], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([738], device='cuda:0') tensor(1.2807e-21, device='cuda:0')
L1: [11334.322]	L2: [45.940365]	Linf: [0.9411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000004, Std=0.000003, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 839 pred_label: 839 pred_clean_logit 0.9979560375213623
prompt generate:  suspension bridge  	labels:  [[839]]
decoder:  [49406, 15417, 2465, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([196], device='cuda:0') tensor(0.9972, device='cuda:0')
after_true: tensor([839], device='cuda:0') tensor(1.2206e-13, device='cuda:0')
L1: [12479.267]	L2: [44.008667]	Linf: [0.8156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 497 pred_label: 818 pred_clean_logit 0.04767782986164093
prompt generate:  church  	labels:  [[818]]
decoder:  [49406, 2735, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([832], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([497], device='cuda:0') tensor(1.3487e-21, device='cuda:0')
L1: [3213.6511]	L2: [13.904223]	Linf: [0.47058827]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 805 pred_label: 768 pred_clean_logit 0.004618999548256397
prompt generate:  soccer ball  	labels:  [[768]]
decoder:  [49406, 4233, 1069, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([768], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([805], device='cuda:0') tensor(8.0091e-17, device='cuda:0')
L1: [10277.501]	L2: [40.14988]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=46.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.5% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 326 pred_label: 326 pred_clean_logit 0.9957454800605774
prompt generate:  lycaenid  	labels:  [[326]]
decoder:  [49406, 1251, 772, 524, 1014, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([36], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([326], device='cuda:0') tensor(3.0544e-15, device='cuda:0')
L1: [7246.714]	L2: [33.11091]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.2%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=60.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.3% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 703 pred_label: 706 pred_clean_logit 0.001056979293935001
prompt generate:  park bench  	labels:  [[706]]
decoder:  [49406, 1452, 8771, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([706], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([703], device='cuda:0') tensor(1.1207e-21, device='cuda:0')
L1: [9356.239]	L2: [35.0993]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 533 pred_label: 533 pred_clean_logit 0.9999505281448364
prompt generate:  dishrag  	labels:  [[533]]
decoder:  [49406, 11039, 20687, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([824], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([533], device='cuda:0') tensor(1.0937e-15, device='cuda:0')
L1: [9840.578]	L2: [41.67348]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.8%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.0%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 847 pred_label: 847 pred_clean_logit 0.9997543692588806
prompt generate:  tank  	labels:  [[847]]
decoder:  [49406, 6172, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([586], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([847], device='cuda:0') tensor(5.3360e-17, device='cuda:0')
L1: [9405.816]	L2: [33.235565]	Linf: [0.63529414]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 311 pred_label: 311 pred_clean_logit 0.9828616380691528
prompt generate:  grasshopper  	labels:  [[311]]
decoder:  [49406, 48894, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([312], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([311], device='cuda:0') tensor(9.6523e-14, device='cuda:0')
L1: [8129.016]	L2: [31.954489]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=58.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.8% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 923 pred_label: 124 pred_clean_logit 0.11381392180919647
prompt generate:  plate  	labels:  [[124]]
decoder:  [49406, 5135, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([947], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([923], device='cuda:0') tensor(1.8971e-20, device='cuda:0')
L1: [10179.015]	L2: [38.725197]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 948 pred_label: 948 pred_clean_logit 0.6165761351585388
prompt generate:  Granny Smith  	labels:  [[948]]
decoder:  [49406, 22710, 2915, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([988], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([948], device='cuda:0') tensor(1.3789e-18, device='cuda:0')
L1: [17695.424]	L2: [59.76731]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=28.1%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 385 pred_label: 101 pred_clean_logit 0.1479695737361908
prompt generate:  Indian elephant  	labels:  [[101]]
decoder:  [49406, 3606, 10299, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([349], device='cuda:0') tensor(0.8643, device='cuda:0')
after_true: tensor([385], device='cuda:0') tensor(6.3396e-23, device='cuda:0')
L1: [11439.022]	L2: [43.37184]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 915 pred_label: 915 pred_clean_logit 1.0
prompt generate:  yurt  	labels:  [[915]]
decoder:  [49406, 88, 24309, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([915], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([915], device='cuda:0') tensor(1., device='cuda:0')
L1: [6224.252]	L2: [24.477068]	Linf: [0.65882355]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.8%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=25.6%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 768 pred_label: 768 pred_clean_logit 0.7848653793334961
prompt generate:  rugby ball  	labels:  [[768]]
decoder:  [49406, 4964, 1069, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([981], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([768], device='cuda:0') tensor(1.2098e-09, device='cuda:0')
L1: [7986.47]	L2: [30.575745]	Linf: [0.9490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.4%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 687 pred_label: 687 pred_clean_logit 0.999998927116394
prompt generate:  organ  	labels:  [[687]]
decoder:  [49406, 13213, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([687], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([687], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [8530.06]	L2: [33.22696]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=7.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.5%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.7%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=22.7%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=46.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.0% (timestep 4)
Min contribution: 7.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 979 pred_label: 979 pred_clean_logit 0.992219090461731
prompt generate:  valley  	labels:  [[979]]
decoder:  [49406, 3136, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([975], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([979], device='cuda:0') tensor(3.0119e-15, device='cuda:0')
L1: [10420.373]	L2: [38.343315]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 884 pred_label: 884 pred_clean_logit 0.9838377833366394
prompt generate:  vault  	labels:  [[884]]
decoder:  [49406, 15240, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([588], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([884], device='cuda:0') tensor(3.5296e-18, device='cuda:0')
L1: [5836.6787]	L2: [20.615429]	Linf: [0.5254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 572 pred_label: 478 pred_clean_logit 0.00017374652088619769
prompt generate:  goblet  	labels:  [[478]]
decoder:  [49406, 29559, 1094, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([478], device='cuda:0') tensor(0.9351, device='cuda:0')
after_true: tensor([572], device='cuda:0') tensor(3.4177e-07, device='cuda:0')
L1: [454.76074]	L2: [8.278447]	Linf: [0.50196075]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=14.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=20.5%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=20.1%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=37.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 37.9% (timestep 4)
Min contribution: 6.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 805 pred_label: 805 pred_clean_logit 0.9868813753128052
prompt generate:  soccer ball  	labels:  [[805]]
decoder:  [49406, 4233, 1069, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([843], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([805], device='cuda:0') tensor(4.7688e-28, device='cuda:0')
L1: [9993.474]	L2: [35.894287]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 663 pred_label: 663 pred_clean_logit 0.9325855374336243
prompt generate:  monastery  	labels:  [[663]]
decoder:  [49406, 21850, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([497], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([663], device='cuda:0') tensor(1.0412e-13, device='cuda:0')
L1: [9246.389]	L2: [37.4015]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=47.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.3% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 779 pred_label: 779 pred_clean_logit 0.9999645948410034
prompt generate:  school bus  	labels:  [[779]]
decoder:  [49406, 1228, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([779], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([779], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5265.29]	L2: [22.070335]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.4%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=24.8%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 959 pred_label: 959 pred_clean_logit 0.9839047789573669
prompt generate:  carbonara  	labels:  [[959]]
decoder:  [49406, 14038, 3340, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([659], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([959], device='cuda:0') tensor(1.4066e-15, device='cuda:0')
L1: [12037.718]	L2: [48.99062]	Linf: [0.8745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 908 pred_label: 475 pred_clean_logit 0.000902454077731818
prompt generate:  wing  	labels:  [[475]]
decoder:  [49406, 1340, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([475], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([908], device='cuda:0') tensor(1.1813e-14, device='cuda:0')
L1: [3014.7764]	L2: [10.843405]	Linf: [0.28235292]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=58.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.4% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 599 pred_label: 599 pred_clean_logit 0.9998639822006226
prompt generate:  honeycomb  	labels:  [[599]]
decoder:  [49406, 48583, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([599], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([599], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [2718.8396]	L2: [10.155356]	Linf: [0.33333334]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=7.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.0%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.7%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=21.3%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 7.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 132 pred_label: 132 pred_clean_logit 0.6876798868179321
prompt generate:  American egret  	labels:  [[132]]
decoder:  [49406, 2151, 42002, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([144], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([132], device='cuda:0') tensor(1.6494e-21, device='cuda:0')
L1: [6680.792]	L2: [29.016224]	Linf: [0.8156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000011, Std=0.000005, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 895 pred_label: 895 pred_clean_logit 0.5041800737380981
prompt generate:  warplane  	labels:  [[895]]
decoder:  [49406, 984, 5363, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([744], device='cuda:0') tensor(0.9908, device='cuda:0')
after_true: tensor([895], device='cuda:0') tensor(2.1657e-12, device='cuda:0')
L1: [3243.706]	L2: [15.567028]	Linf: [0.6117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 421 pred_label: 904 pred_clean_logit 0.028392525389790535
prompt generate:  bannister  	labels:  [[904]]
decoder:  [49406, 1159, 36640, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([900], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([421], device='cuda:0') tensor(1.1730e-22, device='cuda:0')
L1: [4012.2002]	L2: [16.652441]	Linf: [0.56078434]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 979 pred_label: 979 pred_clean_logit 0.2783050835132599
prompt generate:  valley  	labels:  [[979]]
decoder:  [49406, 3136, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([43], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([979], device='cuda:0') tensor(1.4950e-18, device='cuda:0')
L1: [11489.923]	L2: [39.311123]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000009, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000019, Std=0.000004, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 1.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 327 pred_label: 327 pred_clean_logit 0.9997052550315857
prompt generate:  starfish  	labels:  [[327]]
decoder:  [49406, 44283, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([112], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([327], device='cuda:0') tensor(1.0639e-19, device='cuda:0')
L1: [6308.4473]	L2: [27.025639]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 696 pred_label: 420 pred_clean_logit 0.3145133852958679
prompt generate:  paintbrush  	labels:  [[420]]
decoder:  [49406, 7948, 8594, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([420], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([696], device='cuda:0') tensor(3.1038e-39, device='cuda:0')
L1: [4944.8076]	L2: [19.30262]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=24.6%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 675 pred_label: 675 pred_clean_logit 0.9976876974105835
prompt generate:  moving van  	labels:  [[675]]
decoder:  [49406, 3584, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([757], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([675], device='cuda:0') tensor(5.1338e-17, device='cuda:0')
L1: [6152.3174]	L2: [25.085018]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 637 pred_label: 672 pred_clean_logit 0.030851498246192932
prompt generate:  mailbox  	labels:  [[672]]
decoder:  [49406, 31482, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([704], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([637], device='cuda:0') tensor(1.2945e-16, device='cuda:0')
L1: [9722.84]	L2: [39.673286]	Linf: [0.8784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000015, Std=0.000003, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 789 pred_label: 789 pred_clean_logit 0.9862051606178284
prompt generate:  shoji  	labels:  [[789]]
decoder:  [49406, 719, 2697, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([918], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([789], device='cuda:0') tensor(2.4735e-23, device='cuda:0')
L1: [6872.768]	L2: [25.309204]	Linf: [0.4509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=46.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.4% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 741 pred_label: 492 pred_clean_logit 0.01284546684473753
prompt generate:  prayer rug  	labels:  [[492]]
decoder:  [49406, 6583, 19220, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([496], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([741], device='cuda:0') tensor(1.0727e-23, device='cuda:0')
L1: [18145.586]	L2: [60.759594]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 821 pred_label: 821 pred_clean_logit 0.9921053647994995
prompt generate:  steel arch bridge  	labels:  [[821]]
decoder:  [49406, 4726, 8557, 2465, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([701], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([821], device='cuda:0') tensor(5.4563e-15, device='cuda:0')
L1: [4533.561]	L2: [22.393219]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=11.8%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=23.8%
Timestep  4: Avg Loss=0.000012, Std=0.000005, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 920 pred_label: 844 pred_clean_logit 0.025535937398672104
prompt generate:  traffic light  	labels:  [[844]]
decoder:  [49406, 3399, 1395, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([844], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([920], device='cuda:0') tensor(4.7559e-08, device='cuda:0')
L1: [3510.5605]	L2: [16.456005]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=9.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000003, Std=0.000002, Contribution=44.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.4% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 705 pred_label: 705 pred_clean_logit 0.6326198577880859
prompt generate:  passenger car  	labels:  [[705]]
decoder:  [49406, 12311, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([757], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([705], device='cuda:0') tensor(1.9616e-14, device='cuda:0')
L1: [5492.3804]	L2: [25.657566]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 779 pred_label: 779 pred_clean_logit 0.999976396560669
prompt generate:  school bus  	labels:  [[779]]
decoder:  [49406, 1228, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([874], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([779], device='cuda:0') tensor(6.9134e-09, device='cuda:0')
L1: [6228.1255]	L2: [23.701843]	Linf: [0.52156866]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 861 pred_label: 861 pred_clean_logit 0.9999635219573975
prompt generate:  toilet seat  	labels:  [[861]]
decoder:  [49406, 11071, 4922, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([876], device='cuda:0') tensor(0.8749, device='cuda:0')
after_true: tensor([861], device='cuda:0') tensor(5.3934e-11, device='cuda:0')
L1: [4718.098]	L2: [18.303144]	Linf: [0.48235297]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=10.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=12.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.5%
Timestep  3: Avg Loss=0.000002, Std=0.000002, Contribution=21.6%
Timestep  4: Avg Loss=0.000004, Std=0.000003, Contribution=40.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 40.1% (timestep 4)
Min contribution: 10.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 511 pred_label: 817 pred_clean_logit 0.22803382575511932
prompt generate:  convertible  	labels:  [[817]]
decoder:  [49406, 19608, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([751], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([511], device='cuda:0') tensor(8.1148e-14, device='cuda:0')
L1: [4399.6978]	L2: [25.204538]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.4%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=47.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.5% (timestep 4)
Min contribution: 6.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 150 pred_label: 150 pred_clean_logit 0.9671045541763306
prompt generate:  sea lion  	labels:  [[150]]
decoder:  [49406, 2102, 5567, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([63], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([150], device='cuda:0') tensor(1.1670e-19, device='cuda:0')
L1: [5633.427]	L2: [23.687931]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=57.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.9% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 603 pred_label: 603 pred_clean_logit 0.9999992847442627
prompt generate:  horse cart  	labels:  [[603]]
decoder:  [49406, 4558, 13065, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([603], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([603], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7035.4756]	L2: [29.233936]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.2%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.1%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 954 pred_label: 954 pred_clean_logit 0.6939844489097595
prompt generate:  banana  	labels:  [[954]]
decoder:  [49406, 8922, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([618], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([954], device='cuda:0') tensor(4.6001e-15, device='cuda:0')
L1: [5552.7256]	L2: [28.447372]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 820 pred_label: 820 pred_clean_logit 0.9999632835388184
prompt generate:  steam locomotive  	labels:  [[820]]
decoder:  [49406, 6972, 30439, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([895], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([820], device='cuda:0') tensor(1.2549e-12, device='cuda:0')
L1: [4622.835]	L2: [20.012867]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.6% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 293 pred_label: 293 pred_clean_logit 0.9996901750564575
prompt generate:  cheetah  	labels:  [[293]]
decoder:  [49406, 27431, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([288], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([293], device='cuda:0') tensor(5.9323e-09, device='cuda:0')
L1: [14290.379]	L2: [49.64053]	Linf: [0.72156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 707 pred_label: 707 pred_clean_logit 0.9771887063980103
prompt generate:  pay-phone  	labels:  [[707]]
decoder:  [49406, 3345, 268, 1951, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([480], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([707], device='cuda:0') tensor(2.5618e-12, device='cuda:0')
L1: [6744.4116]	L2: [27.394583]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=43.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.9% (timestep 4)
Min contribution: 6.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 630 pred_label: 630 pred_clean_logit 0.9936056137084961
prompt generate:  Loafer  	labels:  [[630]]
decoder:  [49406, 26467, 528, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([413], device='cuda:0') tensor(0.9084, device='cuda:0')
after_true: tensor([630], device='cuda:0') tensor(1.4598e-13, device='cuda:0')
L1: [4082.5176]	L2: [16.14044]	Linf: [0.59607846]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=57.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.4% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 468 pred_label: 656 pred_clean_logit 0.48606282472610474
prompt generate:  cab  	labels:  [[656]]
decoder:  [49406, 11912, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([656], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([468], device='cuda:0') tensor(4.0943e-16, device='cuda:0')
L1: [9895.095]	L2: [39.277973]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=27.3%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=44.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.9% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 331 pred_label: 331 pred_clean_logit 0.9772195219993591
prompt generate:  hare  	labels:  [[331]]
decoder:  [49406, 18464, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([216], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([331], device='cuda:0') tensor(9.6162e-20, device='cuda:0')
L1: [4952.2744]	L2: [18.392334]	Linf: [0.49411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000012, Std=0.000005, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 99 pred_label: 130 pred_clean_logit 0.08163087069988251
prompt generate:  goose  	labels:  [[130]]
decoder:  [49406, 13822, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([130], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([99], device='cuda:0') tensor(4.9059e-18, device='cuda:0')
L1: [9205.93]	L2: [35.390564]	Linf: [0.8156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 736 pred_label: 642 pred_clean_logit 0.005423789843916893
prompt generate:  pool table  	labels:  [[642]]
decoder:  [49406, 2831, 2175, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([642], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([736], device='cuda:0') tensor(7.0010e-28, device='cuda:0')
L1: [7328.5254]	L2: [31.367867]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 514 pred_label: 514 pred_clean_logit 0.867717981338501
prompt generate:  cowboy boot  	labels:  [[514]]
decoder:  [49406, 13657, 8087, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([792], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([514], device='cuda:0') tensor(6.9202e-23, device='cuda:0')
L1: [5230.259]	L2: [19.845564]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=55.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.8% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 652 pred_label: 819 pred_clean_logit 0.13466507196426392
prompt generate:  military uniform  	labels:  [[819]]
decoder:  [49406, 4323, 11075, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([627], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([652], device='cuda:0') tensor(1.9586e-14, device='cuda:0')
L1: [5571.388]	L2: [26.221725]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 972 pred_label: 972 pred_clean_logit 0.933601975440979
prompt generate:  cliff  	labels:  [[972]]
decoder:  [49406, 10625, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([483], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([972], device='cuda:0') tensor(1.8687e-08, device='cuda:0')
L1: [4853.0312]	L2: [24.722607]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.3%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=61.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 61.8% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 391 pred_label: 391 pred_clean_logit 0.7406815886497498
prompt generate:  coho  	labels:  [[391]]
decoder:  [49406, 622, 2971, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([4], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([391], device='cuda:0') tensor(5.6389e-20, device='cuda:0')
L1: [3794.275]	L2: [14.56785]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=13.9%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=26.8%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 847 pred_label: 847 pred_clean_logit 0.5072548389434814
prompt generate:  tank  	labels:  [[847]]
decoder:  [49406, 6172, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([575], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([847], device='cuda:0') tensor(4.0631e-29, device='cuda:0')
L1: [10622.493]	L2: [38.326244]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.9%
Timestep  4: Avg Loss=0.000014, Std=0.000003, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 595 pred_label: 595 pred_clean_logit 0.8919341564178467
prompt generate:  harvester  	labels:  [[595]]
decoder:  [49406, 6405, 881, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([428], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([595], device='cuda:0') tensor(2.9809e-21, device='cuda:0')
L1: [6019.5723]	L2: [27.777815]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.5% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 132 pred_label: 132 pred_clean_logit 0.7530587911605835
prompt generate:  American egret  	labels:  [[132]]
decoder:  [49406, 2151, 42002, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([140], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([132], device='cuda:0') tensor(8.7594e-13, device='cuda:0')
L1: [5401.4004]	L2: [21.172039]	Linf: [0.6588235]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 492 pred_label: 492 pred_clean_logit 0.9999997615814209
prompt generate:  chest  	labels:  [[492]]
decoder:  [49406, 10563, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([492], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([492], device='cuda:0') tensor(1., device='cuda:0')
L1: [10071.711]	L2: [38.700535]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.3%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.0%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=22.9%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=46.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.8% (timestep 4)
Min contribution: 6.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 917 pred_label: 921 pred_clean_logit 0.27635592222213745
prompt generate:  comic book  	labels:  [[921]]
decoder:  [49406, 4962, 1116, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([611], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([917], device='cuda:0') tensor(8.6045e-19, device='cuda:0')
L1: [19216.67]	L2: [71.24517]	Linf: [0.9647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=13.9%
Timestep  3: Avg Loss=0.000010, Std=0.000004, Contribution=28.6%
Timestep  4: Avg Loss=0.000017, Std=0.000006, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 81 pred_label: 81 pred_clean_logit 0.9998487234115601
prompt generate:  ptarmigan  	labels:  [[81]]
decoder:  [49406, 79, 2002, 714, 1670, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([86], device='cuda:0') tensor(0.9980, device='cuda:0')
after_true: tensor([81], device='cuda:0') tensor(1.0851e-19, device='cuda:0')
L1: [15200.81]	L2: [53.09998]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=25.0%
Timestep  4: Avg Loss=0.000012, Std=0.000005, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 763 pred_label: 763 pred_clean_logit 0.9999973773956299
prompt generate:  revolver  	labels:  [[763]]
decoder:  [49406, 38747, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([764], device='cuda:0') tensor(0.5416, device='cuda:0')
after_true: tensor([763], device='cuda:0') tensor(3.7525e-05, device='cuda:0')
L1: [3941.8396]	L2: [17.8339]	Linf: [0.6]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.7%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.2%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 50 pred_label: 50 pred_clean_logit 0.9881885647773743
prompt generate:  American alligator  	labels:  [[50]]
decoder:  [49406, 2151, 28574, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([49], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([50], device='cuda:0') tensor(7.6385e-14, device='cuda:0')
L1: [13829.218]	L2: [46.507225]	Linf: [0.654902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000010, Std=0.000002, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 970 pred_label: 970 pred_clean_logit 0.48951083421707153
prompt generate:  alp  	labels:  [[970]]
decoder:  [49406, 39342, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([459], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([970], device='cuda:0') tensor(9.1041e-18, device='cuda:0')
L1: [3318.2395]	L2: [13.911898]	Linf: [0.572549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=60.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.5% (timestep 4)
Min contribution: 1.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 113 pred_label: 113 pred_clean_logit 0.9999996423721313
prompt generate:  snail  	labels:  [[113]]
decoder:  [49406, 23132, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([113], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([113], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6764.4277]	L2: [26.900707]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.5%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.6%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=48.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.8% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 973 pred_label: 33 pred_clean_logit 0.015518898144364357
prompt generate:  coral reef  	labels:  [[33]]
decoder:  [49406, 12054, 15624, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([299], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([973], device='cuda:0') tensor(3.1310e-17, device='cuda:0')
L1: [7227.855]	L2: [25.28717]	Linf: [0.43921566]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 850 pred_label: 850 pred_clean_logit 0.9103261232376099
prompt generate:  teddy  	labels:  [[850]]
decoder:  [49406, 11798, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([154], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([850], device='cuda:0') tensor(5.8934e-20, device='cuda:0')
L1: [5378.0903]	L2: [20.015486]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=11.5%
Timestep  3: Avg Loss=0.000011, Std=0.000003, Contribution=26.0%
Timestep  4: Avg Loss=0.000023, Std=0.000007, Contribution=56.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.5% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 1 pred_label: 1 pred_clean_logit 0.9878992438316345
prompt generate:  goldfish  	labels:  [[1]]
decoder:  [49406, 40293, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([33], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([1], device='cuda:0') tensor(1.1839e-16, device='cuda:0')
L1: [8997.329]	L2: [32.347088]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 978 pred_label: 978 pred_clean_logit 0.8638083338737488
prompt generate:  seashore  	labels:  [[978]]
decoder:  [49406, 567, 31194, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([975], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([978], device='cuda:0') tensor(3.2814e-12, device='cuda:0')
L1: [3979.8394]	L2: [19.479038]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.4%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 132 pred_label: 132 pred_clean_logit 0.9952736496925354
prompt generate:  American egret  	labels:  [[132]]
decoder:  [49406, 2151, 42002, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([131], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([132], device='cuda:0') tensor(3.5804e-09, device='cuda:0')
L1: [3891.0273]	L2: [16.895086]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=22.1%
Timestep  4: Avg Loss=0.000006, Std=0.000004, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 335 pred_label: 335 pred_clean_logit 0.9996229410171509
prompt generate:  fox squirrel  	labels:  [[335]]
decoder:  [49406, 3240, 14004, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([811], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([335], device='cuda:0') tensor(1.6843e-16, device='cuda:0')
L1: [3985.7454]	L2: [15.289312]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.6%
Timestep  4: Avg Loss=0.000010, Std=0.000005, Contribution=57.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.8% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 143 pred_label: 143 pred_clean_logit 0.9998998641967773
prompt generate:  oystercatcher  	labels:  [[143]]
decoder:  [49406, 40545, 15965, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([143], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([143], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3076.4944]	L2: [13.166059]	Linf: [0.61176467]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.8%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 921 pred_label: 921 pred_clean_logit 0.9422560930252075
prompt generate:  book jacket  	labels:  [[921]]
decoder:  [49406, 1116, 6164, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([709], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([921], device='cuda:0') tensor(1.8558e-26, device='cuda:0')
L1: [8348.525]	L2: [34.138058]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 562 pred_label: 562 pred_clean_logit 0.999990701675415
prompt generate:  fountain  	labels:  [[562]]
decoder:  [49406, 13405, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([855], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([562], device='cuda:0') tensor(6.1602e-31, device='cuda:0')
L1: [11827.091]	L2: [49.774902]	Linf: [0.95686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=14.1%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.8%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 321 pred_label: 321 pred_clean_logit 0.9999843835830688
prompt generate:  admiral  	labels:  [[321]]
decoder:  [49406, 21013, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([322], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([321], device='cuda:0') tensor(1.6917e-09, device='cuda:0')
L1: [7590.1846]	L2: [29.763418]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 879 pred_label: 879 pred_clean_logit 1.0
prompt generate:  umbrella  	labels:  [[879]]
decoder:  [49406, 17143, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
L1: [3876.7805]	L2: [15.9803505]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.5%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 303 pred_label: 303 pred_clean_logit 0.998391330242157
prompt generate:  long-horned beetle  	labels:  [[303]]
decoder:  [49406, 1538, 268, 34526, 16534, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([302], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([303], device='cuda:0') tensor(4.9000e-12, device='cuda:0')
L1: [5256.459]	L2: [20.275812]	Linf: [0.65882355]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 355 pred_label: 355 pred_clean_logit 0.9999997615814209
prompt generate:  llama  	labels:  [[355]]
decoder:  [49406, 36679, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([348], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([355], device='cuda:0') tensor(3.0735e-19, device='cuda:0')
L1: [6402.012]	L2: [22.861092]	Linf: [0.5372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 436 pred_label: 734 pred_clean_logit 0.20202402770519257
prompt generate:  beach wagon  	labels:  [[734]]
decoder:  [49406, 2117, 13260, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([734], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([436], device='cuda:0') tensor(5.6134e-19, device='cuda:0')
L1: [7998.2476]	L2: [31.309734]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=7.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=44.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.8% (timestep 4)
Min contribution: 7.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 99 pred_label: 99 pred_clean_logit 0.6791041493415833
prompt generate:  goose  	labels:  [[99]]
decoder:  [49406, 13822, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([99], device='cuda:0') tensor(4.3527e-14, device='cuda:0')
L1: [9057.368]	L2: [32.75876]	Linf: [0.6117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 919 pred_label: 919 pred_clean_logit 0.9829590320587158
prompt generate:  street sign  	labels:  [[919]]
decoder:  [49406, 2012, 2292, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([491], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([919], device='cuda:0') tensor(1.5366e-12, device='cuda:0')
L1: [7334.2354]	L2: [29.2716]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 283 pred_label: 283 pred_clean_logit 0.999998927116394
prompt generate:  Persian cat  	labels:  [[283]]
decoder:  [49406, 19859, 2368, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([283], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([283], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6433.659]	L2: [21.958334]	Linf: [0.35686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=13.4%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.2%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 541 pred_label: 541 pred_clean_logit 0.9958629608154297
prompt generate:  drum  	labels:  [[541]]
decoder:  [49406, 8698, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([401], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([541], device='cuda:0') tensor(3.4290e-42, device='cuda:0')
L1: [14487.098]	L2: [52.876858]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 317 pred_label: 317 pred_clean_logit 0.9621515870094299
prompt generate:  leafhopper  	labels:  [[317]]
decoder:  [49406, 9377, 21748, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([312], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([317], device='cuda:0') tensor(5.2052e-19, device='cuda:0')
L1: [7318.914]	L2: [26.97989]	Linf: [0.5803922]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=58.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.5% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 754 pred_label: 754 pred_clean_logit 0.9735011458396912
prompt generate:  radio  	labels:  [[754]]
decoder:  [49406, 2638, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([662], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([754], device='cuda:0') tensor(1.4805e-12, device='cuda:0')
L1: [10289.607]	L2: [39.216305]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 404 pred_label: 404 pred_clean_logit 0.7148678302764893
prompt generate:  airliner  	labels:  [[404]]
decoder:  [49406, 1281, 11618, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([657], device='cuda:0') tensor(0.9853, device='cuda:0')
after_true: tensor([404], device='cuda:0') tensor(1.7930e-14, device='cuda:0')
L1: [5547.7144]	L2: [25.2925]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 537 pred_label: 537 pred_clean_logit 0.9617815017700195
prompt generate:  dogsled  	labels:  [[537]]
decoder:  [49406, 4326, 28438, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([830], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([537], device='cuda:0') tensor(1.2321e-25, device='cuda:0')
L1: [8550.604]	L2: [32.425728]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.7%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 830 pred_label: 830 pred_clean_logit 0.9945694804191589
prompt generate:  stretcher  	labels:  [[830]]
decoder:  [49406, 12265, 3466, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([424], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([830], device='cuda:0') tensor(2.3143e-21, device='cuda:0')
L1: [10771.121]	L2: [42.26086]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=26.8%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 308 pred_label: 308 pred_clean_logit 0.9999985694885254
prompt generate:  fly  	labels:  [[308]]
decoder:  [49406, 3228, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([308], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([308], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6120.3447]	L2: [23.708323]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 931 pred_label: 931 pred_clean_logit 0.9999984502792358
prompt generate:  bagel  	labels:  [[931]]
decoder:  [49406, 28777, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([932], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([931], device='cuda:0') tensor(1.6401e-15, device='cuda:0')
L1: [7540.8315]	L2: [27.91051]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=57.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.1% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 489 pred_label: 489 pred_clean_logit 0.4623035490512848
prompt generate:  chainlink fence  	labels:  [[489]]
decoder:  [49406, 13898, 2468, 12679, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([408], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([489], device='cuda:0') tensor(1.4440e-16, device='cuda:0')
L1: [8419.035]	L2: [39.073215]	Linf: [0.8666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 406 pred_label: 884 pred_clean_logit 0.3160266876220703
prompt generate:  altar  	labels:  [[884]]
decoder:  [49406, 16385, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([619], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([406], device='cuda:0') tensor(3.6074e-23, device='cuda:0')
L1: [8641.848]	L2: [31.917145]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.0%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000019, Std=0.000005, Contribution=59.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.3% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 597 pred_label: 597 pred_clean_logit 0.5692209601402283
prompt generate:  holster  	labels:  [[597]]
decoder:  [49406, 1187, 881, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([491], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([597], device='cuda:0') tensor(9.2636e-31, device='cuda:0')
L1: [10072.388]	L2: [38.566097]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 919 pred_label: 919 pred_clean_logit 1.0
prompt generate:  street sign  	labels:  [[919]]
decoder:  [49406, 2012, 2292, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([919], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([919], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6809.667]	L2: [28.201298]	Linf: [0.69803923]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.9%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 799 pred_label: 799 pred_clean_logit 0.7673892378807068
prompt generate:  sliding door  	labels:  [[799]]
decoder:  [49406, 21468, 2489, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([905], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([799], device='cuda:0') tensor(2.2289e-13, device='cuda:0')
L1: [6016.6904]	L2: [23.776592]	Linf: [0.572549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 944 pred_label: 944 pred_clean_logit 0.979377269744873
prompt generate:  artichoke  	labels:  [[944]]
decoder:  [49406, 39647, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([936], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([944], device='cuda:0') tensor(3.4885e-14, device='cuda:0')
L1: [11540.1455]	L2: [41.900883]	Linf: [0.8745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 97 pred_label: 97 pred_clean_logit 0.9999605417251587
prompt generate:  drake  	labels:  [[97]]
decoder:  [49406, 8958, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([148], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([97], device='cuda:0') tensor(7.7923e-08, device='cuda:0')
L1: [7924.428]	L2: [28.845577]	Linf: [0.4901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 959 pred_label: 937 pred_clean_logit 0.0006518891896121204
prompt generate:  carbonara  	labels:  [[937]]
decoder:  [49406, 14038, 3340, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([937], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([959], device='cuda:0') tensor(3.0271e-35, device='cuda:0')
L1: [7953.0474]	L2: [30.084848]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 541 pred_label: 859 pred_clean_logit 0.08317650109529495
prompt generate:  drum  	labels:  [[859]]
decoder:  [49406, 8698, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([859], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([541], device='cuda:0') tensor(4.1122e-36, device='cuda:0')
L1: [10069.934]	L2: [41.39638]	Linf: [0.9137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 900 pred_label: 900 pred_clean_logit 0.9999905824661255
prompt generate:  water tower  	labels:  [[900]]
decoder:  [49406, 1573, 4730, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([602], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([900], device='cuda:0') tensor(4.0730e-17, device='cuda:0')
L1: [6653.6587]	L2: [28.618172]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=14.0%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=26.0%
Timestep  4: Avg Loss=0.000010, Std=0.000005, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 865 pred_label: 865 pred_clean_logit 0.9740009903907776
prompt generate:  toyshop  	labels:  [[865]]
decoder:  [49406, 14387, 1557, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([859], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([865], device='cuda:0') tensor(1.4359e-35, device='cuda:0')
L1: [12611.973]	L2: [51.452816]	Linf: [0.9764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=15.0%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=27.4%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=47.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.8% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 33 pred_label: 33 pred_clean_logit 0.9927560687065125
prompt generate:  loggerhead  	labels:  [[33]]
decoder:  [49406, 549, 12367, 1375, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([34], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([33], device='cuda:0') tensor(6.7410e-09, device='cuda:0')
L1: [5161.3447]	L2: [19.149519]	Linf: [0.47058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 146 pred_label: 146 pred_clean_logit 0.9954948425292969
prompt generate:  albatross  	labels:  [[146]]
decoder:  [49406, 42797, 2158, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([143], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([146], device='cuda:0') tensor(1.0744e-09, device='cuda:0')
L1: [6953.604]	L2: [27.854073]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=47.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.7% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 661 pred_label: 609 pred_clean_logit 0.4493834376335144
prompt generate:  Model T  	labels:  [[609]]
decoder:  [49406, 2863, 339, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([609], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([661], device='cuda:0') tensor(4.1826e-27, device='cuda:0')
L1: [9621.354]	L2: [37.514664]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=48.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.2% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 995 pred_label: 954 pred_clean_logit 0.003298370400443673
prompt generate:  earthstar  	labels:  [[954]]
decoder:  [49406, 5184, 1565, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([954], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([995], device='cuda:0') tensor(1.0690e-34, device='cuda:0')
L1: [9689.427]	L2: [35.133987]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=48.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.9% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 32 pred_label: 32 pred_clean_logit 0.9967165589332581
prompt generate:  tailed frog  	labels:  [[32]]
decoder:  [49406, 20626, 11438, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([30], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([32], device='cuda:0') tensor(1.3196e-09, device='cuda:0')
L1: [5423.4355]	L2: [28.08794]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.0%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=55.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.8% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 718 pred_label: 718 pred_clean_logit 0.9997300505638123
prompt generate:  pier  	labels:  [[718]]
decoder:  [49406, 11348, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([525], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([718], device='cuda:0') tensor(1.2186e-13, device='cuda:0')
L1: [3784.1997]	L2: [18.98076]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 107 pred_label: 107 pred_clean_logit 0.887060821056366
prompt generate:  jellyfish  	labels:  [[107]]
decoder:  [49406, 30988, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([459], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([107], device='cuda:0') tensor(8.5471e-23, device='cuda:0')
L1: [7276.5327]	L2: [25.65793]	Linf: [0.5803922]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.5%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=26.6%
Timestep  4: Avg Loss=0.000018, Std=0.000006, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 679 pred_label: 679 pred_clean_logit 0.9999774694442749
prompt generate:  necklace  	labels:  [[679]]
decoder:  [49406, 7385, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([505], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([679], device='cuda:0') tensor(1.6358e-13, device='cuda:0')
L1: [5630.2354]	L2: [24.475779]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 814 pred_label: 814 pred_clean_logit 0.9997606873512268
prompt generate:  speedboat  	labels:  [[814]]
decoder:  [49406, 6860, 4440, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([466], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([814], device='cuda:0') tensor(8.1628e-10, device='cuda:0')
L1: [3146.7961]	L2: [18.240505]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=12.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=13.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=15.9%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=20.9%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=37.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 37.2% (timestep 4)
Min contribution: 12.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 526 pred_label: 406 pred_clean_logit 0.0047531211748719215
prompt generate:  desk  	labels:  [[406]]
decoder:  [49406, 6550, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([406], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([526], device='cuda:0') tensor(6.3894e-23, device='cuda:0')
L1: [8668.22]	L2: [34.408287]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 1 pred_label: 876 pred_clean_logit 0.00022884794452693313
prompt generate:  goldfish  	labels:  [[876]]
decoder:  [49406, 40293, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([876], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([1], device='cuda:0') tensor(1.6764e-28, device='cuda:0')
L1: [5344.31]	L2: [20.52553]	Linf: [0.5882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 873 pred_label: 873 pred_clean_logit 0.9977003931999207
prompt generate:  triumphal arch  	labels:  [[873]]
decoder:  [49406, 14782, 1037, 8708, 8557, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([847], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([873], device='cuda:0') tensor(1.0567e-15, device='cuda:0')
L1: [6953.0005]	L2: [31.329157]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=58.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.7% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 338 pred_label: 338 pred_clean_logit 0.9999836683273315
prompt generate:  guinea pig  	labels:  [[338]]
decoder:  [49406, 18537, 9619, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([338], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([338], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [4821.722]	L2: [18.318274]	Linf: [0.56078434]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.6%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.8%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.5%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 718 pred_label: 718 pred_clean_logit 0.9980873465538025
prompt generate:  pier  	labels:  [[718]]
decoder:  [49406, 11348, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([525], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([718], device='cuda:0') tensor(4.2109e-19, device='cuda:0')
L1: [9227.815]	L2: [37.767128]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 839 pred_label: 839 pred_clean_logit 0.4390246272087097
prompt generate:  suspension bridge  	labels:  [[839]]
decoder:  [49406, 15417, 2465, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([433], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([839], device='cuda:0') tensor(6.7149e-28, device='cuda:0')
L1: [10106.429]	L2: [39.03393]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 975 pred_label: 975 pred_clean_logit 0.5519164204597473
prompt generate:  lakeside  	labels:  [[975]]
decoder:  [49406, 30915, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([144], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([975], device='cuda:0') tensor(1.5966e-12, device='cuda:0')
L1: [8888.225]	L2: [33.18667]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 396 pred_label: 396 pred_clean_logit 0.9989557266235352
prompt generate:  lionfish  	labels:  [[396]]
decoder:  [49406, 8872, 2759, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([71], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([396], device='cuda:0') tensor(5.4430e-20, device='cuda:0')
L1: [8776.036]	L2: [35.68939]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 884 pred_label: 884 pred_clean_logit 0.9990087151527405
prompt generate:  vault  	labels:  [[884]]
decoder:  [49406, 15240, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([887], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([884], device='cuda:0') tensor(6.0952e-12, device='cuda:0')
L1: [8193.717]	L2: [30.233273]	Linf: [0.59607846]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.4%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=11.0%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=24.4%
Timestep  4: Avg Loss=0.000021, Std=0.000007, Contribution=58.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.5% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 57 pred_label: 57 pred_clean_logit 0.9379867911338806
prompt generate:  garter snake  	labels:  [[57]]
decoder:  [49406, 48420, 8798, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([58], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([57], device='cuda:0') tensor(7.8960e-14, device='cuda:0')
L1: [16660.057]	L2: [56.598915]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=27.6%
Timestep  4: Avg Loss=0.000014, Std=0.000003, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 243 pred_label: 243 pred_clean_logit 0.9999736547470093
prompt generate:  bull mastiff  	labels:  [[243]]
decoder:  [49406, 6029, 42311, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([159], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([243], device='cuda:0') tensor(1.5144e-18, device='cuda:0')
L1: [10500.969]	L2: [36.273468]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 770 pred_label: 770 pred_clean_logit 0.9964955449104309
prompt generate:  running shoe  	labels:  [[770]]
decoder:  [49406, 2761, 7342, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([676], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([770], device='cuda:0') tensor(3.9309e-11, device='cuda:0')
L1: [2915.9377]	L2: [12.702985]	Linf: [0.59607846]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.7%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=56.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.4% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 820 pred_label: 745 pred_clean_logit 0.41332727670669556
prompt generate:  steam locomotive  	labels:  [[745]]
decoder:  [49406, 6972, 30439, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([745], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([820], device='cuda:0') tensor(5.7222e-24, device='cuda:0')
L1: [6959.9297]	L2: [27.916286]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 479 pred_label: 479 pred_clean_logit 0.9981909394264221
prompt generate:  car wheel  	labels:  [[479]]
decoder:  [49406, 1615, 6744, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([501], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([479], device='cuda:0') tensor(3.2099e-17, device='cuda:0')
L1: [3878.3337]	L2: [19.36696]	Linf: [0.5882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 820 pred_label: 820 pred_clean_logit 0.9997398257255554
prompt generate:  steam locomotive  	labels:  [[820]]
decoder:  [49406, 6972, 30439, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([864], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([820], device='cuda:0') tensor(1.3257e-22, device='cuda:0')
L1: [10227.97]	L2: [39.86201]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000005, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000010, Std=0.000002, Contribution=28.2%
Timestep  4: Avg Loss=0.000018, Std=0.000004, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 320 pred_label: 319 pred_clean_logit 0.2723246216773987
prompt generate:  damselfly  	labels:  [[319]]
decoder:  [49406, 1880, 1000, 3228, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([74], device='cuda:0') tensor(0.9992, device='cuda:0')
after_true: tensor([320], device='cuda:0') tensor(3.7903e-12, device='cuda:0')
L1: [6385.2783]	L2: [22.846725]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=27.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 630 pred_label: 630 pred_clean_logit 0.213254913687706
prompt generate:  Loafer  	labels:  [[630]]
decoder:  [49406, 26467, 528, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([491], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([630], device='cuda:0') tensor(2.3472e-28, device='cuda:0')
L1: [3453.5962]	L2: [12.6460705]	Linf: [0.33333334]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=59.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.6% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 113 pred_label: 113 pred_clean_logit 0.9999902248382568
prompt generate:  snail  	labels:  [[113]]
decoder:  [49406, 23132, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([988], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([113], device='cuda:0') tensor(2.0786e-17, device='cuda:0')
L1: [8842.868]	L2: [33.2704]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 873 pred_label: 873 pred_clean_logit 0.9992402791976929
prompt generate:  triumphal arch  	labels:  [[873]]
decoder:  [49406, 14782, 1037, 8708, 8557, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([698], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([873], device='cuda:0') tensor(4.2840e-13, device='cuda:0')
L1: [4858.898]	L2: [22.784412]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=57.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.9% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 429 pred_label: 429 pred_clean_logit 0.9999788999557495
prompt generate:  baseball  	labels:  [[429]]
decoder:  [49406, 3470, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([429], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([429], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3828.071]	L2: [22.012487]	Linf: [0.9490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.7%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.4%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=21.7%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=46.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.4% (timestep 4)
Min contribution: 6.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 970 pred_label: 970 pred_clean_logit 0.999798595905304
prompt generate:  alp  	labels:  [[970]]
decoder:  [49406, 39342, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([979], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([970], device='cuda:0') tensor(3.5356e-09, device='cuda:0')
L1: [6950.8438]	L2: [25.782509]	Linf: [0.59607846]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 967 pred_label: 463 pred_clean_logit 0.09133784472942352
prompt generate:  espresso  	labels:  [[463]]
decoder:  [49406, 17098, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([818], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([967], device='cuda:0') tensor(5.9009e-23, device='cuda:0')
L1: [6480.9883]	L2: [23.03775]	Linf: [0.52549016]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 976 pred_label: 976 pred_clean_logit 0.9949560761451721
prompt generate:  promontory  	labels:  [[976]]
decoder:  [49406, 644, 749, 4214, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([978], device='cuda:0') tensor(0.9975, device='cuda:0')
after_true: tensor([976], device='cuda:0') tensor(4.6367e-08, device='cuda:0')
L1: [6250.718]	L2: [25.236506]	Linf: [0.6117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.8%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.6%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 603 pred_label: 603 pred_clean_logit 0.7516590356826782
prompt generate:  horse cart  	labels:  [[603]]
decoder:  [49406, 4558, 13065, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([690], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([603], device='cuda:0') tensor(1.8232e-11, device='cuda:0')
L1: [7152.5527]	L2: [29.156033]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.4%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 570 pred_label: 570 pred_clean_logit 0.9999947547912598
prompt generate:  gasmask  	labels:  [[570]]
decoder:  [49406, 5047, 8306, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([691], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([570], device='cuda:0') tensor(2.6828e-06, device='cuda:0')
L1: [7085.9966]	L2: [31.371174]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.6%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 853 pred_label: 853 pred_clean_logit 0.999946117401123
prompt generate:  thatch  	labels:  [[853]]
decoder:  [49406, 6303, 634, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([619], device='cuda:0') tensor(0.9995, device='cuda:0')
after_true: tensor([853], device='cuda:0') tensor(3.6931e-16, device='cuda:0')
L1: [5055.411]	L2: [20.791885]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.0%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=61.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 61.7% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 229 pred_label: 229 pred_clean_logit 0.7925835251808167
prompt generate:  Old English sheepdog  	labels:  [[229]]
decoder:  [49406, 896, 3469, 23604, 1929, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([170], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([229], device='cuda:0') tensor(4.3392e-14, device='cuda:0')
L1: [8105.789]	L2: [29.499344]	Linf: [0.5921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 945 pred_label: 945 pred_clean_logit 0.9999370574951172
prompt generate:  bell pepper  	labels:  [[945]]
decoder:  [49406, 3718, 8253, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([747], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([945], device='cuda:0') tensor(2.9126e-22, device='cuda:0')
L1: [4737.1924]	L2: [23.24151]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 319 pred_label: 319 pred_clean_logit 0.9999920129776001
prompt generate:  dragonfly  	labels:  [[319]]
decoder:  [49406, 32824, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([316], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([319], device='cuda:0') tensor(2.1598e-16, device='cuda:0')
L1: [6845.8354]	L2: [28.809387]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 535 pred_label: 573 pred_clean_logit 0.0008028927259147167
prompt generate:  disk brake  	labels:  [[573]]
decoder:  [49406, 17970, 14937, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([573], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([535], device='cuda:0') tensor(1.5233e-16, device='cuda:0')
L1: [5772.569]	L2: [24.171635]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 656 pred_label: 656 pred_clean_logit 0.9991450309753418
prompt generate:  minivan  	labels:  [[656]]
decoder:  [49406, 1810, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([656], device='cuda:0') tensor(3.5353e-17, device='cuda:0')
L1: [5405.1255]	L2: [24.441788]	Linf: [0.5921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=47.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.0% (timestep 4)
Min contribution: 5.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 144 pred_label: 144 pred_clean_logit 0.9851330518722534
prompt generate:  pelican  	labels:  [[144]]
decoder:  [49406, 34131, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([146], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([144], device='cuda:0') tensor(1.1444e-11, device='cuda:0')
L1: [2527.804]	L2: [11.370701]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.3%
Timestep  4: Avg Loss=0.000012, Std=0.000005, Contribution=57.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.0% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 919 pred_label: 919 pred_clean_logit 0.9409171938896179
prompt generate:  street sign  	labels:  [[919]]
decoder:  [49406, 2012, 2292, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([557], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([919], device='cuda:0') tensor(6.7920e-20, device='cuda:0')
L1: [8375.173]	L2: [33.095314]	Linf: [0.8156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 917 pred_label: 917 pred_clean_logit 0.9529033303260803
prompt generate:  comic book  	labels:  [[917]]
decoder:  [49406, 4962, 1116, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([805], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([917], device='cuda:0') tensor(6.2891e-29, device='cuda:0')
L1: [9334.185]	L2: [35.57839]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 883 pred_label: 883 pred_clean_logit 0.3995674252510071
prompt generate:  vase  	labels:  [[883]]
decoder:  [49406, 20431, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([911], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([883], device='cuda:0') tensor(7.9054e-28, device='cuda:0')
L1: [5161.522]	L2: [20.334234]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=56.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.2% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 73 pred_label: 73 pred_clean_logit 0.7488833665847778
prompt generate:  barn spider  	labels:  [[73]]
decoder:  [49406, 10942, 7622, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([74], device='cuda:0') tensor(0.9995, device='cuda:0')
after_true: tensor([73], device='cuda:0') tensor(1.6032e-06, device='cuda:0')
L1: [6747.0703]	L2: [27.058674]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 385 pred_label: 385 pred_clean_logit 0.9989179372787476
prompt generate:  Indian elephant  	labels:  [[385]]
decoder:  [49406, 3606, 10299, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([386], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([385], device='cuda:0') tensor(1.9925e-18, device='cuda:0')
L1: [6029.0273]	L2: [21.21213]	Linf: [0.48627454]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 927 pred_label: 927 pred_clean_logit 0.9303990602493286
prompt generate:  trifle  	labels:  [[927]]
decoder:  [49406, 924, 44964, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([773], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([927], device='cuda:0') tensor(2.4292e-20, device='cuda:0')
L1: [6339.1294]	L2: [23.964787]	Linf: [0.6196078]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.7%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=14.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=46.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.6% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 472 pred_label: 472 pred_clean_logit 0.993735134601593
prompt generate:  canoe  	labels:  [[472]]
decoder:  [49406, 23503, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([625], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([472], device='cuda:0') tensor(1.3061e-24, device='cuda:0')
L1: [7830.2554]	L2: [32.908424]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 746 pred_label: 746 pred_clean_logit 0.9948793649673462
prompt generate:  puck  	labels:  [[746]]
decoder:  [49406, 17550, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([795], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([746], device='cuda:0') tensor(6.3044e-11, device='cuda:0')
L1: [4348.0747]	L2: [22.864191]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 421 pred_label: 818 pred_clean_logit 0.00024304479302372783
prompt generate:  bannister  	labels:  [[818]]
decoder:  [49406, 1159, 36640, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([818], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([421], device='cuda:0') tensor(9.2099e-25, device='cuda:0')
L1: [3136.0237]	L2: [14.48944]	Linf: [0.67450976]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.1%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=50.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.0% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 910 pred_label: 910 pred_clean_logit 0.2607631981372833
prompt generate:  wooden spoon  	labels:  [[910]]
decoder:  [49406, 9057, 14024, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([113], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([910], device='cuda:0') tensor(1.3874e-23, device='cuda:0')
L1: [5165.444]	L2: [21.09923]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.3%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 879 pred_label: 879 pred_clean_logit 0.9999943971633911
prompt generate:  umbrella  	labels:  [[879]]
decoder:  [49406, 17143, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([936], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([879], device='cuda:0') tensor(3.5157e-24, device='cuda:0')
L1: [14476.396]	L2: [49.287086]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.9%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 967 pred_label: 967 pred_clean_logit 0.9998666048049927
prompt generate:  espresso  	labels:  [[967]]
decoder:  [49406, 17098, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([935], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([967], device='cuda:0') tensor(5.8210e-23, device='cuda:0')
L1: [5856.294]	L2: [25.762445]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=13.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 557 pred_label: 775 pred_clean_logit 0.002792698796838522
prompt generate:  flagpole  	labels:  [[775]]
decoder:  [49406, 11536, 8170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([775], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([557], device='cuda:0') tensor(1.2144e-22, device='cuda:0')
L1: [7119.0703]	L2: [36.488773]	Linf: [0.99215686]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 554 pred_label: 718 pred_clean_logit 0.02032981812953949
prompt generate:  fireboat  	labels:  [[718]]
decoder:  [49406, 2951, 4440, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([718], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([554], device='cuda:0') tensor(8.6499e-10, device='cuda:0')
L1: [6499.27]	L2: [28.157602]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 253 pred_label: 253 pred_clean_logit 0.9998292922973633
prompt generate:  basenji  	labels:  [[253]]
decoder:  [49406, 1244, 524, 2697, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([286], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([253], device='cuda:0') tensor(7.0461e-17, device='cuda:0')
L1: [5533.3545]	L2: [21.183958]	Linf: [0.8745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=26.1%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=50.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.0% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 440 pred_label: 440 pred_clean_logit 0.9945927262306213
prompt generate:  beer bottle  	labels:  [[440]]
decoder:  [49406, 2544, 5392, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([631], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([440], device='cuda:0') tensor(5.1012e-30, device='cuda:0')
L1: [10158.691]	L2: [40.834526]	Linf: [0.91764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 987 pred_label: 987 pred_clean_logit 0.8130600452423096
prompt generate:  corn  	labels:  [[987]]
decoder:  [49406, 5894, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([943], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([987], device='cuda:0') tensor(3.7820e-28, device='cuda:0')
L1: [7340.7954]	L2: [28.20017]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 547 pred_label: 547 pred_clean_logit 0.9996097683906555
prompt generate:  electric locomotive  	labels:  [[547]]
decoder:  [49406, 5031, 30439, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([625], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([547], device='cuda:0') tensor(2.1146e-11, device='cuda:0')
L1: [5628.0674]	L2: [24.31872]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.7%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 922 pred_label: 782 pred_clean_logit 0.4194594621658325
prompt generate:  menu  	labels:  [[782]]
decoder:  [49406, 6225, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([782], device='cuda:0') tensor(0.9770, device='cuda:0')
after_true: tensor([922], device='cuda:0') tensor(1.0559e-10, device='cuda:0')
L1: [4415.0034]	L2: [19.118519]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=10.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=12.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.0%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=40.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 40.5% (timestep 4)
Min contribution: 10.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 137 pred_label: 137 pred_clean_logit 0.9923145174980164
prompt generate:  American coot  	labels:  [[137]]
decoder:  [49406, 2151, 1664, 339, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([99], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([137], device='cuda:0') tensor(7.2106e-11, device='cuda:0')
L1: [11187.997]	L2: [39.000443]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 533 pred_label: 533 pred_clean_logit 0.42179757356643677
prompt generate:  dishrag  	labels:  [[533]]
decoder:  [49406, 11039, 20687, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([824], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([533], device='cuda:0') tensor(4.2538e-12, device='cuda:0')
L1: [8827.508]	L2: [38.72643]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.0%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=26.4%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=47.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.7% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 698 pred_label: 698 pred_clean_logit 0.9976786971092224
prompt generate:  palace  	labels:  [[698]]
decoder:  [49406, 6381, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([665], device='cuda:0') tensor(0.9195, device='cuda:0')
after_true: tensor([698], device='cuda:0') tensor(5.0661e-13, device='cuda:0')
L1: [9555.443]	L2: [36.53273]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.4%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=45.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.2% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 487 pred_label: 662 pred_clean_logit 1.2032273843942676e-07
prompt generate:  cellular telephone  	labels:  [[662]]
decoder:  [49406, 23268, 17243, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([662], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([487], device='cuda:0') tensor(3.8042e-24, device='cuda:0')
L1: [5144.7173]	L2: [24.842867]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 990 pred_label: 990 pred_clean_logit 0.9973151087760925
prompt generate:  buckeye  	labels:  [[990]]
decoder:  [49406, 34549, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([118], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([990], device='cuda:0') tensor(1.8424e-22, device='cuda:0')
L1: [8884.009]	L2: [34.321404]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=27.3%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 417 pred_label: 417 pred_clean_logit 0.9999970197677612
prompt generate:  balloon  	labels:  [[417]]
decoder:  [49406, 13634, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([417], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([417], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3392.0862]	L2: [14.41024]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=7.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=16.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.3%
Timestep  4: Avg Loss=0.000002, Std=0.000000, Contribution=41.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.5% (timestep 4)
Min contribution: 7.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 603 pred_label: 603 pred_clean_logit 0.9999796152114868
prompt generate:  horse cart  	labels:  [[603]]
decoder:  [49406, 4558, 13065, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([822], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([603], device='cuda:0') tensor(1.0152e-37, device='cuda:0')
L1: [9475.673]	L2: [34.98191]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 624 pred_label: 624 pred_clean_logit 0.9639179706573486
prompt generate:  library  	labels:  [[624]]
decoder:  [49406, 3519, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([498], device='cuda:0') tensor(0.9995, device='cuda:0')
after_true: tensor([624], device='cuda:0') tensor(1.2499e-23, device='cuda:0')
L1: [6774.321]	L2: [28.402428]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 517 pred_label: 483 pred_clean_logit 0.17049628496170044
prompt generate:  crane  	labels:  [[483]]
decoder:  [49406, 14626, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([731], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([517], device='cuda:0') tensor(2.9487e-30, device='cuda:0')
L1: [8311.479]	L2: [37.285934]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 327 pred_label: 327 pred_clean_logit 0.973945677280426
prompt generate:  starfish  	labels:  [[327]]
decoder:  [49406, 44283, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([112], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([327], device='cuda:0') tensor(5.9942e-12, device='cuda:0')
L1: [4828.596]	L2: [25.211233]	Linf: [0.94509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.1%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 319 pred_label: 319 pred_clean_logit 0.999854326248169
prompt generate:  dragonfly  	labels:  [[319]]
decoder:  [49406, 32824, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([326], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([319], device='cuda:0') tensor(1.8685e-10, device='cuda:0')
L1: [3617.5217]	L2: [16.657146]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.2%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 518 pred_label: 518 pred_clean_logit 0.9996545314788818
prompt generate:  crash helmet  	labels:  [[518]]
decoder:  [49406, 5033, 11122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([746], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([518], device='cuda:0') tensor(2.5879e-12, device='cuda:0')
L1: [7658.126]	L2: [37.390114]	Linf: [0.9411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 386 pred_label: 386 pred_clean_logit 0.9997387528419495
prompt generate:  African elephant  	labels:  [[386]]
decoder:  [49406, 4736, 10299, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([101], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([386], device='cuda:0') tensor(1.2088e-16, device='cuda:0')
L1: [10931.361]	L2: [41.693306]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 404 pred_label: 404 pred_clean_logit 0.999975323677063
prompt generate:  airliner  	labels:  [[404]]
decoder:  [49406, 1281, 11618, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([404], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([404], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2894.059]	L2: [13.960469]	Linf: [0.5921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.5%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=49.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.2% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 749 pred_label: 749 pred_clean_logit 1.0
prompt generate:  quill  	labels:  [[749]]
decoder:  [49406, 48951, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([749], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([749], device='cuda:0') tensor(1., device='cuda:0')
L1: [9579.146]	L2: [32.489548]	Linf: [0.4666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.3%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.1%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=58.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.5% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 415 pred_label: 415 pred_clean_logit 0.998011589050293
prompt generate:  bakery  	labels:  [[415]]
decoder:  [49406, 13377, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([955], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([415], device='cuda:0') tensor(3.7895e-27, device='cuda:0')
L1: [9117.302]	L2: [38.136887]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 569 pred_label: 569 pred_clean_logit 0.988713800907135
prompt generate:  garbage truck  	labels:  [[569]]
decoder:  [49406, 13760, 4629, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([450], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([569], device='cuda:0') tensor(3.4819e-23, device='cuda:0')
L1: [7904.1265]	L2: [33.90769]	Linf: [0.92941177]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 990 pred_label: 990 pred_clean_logit 0.9999728202819824
prompt generate:  buckeye  	labels:  [[990]]
decoder:  [49406, 34549, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([952], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([990], device='cuda:0') tensor(3.8454e-18, device='cuda:0')
L1: [7453.1924]	L2: [31.675901]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 851 pred_label: 851 pred_clean_logit 0.43955257534980774
prompt generate:  television  	labels:  [[851]]
decoder:  [49406, 8608, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([920], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([851], device='cuda:0') tensor(7.0431e-23, device='cuda:0')
L1: [4107.832]	L2: [17.914074]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 9 pred_label: 9 pred_clean_logit 0.9999959468841553
prompt generate:  ostrich  	labels:  [[9]]
decoder:  [49406, 47640, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([355], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([9], device='cuda:0') tensor(1.7171e-19, device='cuda:0')
L1: [7481.804]	L2: [26.329086]	Linf: [0.5803921]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 717 pred_label: 717 pred_clean_logit 0.9997900128364563
prompt generate:  pickup  	labels:  [[717]]
decoder:  [49406, 15382, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([436], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([717], device='cuda:0') tensor(5.8848e-13, device='cuda:0')
L1: [6800.8745]	L2: [25.869883]	Linf: [0.6666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=43.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.8% (timestep 4)
Min contribution: 7.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 347 pred_label: 347 pred_clean_logit 0.999990701675415
prompt generate:  bison  	labels:  [[347]]
decoder:  [49406, 19741, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([294], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([347], device='cuda:0') tensor(7.0395e-18, device='cuda:0')
L1: [5980.0547]	L2: [24.314182]	Linf: [0.5372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 555 pred_label: 555 pred_clean_logit 0.9999994039535522
prompt generate:  fire engine  	labels:  [[555]]
decoder:  [49406, 1769, 5857, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([555], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([555], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [10076.264]	L2: [41.519188]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=10.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.7%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.6%
Timestep  4: Avg Loss=0.000002, Std=0.000000, Contribution=42.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.7% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 817 pred_label: 817 pred_clean_logit 0.9987474679946899
prompt generate:  sports car  	labels:  [[817]]
decoder:  [49406, 2054, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([656], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([817], device='cuda:0') tensor(7.7830e-11, device='cuda:0')
L1: [5521.5415]	L2: [21.028658]	Linf: [0.5960784]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 5.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 865 pred_label: 865 pred_clean_logit 0.9949308037757874
prompt generate:  toyshop  	labels:  [[865]]
decoder:  [49406, 14387, 1557, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([621], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([865], device='cuda:0') tensor(3.3258e-17, device='cuda:0')
L1: [8689.98]	L2: [34.158806]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 411 pred_label: 411 pred_clean_logit 0.9960911870002747
prompt generate:  apron  	labels:  [[411]]
decoder:  [49406, 29502, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([823], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([411], device='cuda:0') tensor(1.4944e-27, device='cuda:0')
L1: [4503.38]	L2: [21.199583]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=48.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.3% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 629 pred_label: 629 pred_clean_logit 0.9999837875366211
prompt generate:  lipstick  	labels:  [[629]]
decoder:  [49406, 15618, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([153], device='cuda:0') tensor(0.9994, device='cuda:0')
after_true: tensor([629], device='cuda:0') tensor(2.9508e-12, device='cuda:0')
L1: [2569.8433]	L2: [8.744263]	Linf: [0.19215685]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=21.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=60.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.3% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 963 pred_label: 963 pred_clean_logit 0.8544861078262329
prompt generate:  pizza  	labels:  [[963]]
decoder:  [49406, 4474, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([941], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([963], device='cuda:0') tensor(1.4740e-15, device='cuda:0')
L1: [13334.725]	L2: [46.021008]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 517 pred_label: 517 pred_clean_logit 0.9979812502861023
prompt generate:  crane  	labels:  [[517]]
decoder:  [49406, 14626, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([744], device='cuda:0') tensor(0.9864, device='cuda:0')
after_true: tensor([517], device='cuda:0') tensor(3.1862e-17, device='cuda:0')
L1: [9959.639]	L2: [39.477657]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 264 pred_label: 264 pred_clean_logit 0.9998538494110107
prompt generate:  Cardigan  	labels:  [[264]]
decoder:  [49406, 30501, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([232], device='cuda:0') tensor(0.9676, device='cuda:0')
after_true: tensor([264], device='cuda:0') tensor(2.4630e-10, device='cuda:0')
L1: [6099.7217]	L2: [22.60088]	Linf: [0.47450984]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=45.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.5% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 895 pred_label: 895 pred_clean_logit 0.45393046736717224
prompt generate:  warplane  	labels:  [[895]]
decoder:  [49406, 984, 5363, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([822], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([895], device='cuda:0') tensor(1.2709e-27, device='cuda:0')
L1: [6066.561]	L2: [28.401043]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 546 pred_label: 546 pred_clean_logit 0.8347919583320618
prompt generate:  electric guitar  	labels:  [[546]]
decoder:  [49406, 5031, 5084, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([402], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([546], device='cuda:0') tensor(1.6727e-08, device='cuda:0')
L1: [6459.5215]	L2: [31.070562]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=42.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.9% (timestep 4)
Min contribution: 8.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 903 pred_label: 903 pred_clean_logit 0.9996589422225952
prompt generate:  wig  	labels:  [[903]]
decoder:  [49406, 12216, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([616], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([903], device='cuda:0') tensor(8.3027e-14, device='cuda:0')
L1: [6769.683]	L2: [25.667896]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.5%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 708 pred_label: 708 pred_clean_logit 0.9963271021842957
prompt generate:  pedestal  	labels:  [[708]]
decoder:  [49406, 12862, 5535, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([863], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([708], device='cuda:0') tensor(1.2291e-25, device='cuda:0')
L1: [12946.546]	L2: [45.54898]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000009, Std=0.000002, Contribution=27.3%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 317 pred_label: 317 pred_clean_logit 0.9999699592590332
prompt generate:  leafhopper  	labels:  [[317]]
decoder:  [49406, 9377, 21748, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([316], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([317], device='cuda:0') tensor(2.1478e-15, device='cuda:0')
L1: [5332.0786]	L2: [21.49541]	Linf: [0.5764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=57.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.4% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 141 pred_label: 141 pred_clean_logit 0.9998247027397156
prompt generate:  redshank  	labels:  [[141]]
decoder:  [49406, 1893, 24685, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([143], device='cuda:0') tensor(0.9939, device='cuda:0')
after_true: tensor([141], device='cuda:0') tensor(9.2835e-07, device='cuda:0')
L1: [3979.3022]	L2: [17.687263]	Linf: [0.5647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=22.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 22 pred_label: 22 pred_clean_logit 0.9998936653137207
prompt generate:  bald eagle  	labels:  [[22]]
decoder:  [49406, 14875, 7517, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([23], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([22], device='cuda:0') tensor(6.5187e-10, device='cuda:0')
L1: [4470.4277]	L2: [17.92841]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 760 pred_label: 760 pred_clean_logit 0.9886598587036133
prompt generate:  refrigerator  	labels:  [[760]]
decoder:  [49406, 36662, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([710], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([760], device='cuda:0') tensor(1.8203e-09, device='cuda:0')
L1: [2674.8904]	L2: [15.39484]	Linf: [0.65098035]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.3%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=48.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.8% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 772 pred_label: 772 pred_clean_logit 0.7453737854957581
prompt generate:  safety pin  	labels:  [[772]]
decoder:  [49406, 3406, 5164, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([769], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([772], device='cuda:0') tensor(9.3552e-23, device='cuda:0')
L1: [10358.462]	L2: [44.391525]	Linf: [0.99607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.1%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=48.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.3% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 978 pred_label: 976 pred_clean_logit 0.37006035447120667
prompt generate:  seashore  	labels:  [[976]]
decoder:  [49406, 567, 31194, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([976], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([978], device='cuda:0') tensor(1.6588e-08, device='cuda:0')
L1: [6900.314]	L2: [30.284033]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 682 pred_label: 682 pred_clean_logit 0.9976577758789062
prompt generate:  obelisk  	labels:  [[682]]
decoder:  [49406, 78, 1308, 30171, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([437], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([682], device='cuda:0') tensor(2.4478e-18, device='cuda:0')
L1: [4636.188]	L2: [20.54437]	Linf: [0.69803923]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 746 pred_label: 746 pred_clean_logit 0.998091995716095
prompt generate:  puck  	labels:  [[746]]
decoder:  [49406, 17550, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([795], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([746], device='cuda:0') tensor(1.4740e-09, device='cuda:0')
L1: [6801.3223]	L2: [33.69385]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 938 pred_label: 582 pred_clean_logit 0.15248779952526093
prompt generate:  cauliflower  	labels:  [[582]]
decoder:  [49406, 23802, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([410], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([938], device='cuda:0') tensor(1.3974e-26, device='cuda:0')
L1: [6978.686]	L2: [30.520369]	Linf: [0.9372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 472 pred_label: 975 pred_clean_logit 0.017955441027879715
prompt generate:  canoe  	labels:  [[975]]
decoder:  [49406, 23503, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([863], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([472], device='cuda:0') tensor(1.3480e-25, device='cuda:0')
L1: [8678.587]	L2: [31.566025]	Linf: [0.6352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 864 pred_label: 864 pred_clean_logit 0.8859937191009521
prompt generate:  tow truck  	labels:  [[864]]
decoder:  [49406, 18653, 4629, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([867], device='cuda:0') tensor(0.9954, device='cuda:0')
after_true: tensor([864], device='cuda:0') tensor(2.4719e-08, device='cuda:0')
L1: [8135.177]	L2: [35.729794]	Linf: [0.8784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.4%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 765 pred_label: 765 pred_clean_logit 0.9990702271461487
prompt generate:  rocking chair  	labels:  [[765]]
decoder:  [49406, 7081, 4269, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([706], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([765], device='cuda:0') tensor(2.9506e-11, device='cuda:0')
L1: [7117.2637]	L2: [30.134521]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 754 pred_label: 528 pred_clean_logit 0.0006989212124608457
prompt generate:  radio  	labels:  [[528]]
decoder:  [49406, 2638, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([528], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([754], device='cuda:0') tensor(4.5900e-17, device='cuda:0')
L1: [9047.597]	L2: [41.348595]	Linf: [0.8666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 705 pred_label: 705 pred_clean_logit 0.9989870190620422
prompt generate:  passenger car  	labels:  [[705]]
decoder:  [49406, 12311, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([466], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([705], device='cuda:0') tensor(7.3488e-12, device='cuda:0')
L1: [9459.349]	L2: [37.71462]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=46.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.1% (timestep 4)
Min contribution: 6.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 614 pred_label: 614 pred_clean_logit 0.9994292855262756
prompt generate:  kimono  	labels:  [[614]]
decoder:  [49406, 40024, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([703], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([614], device='cuda:0') tensor(5.6410e-24, device='cuda:0')
L1: [9560.978]	L2: [37.520626]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 309 pred_label: 309 pred_clean_logit 0.999890923500061
prompt generate:  bee  	labels:  [[309]]
decoder:  [49406, 5028, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([410], device='cuda:0') tensor(0.6018, device='cuda:0')
after_true: tensor([309], device='cuda:0') tensor(0.3420, device='cuda:0')
L1: [4897.216]	L2: [20.25112]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 884 pred_label: 884 pred_clean_logit 0.6498848795890808
prompt generate:  vault  	labels:  [[884]]
decoder:  [49406, 15240, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([457], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([884], device='cuda:0') tensor(7.7209e-14, device='cuda:0')
L1: [9173.636]	L2: [32.666607]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=10.8%
Timestep  3: Avg Loss=0.000012, Std=0.000004, Contribution=24.7%
Timestep  4: Avg Loss=0.000029, Std=0.000008, Contribution=58.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.9% (timestep 4)
Min contribution: 1.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 471 pred_label: 471 pred_clean_logit 0.9998257756233215
prompt generate:  cannon  	labels:  [[471]]
decoder:  [49406, 15661, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([744], device='cuda:0') tensor(0.7988, device='cuda:0')
after_true: tensor([471], device='cuda:0') tensor(5.1264e-19, device='cuda:0')
L1: [7350.9683]	L2: [33.12198]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.2%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 698 pred_label: 698 pred_clean_logit 0.5003770589828491
prompt generate:  palace  	labels:  [[698]]
decoder:  [49406, 6381, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([483], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([698], device='cuda:0') tensor(0.0001, device='cuda:0')
L1: [8721.361]	L2: [40.637398]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.5%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=21.7%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=57.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.9% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 884 pred_label: 884 pred_clean_logit 0.9979724287986755
prompt generate:  vault  	labels:  [[884]]
decoder:  [49406, 15240, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([74], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([884], device='cuda:0') tensor(5.0626e-15, device='cuda:0')
L1: [12498.726]	L2: [43.588543]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=7.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=45.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.2% (timestep 4)
Min contribution: 7.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 972 pred_label: 500 pred_clean_logit 0.021556243300437927
prompt generate:  cliff  	labels:  [[500]]
decoder:  [49406, 10625, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([237], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([972], device='cuda:0') tensor(3.1942e-23, device='cuda:0')
L1: [8233.919]	L2: [28.438213]	Linf: [0.5411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=24.3%
Timestep  4: Avg Loss=0.000021, Std=0.000006, Contribution=59.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.1% (timestep 4)
Min contribution: 1.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 401 pred_label: 645 pred_clean_logit 0.000551500590518117
prompt generate:  accordion  	labels:  [[645]]
decoder:  [49406, 48760, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([645], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([401], device='cuda:0') tensor(2.1250e-26, device='cuda:0')
L1: [9833.863]	L2: [37.312584]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=45.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.9% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 970 pred_label: 876 pred_clean_logit 0.008157282136380672
prompt generate:  alp  	labels:  [[876]]
decoder:  [49406, 39342, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([876], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([970], device='cuda:0') tensor(2.0329e-22, device='cuda:0')
L1: [5801.855]	L2: [22.89332]	Linf: [0.5529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 630 pred_label: 630 pred_clean_logit 0.8765501976013184
prompt generate:  Loafer  	labels:  [[630]]
decoder:  [49406, 26467, 528, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([589], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([630], device='cuda:0') tensor(3.5495e-18, device='cuda:0')
L1: [3393.1646]	L2: [16.3299]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.3%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 310 pred_label: 310 pred_clean_logit 0.9999932050704956
prompt generate:  ant  	labels:  [[310]]
decoder:  [49406, 773, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([70], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([310], device='cuda:0') tensor(6.3065e-17, device='cuda:0')
L1: [5971.823]	L2: [23.04273]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 12 pred_label: 12 pred_clean_logit 0.9999327659606934
prompt generate:  house finch  	labels:  [[12]]
decoder:  [49406, 1212, 18523, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([12], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([12], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [2462.6782]	L2: [11.550146]	Linf: [0.59607846]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=19.9%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=62.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 62.8% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 538 pred_label: 884 pred_clean_logit 0.4329378008842468
prompt generate:  dome  	labels:  [[884]]
decoder:  [49406, 9827, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([884], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([538], device='cuda:0') tensor(4.1255e-12, device='cuda:0')
L1: [5395.074]	L2: [23.510662]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=49.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.2% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 538 pred_label: 538 pred_clean_logit 0.9985617995262146
prompt generate:  dome  	labels:  [[538]]
decoder:  [49406, 9827, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([832], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([538], device='cuda:0') tensor(6.0720e-12, device='cuda:0')
L1: [5966.6113]	L2: [26.29849]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=13.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=14.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=17.1%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=21.4%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=34.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 34.1% (timestep 4)
Min contribution: 13.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 38 pred_label: 38 pred_clean_logit 0.9079753160476685
prompt generate:  banded gecko  	labels:  [[38]]
decoder:  [49406, 37804, 38616, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([56], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([38], device='cuda:0') tensor(3.4190e-19, device='cuda:0')
L1: [7060.345]	L2: [28.798685]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 667 pred_label: 764 pred_clean_logit 0.018050843849778175
prompt generate:  mortarboard  	labels:  [[764]]
decoder:  [49406, 657, 2002, 1972, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([614], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([667], device='cuda:0') tensor(3.1759e-19, device='cuda:0')
L1: [4525.463]	L2: [19.833559]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 340 pred_label: 340 pred_clean_logit 0.9999908208847046
prompt generate:  zebra  	labels:  [[340]]
decoder:  [49406, 22548, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([340], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([340], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [13930.719]	L2: [53.180668]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 605 pred_label: 620 pred_clean_logit 0.27445563673973083
prompt generate:  iPod  	labels:  [[620]]
decoder:  [49406, 17889, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([620], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([605], device='cuda:0') tensor(4.3148e-15, device='cuda:0')
L1: [4902.4595]	L2: [21.09764]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 547 pred_label: 547 pred_clean_logit 0.9515500068664551
prompt generate:  electric locomotive  	labels:  [[547]]
decoder:  [49406, 5031, 30439, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([494], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([547], device='cuda:0') tensor(2.9244e-37, device='cuda:0')
L1: [8826.433]	L2: [34.57906]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 652 pred_label: 652 pred_clean_logit 0.7433629035949707
prompt generate:  military uniform  	labels:  [[652]]
decoder:  [49406, 4323, 11075, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([645], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([652], device='cuda:0') tensor(1.0679e-18, device='cuda:0')
L1: [8751.482]	L2: [42.642067]	Linf: [0.98039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=27.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 937 pred_label: 937 pred_clean_logit 0.999998927116394
prompt generate:  broccoli  	labels:  [[937]]
decoder:  [49406, 19094, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([952], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([937], device='cuda:0') tensor(1.3352e-22, device='cuda:0')
L1: [7641.463]	L2: [30.361803]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.1%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.6%
Timestep  4: Avg Loss=0.000018, Std=0.000006, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 777 pred_label: 777 pred_clean_logit 0.4781397879123688
prompt generate:  scabbard  	labels:  [[777]]
decoder:  [49406, 31716, 17514, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([858], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([777], device='cuda:0') tensor(5.8855e-14, device='cuda:0')
L1: [4260.411]	L2: [16.495705]	Linf: [0.5372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 665 pred_label: 665 pred_clean_logit 0.9947222471237183
prompt generate:  moped  	labels:  [[665]]
decoder:  [49406, 617, 2966, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([671], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([665], device='cuda:0') tensor(8.0988e-14, device='cuda:0')
L1: [11152.199]	L2: [41.008904]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 685 pred_label: 507 pred_clean_logit 0.40768879652023315
prompt generate:  odometer  	labels:  [[507]]
decoder:  [49406, 78, 8515, 652, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([507], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([685], device='cuda:0') tensor(1.5947e-08, device='cuda:0')
L1: [2483.361]	L2: [20.922966]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=27.1%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=47.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.5% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 511 pred_label: 511 pred_clean_logit 0.9958977103233337
prompt generate:  convertible  	labels:  [[511]]
decoder:  [49406, 19608, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([627], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([511], device='cuda:0') tensor(1.1091e-20, device='cuda:0')
L1: [8106.177]	L2: [32.862324]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 308 pred_label: 308 pred_clean_logit 0.8549548387527466
prompt generate:  fly  	labels:  [[308]]
decoder:  [49406, 3228, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([314], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([308], device='cuda:0') tensor(4.7513e-16, device='cuda:0')
L1: [4920.5693]	L2: [19.052204]	Linf: [0.5372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.3%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 2 pred_label: 2 pred_clean_logit 0.9997571110725403
prompt generate:  great white shark  	labels:  [[2]]
decoder:  [49406, 830, 1579, 7980, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([801], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([2], device='cuda:0') tensor(3.0485e-14, device='cuda:0')
L1: [3452.247]	L2: [13.200509]	Linf: [0.65882355]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.8%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 469 pred_label: 469 pred_clean_logit 0.9999295473098755
prompt generate:  caldron  	labels:  [[469]]
decoder:  [49406, 1198, 23360, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([541], device='cuda:0') tensor(0.9831, device='cuda:0')
after_true: tensor([469], device='cuda:0') tensor(1.7694e-16, device='cuda:0')
L1: [6677.]	L2: [26.719398]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=13.2%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.3%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 717 pred_label: 717 pred_clean_logit 0.9998650550842285
prompt generate:  pickup  	labels:  [[717]]
decoder:  [49406, 15382, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([717], device='cuda:0') tensor(4.8015e-13, device='cuda:0')
L1: [7587.3696]	L2: [30.234129]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=11.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.3%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.1%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=42.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.1% (timestep 4)
Min contribution: 8.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 980 pred_label: 980 pred_clean_logit 0.9931753277778625
prompt generate:  volcano  	labels:  [[980]]
decoder:  [49406, 14581, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([994], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([980], device='cuda:0') tensor(2.1976e-14, device='cuda:0')
L1: [15400.29]	L2: [53.612774]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 251 pred_label: 251 pred_clean_logit 0.9991016387939453
prompt generate:  dalmatian  	labels:  [[251]]
decoder:  [49406, 44275, 550, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([251], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([251], device='cuda:0') tensor(0.9998, device='cuda:0')
L1: [8724.24]	L2: [32.164555]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.8%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.5%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 738 pred_label: 738 pred_clean_logit 0.9969267249107361
prompt generate:  pot  	labels:  [[738]]
decoder:  [49406, 5168, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([949], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([738], device='cuda:0') tensor(1.4682e-19, device='cuda:0')
L1: [9657.231]	L2: [36.736282]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 829 pred_label: 874 pred_clean_logit 0.02417285367846489
prompt generate:  streetcar  	labels:  [[874]]
decoder:  [49406, 34268, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([874], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([829], device='cuda:0') tensor(2.4958e-17, device='cuda:0')
L1: [4730.49]	L2: [21.143646]	Linf: [0.93333334]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=24.6%
Timestep  4: Avg Loss=0.000019, Std=0.000005, Contribution=57.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.0% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 557 pred_label: 557 pred_clean_logit 0.8405631184577942
prompt generate:  flagpole  	labels:  [[557]]
decoder:  [49406, 11536, 8170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([889], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([557], device='cuda:0') tensor(1.3536e-35, device='cuda:0')
L1: [8519.722]	L2: [39.08891]	Linf: [0.92156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 817 pred_label: 817 pred_clean_logit 0.5243144035339355
prompt generate:  sports car  	labels:  [[817]]
decoder:  [49406, 2054, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([817], device='cuda:0') tensor(2.3077e-12, device='cuda:0')
L1: [6656.059]	L2: [25.062572]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.5%
Timestep  3: Avg Loss=0.000009, Std=0.000004, Contribution=26.0%
Timestep  4: Avg Loss=0.000018, Std=0.000007, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 833 pred_label: 833 pred_clean_logit 0.9998900890350342
prompt generate:  submarine  	labels:  [[833]]
decoder:  [49406, 19968, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([718], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([833], device='cuda:0') tensor(5.6521e-15, device='cuda:0')
L1: [4827.2437]	L2: [20.693935]	Linf: [0.65882355]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=11.7%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=25.3%
Timestep  4: Avg Loss=0.000018, Std=0.000006, Contribution=56.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.2% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 829 pred_label: 829 pred_clean_logit 0.9943954944610596
prompt generate:  streetcar  	labels:  [[829]]
decoder:  [49406, 34268, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([874], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([829], device='cuda:0') tensor(3.5563e-16, device='cuda:0')
L1: [8982.726]	L2: [34.167397]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 458 pred_label: 458 pred_clean_logit 0.9999243021011353
prompt generate:  brass  	labels:  [[458]]
decoder:  [49406, 11655, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([458], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([458], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [8165.0356]	L2: [33.094498]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=9.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.9%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=13.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=20.7%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=45.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.1% (timestep 4)
Min contribution: 9.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 979 pred_label: 979 pred_clean_logit 0.5543986558914185
prompt generate:  valley  	labels:  [[979]]
decoder:  [49406, 3136, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([978], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([979], device='cuda:0') tensor(5.1475e-15, device='cuda:0')
L1: [11943.676]	L2: [44.68996]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=59.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.1% (timestep 4)
Min contribution: 1.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 887 pred_label: 467 pred_clean_logit 0.4689154028892517
prompt generate:  vestment  	labels:  [[467]]
decoder:  [49406, 31657, 777, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([564], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([887], device='cuda:0') tensor(4.8993e-19, device='cuda:0')
L1: [9669.949]	L2: [35.627373]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 959 pred_label: 959 pred_clean_logit 0.9998939037322998
prompt generate:  carbonara  	labels:  [[959]]
decoder:  [49406, 14038, 3340, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([959], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([959], device='cuda:0') tensor(0.9998, device='cuda:0')
L1: [3610.3293]	L2: [12.942661]	Linf: [0.3529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.3%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 883 pred_label: 883 pred_clean_logit 0.9997400641441345
prompt generate:  vase  	labels:  [[883]]
decoder:  [49406, 20431, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([725], device='cuda:0') tensor(0.9894, device='cuda:0')
after_true: tensor([883], device='cuda:0') tensor(1.0050e-15, device='cuda:0')
L1: [6659.8433]	L2: [30.178698]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 853 pred_label: 637 pred_clean_logit 0.0015737286303192377
prompt generate:  thatch  	labels:  [[637]]
decoder:  [49406, 6303, 634, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([637], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([853], device='cuda:0') tensor(4.8628e-21, device='cuda:0')
L1: [8022.0396]	L2: [31.943304]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 309 pred_label: 309 pred_clean_logit 0.9987236857414246
prompt generate:  bee  	labels:  [[309]]
decoder:  [49406, 5028, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([310], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([309], device='cuda:0') tensor(8.4126e-29, device='cuda:0')
L1: [9125.321]	L2: [34.760784]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=13.3%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.8%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 892 pred_label: 892 pred_clean_logit 0.7424347996711731
prompt generate:  wall clock  	labels:  [[892]]
decoder:  [49406, 2569, 6716, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([409], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([892], device='cuda:0') tensor(3.4661e-16, device='cuda:0')
L1: [9744.344]	L2: [37.4703]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 519 pred_label: 519 pred_clean_logit 0.6149552464485168
prompt generate:  crate  	labels:  [[519]]
decoder:  [49406, 24756, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([542], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([519], device='cuda:0') tensor(3.0347e-28, device='cuda:0')
L1: [11946.313]	L2: [44.136604]	Linf: [0.98039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.4%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=48.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.0% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 475 pred_label: 475 pred_clean_logit 0.9999945163726807
prompt generate:  car mirror  	labels:  [[475]]
decoder:  [49406, 1615, 7220, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([837], device='cuda:0') tensor(0.9718, device='cuda:0')
after_true: tensor([475], device='cuda:0') tensor(1.3718e-12, device='cuda:0')
L1: [4021.8118]	L2: [22.079636]	Linf: [0.95686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=22.4%
Timestep  4: Avg Loss=0.000007, Std=0.000004, Contribution=58.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.3% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 562 pred_label: 562 pred_clean_logit 0.997365415096283
prompt generate:  fountain  	labels:  [[562]]
decoder:  [49406, 13405, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([819], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([562], device='cuda:0') tensor(5.4180e-21, device='cuda:0')
L1: [5503.09]	L2: [26.099491]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 557 pred_label: 557 pred_clean_logit 0.9954534769058228
prompt generate:  flagpole  	labels:  [[557]]
decoder:  [49406, 11536, 8170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([842], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([557], device='cuda:0') tensor(2.8185e-22, device='cuda:0')
L1: [7366.204]	L2: [30.999865]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.4%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=47.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.7% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 983 pred_label: 983 pred_clean_logit 0.9998177886009216
prompt generate:  scuba diver  	labels:  [[983]]
decoder:  [49406, 20559, 22094, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([983], device='cuda:0') tensor(0.9990, device='cuda:0')
after_true: tensor([983], device='cuda:0') tensor(0.9990, device='cuda:0')
L1: [2817.4238]	L2: [12.619127]	Linf: [0.6823529]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.7%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 672 pred_label: 672 pred_clean_logit 0.2929824888706207
prompt generate:  mountain tent  	labels:  [[672]]
decoder:  [49406, 3965, 10782, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([432], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([672], device='cuda:0') tensor(1.4185e-25, device='cuda:0')
L1: [9106.221]	L2: [33.204224]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=58.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.1% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 437 pred_label: 437 pred_clean_logit 0.9999972581863403
prompt generate:  beacon  	labels:  [[437]]
decoder:  [49406, 18858, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([437], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([437], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5386.9653]	L2: [24.473703]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.2%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=23.6%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 129 pred_label: 129 pred_clean_logit 0.9479572176933289
prompt generate:  spoonbill  	labels:  [[129]]
decoder:  [49406, 27001, 2886, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([127], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([129], device='cuda:0') tensor(8.5923e-11, device='cuda:0')
L1: [2654.9927]	L2: [11.790935]	Linf: [0.5529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=9.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=11.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.7%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.4%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=40.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 40.7% (timestep 4)
Min contribution: 9.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 928 pred_label: 928 pred_clean_logit 0.9999995231628418
prompt generate:  ice cream  	labels:  [[928]]
decoder:  [49406, 733, 3867, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([931], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([928], device='cuda:0') tensor(4.1923e-22, device='cuda:0')
L1: [8662.855]	L2: [36.545944]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 637 pred_label: 637 pred_clean_logit 0.9999969005584717
prompt generate:  mailbox  	labels:  [[637]]
decoder:  [49406, 31482, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([637], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([637], device='cuda:0') tensor(1., device='cuda:0')
L1: [6714.389]	L2: [25.98131]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 467 pred_label: 467 pred_clean_logit 0.9997115731239319
prompt generate:  butcher shop  	labels:  [[467]]
decoder:  [49406, 18732, 1557, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([991], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([467], device='cuda:0') tensor(2.7564e-12, device='cuda:0')
L1: [10422.746]	L2: [36.94341]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=56.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.4% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 708 pred_label: 708 pred_clean_logit 0.831640899181366
prompt generate:  pedestal  	labels:  [[708]]
decoder:  [49406, 12862, 5535, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([501], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([708], device='cuda:0') tensor(4.1313e-21, device='cuda:0')
L1: [12779.072]	L2: [46.0052]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 858 pred_label: 858 pred_clean_logit 0.9998800754547119
prompt generate:  tile roof  	labels:  [[858]]
decoder:  [49406, 8227, 6449, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([858], device='cuda:0') tensor(0.9994, device='cuda:0')
after_true: tensor([858], device='cuda:0') tensor(0.9994, device='cuda:0')
L1: [7841.8193]	L2: [35.012096]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.0%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=48.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.3% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 628 pred_label: 628 pred_clean_logit 0.9996746778488159
prompt generate:  liner  	labels:  [[628]]
decoder:  [49406, 11618, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([606], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([628], device='cuda:0') tensor(1.1690e-18, device='cuda:0')
L1: [6859.3174]	L2: [29.877197]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 582 pred_label: 454 pred_clean_logit 8.045460708672181e-05
prompt generate:  grocery store  	labels:  [[454]]
decoder:  [49406, 13826, 2183, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([454], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([582], device='cuda:0') tensor(1.5229e-21, device='cuda:0')
L1: [9903.428]	L2: [39.6613]	Linf: [0.89411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 157 pred_label: 157 pred_clean_logit 0.999943733215332
prompt generate:  papillon  	labels:  [[157]]
decoder:  [49406, 1884, 20516, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([157], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([157], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7232.852]	L2: [26.19029]	Linf: [0.59607846]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.9%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=26.0%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 51 pred_label: 71 pred_clean_logit 0.005267221014946699
prompt generate:  triceratops  	labels:  [[71]]
decoder:  [49406, 9511, 517, 527, 3054, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([679], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([51], device='cuda:0') tensor(6.1545e-16, device='cuda:0')
L1: [6502.894]	L2: [30.190268]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 984 pred_label: 738 pred_clean_logit 0.042999766767024994
prompt generate:  rapeseed  	labels:  [[738]]
decoder:  [49406, 46099, 6488, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([276], device='cuda:0') tensor(0.9985, device='cuda:0')
after_true: tensor([984], device='cuda:0') tensor(4.9506e-12, device='cuda:0')
L1: [13526.984]	L2: [48.255894]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.6%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 104 pred_label: 104 pred_clean_logit 0.9999794960021973
prompt generate:  wallaby  	labels:  [[104]]
decoder:  [49406, 26007, 638, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([104], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([104], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [10069.11]	L2: [36.590458]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.7%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.6%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=26.3%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=46.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.8% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 441 pred_label: 441 pred_clean_logit 0.9975653886795044
prompt generate:  beer glass  	labels:  [[441]]
decoder:  [49406, 2544, 3313, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([960], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([441], device='cuda:0') tensor(2.5669e-13, device='cuda:0')
L1: [3932.3572]	L2: [15.627123]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.1%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=57.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.9% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 595 pred_label: 595 pred_clean_logit 0.4554327130317688
prompt generate:  harvester  	labels:  [[595]]
decoder:  [49406, 6405, 881, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([958], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([595], device='cuda:0') tensor(2.0297e-15, device='cuda:0')
L1: [4593.714]	L2: [18.231722]	Linf: [0.5137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 946 pred_label: 946 pred_clean_logit 0.6491648554801941
prompt generate:  cardoon  	labels:  [[946]]
decoder:  [49406, 811, 36612, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([309], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([946], device='cuda:0') tensor(8.1371e-13, device='cuda:0')
L1: [5895.0156]	L2: [26.848042]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=21.7%
Timestep  4: Avg Loss=0.000010, Std=0.000002, Contribution=60.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.0% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 521 pred_label: 521 pred_clean_logit 0.7522128224372864
prompt generate:  Crock Pot  	labels:  [[521]]
decoder:  [49406, 1192, 868, 5168, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([886], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([521], device='cuda:0') tensor(1.3151e-15, device='cuda:0')
L1: [10111.898]	L2: [39.801384]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.2%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=44.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.3% (timestep 4)
Min contribution: 6.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 545 pred_label: 545 pred_clean_logit 0.9995294809341431
prompt generate:  electric fan  	labels:  [[545]]
decoder:  [49406, 5031, 2261, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([813], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([545], device='cuda:0') tensor(4.0893e-26, device='cuda:0')
L1: [5410.3726]	L2: [23.188309]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 946 pred_label: 946 pred_clean_logit 0.5040475726127625
prompt generate:  cardoon  	labels:  [[946]]
decoder:  [49406, 811, 36612, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([990], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([946], device='cuda:0') tensor(1.2152e-12, device='cuda:0')
L1: [12148.251]	L2: [43.84205]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=27.5%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 579 pred_label: 579 pred_clean_logit 0.9906195402145386
prompt generate:  grand piano  	labels:  [[579]]
decoder:  [49406, 2991, 7894, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([513], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([579], device='cuda:0') tensor(1.9471e-19, device='cuda:0')
L1: [4263.5103]	L2: [22.923668]	Linf: [0.89411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 863 pred_label: 863 pred_clean_logit 0.9999995231628418
prompt generate:  totem pole  	labels:  [[863]]
decoder:  [49406, 45376, 8170, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([863], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([863], device='cuda:0') tensor(1., device='cuda:0')
L1: [6166.2197]	L2: [24.816124]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.0%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=25.0%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 10 pred_label: 10 pred_clean_logit 0.869558572769165
prompt generate:  brambling  	labels:  [[10]]
decoder:  [49406, 14815, 7097, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([12], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([10], device='cuda:0') tensor(3.7751e-11, device='cuda:0')
L1: [2838.0984]	L2: [12.699358]	Linf: [0.49411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=9.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=47.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.8% (timestep 4)
Min contribution: 6.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 455 pred_label: 455 pred_clean_logit 0.9291567206382751
prompt generate:  bottlecap  	labels:  [[455]]
decoder:  [49406, 37306, 3938, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([737], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([455], device='cuda:0') tensor(1.9298e-07, device='cuda:0')
L1: [4898.839]	L2: [19.68738]	Linf: [0.56078434]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=9.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=11.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=16.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=39.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 39.2% (timestep 4)
Min contribution: 9.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 433 pred_label: 433 pred_clean_logit 0.9999960660934448
prompt generate:  bathing cap  	labels:  [[433]]
decoder:  [49406, 20144, 3938, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([433], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([433], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6090.9614]	L2: [24.708069]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.4%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.1%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=22.2%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=47.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.5% (timestep 4)
Min contribution: 6.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 455 pred_label: 539 pred_clean_logit 0.009060190990567207
prompt generate:  bottlecap  	labels:  [[539]]
decoder:  [49406, 37306, 3938, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([539], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([455], device='cuda:0') tensor(9.5573e-14, device='cuda:0')
L1: [12779.878]	L2: [43.845676]	Linf: [0.69803923]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 480 pred_label: 894 pred_clean_logit 0.03261096403002739
prompt generate:  cash machine  	labels:  [[894]]
decoder:  [49406, 5131, 4169, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([894], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([480], device='cuda:0') tensor(7.1386e-20, device='cuda:0')
L1: [4680.2197]	L2: [20.8667]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=12.2%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=24.2%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 912 pred_label: 912 pred_clean_logit 0.7802910804748535
prompt generate:  worm fence  	labels:  [[912]]
decoder:  [49406, 10945, 12679, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([888], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([912], device='cuda:0') tensor(1.3312e-11, device='cuda:0')
L1: [6090.161]	L2: [24.181814]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.6%
Timestep  4: Avg Loss=0.000011, Std=0.000005, Contribution=58.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.4% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 908 pred_label: 908 pred_clean_logit 0.999836802482605
prompt generate:  wing  	labels:  [[908]]
decoder:  [49406, 1340, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([672], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([908], device='cuda:0') tensor(1.8324e-13, device='cuda:0')
L1: [3482.8472]	L2: [17.397629]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 348 pred_label: 348 pred_clean_logit 0.7650612592697144
prompt generate:  ram  	labels:  [[348]]
decoder:  [49406, 2007, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([169], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([348], device='cuda:0') tensor(1.8933e-21, device='cuda:0')
L1: [6242.2935]	L2: [22.350143]	Linf: [0.5686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=57.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.2% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 717 pred_label: 864 pred_clean_logit 0.006904053967446089
prompt generate:  pickup  	labels:  [[864]]
decoder:  [49406, 15382, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([864], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([717], device='cuda:0') tensor(3.4521e-20, device='cuda:0')
L1: [9046.323]	L2: [36.16484]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.9% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 470 pred_label: 572 pred_clean_logit 0.23213282227516174
prompt generate:  candle  	labels:  [[572]]
decoder:  [49406, 12674, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([519], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([470], device='cuda:0') tensor(2.0353e-18, device='cuda:0')
L1: [4699.8276]	L2: [19.430815]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.9%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=58.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.2% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 874 pred_label: 829 pred_clean_logit 0.4045528769493103
prompt generate:  trolleybus  	labels:  [[829]]
decoder:  [49406, 10306, 2565, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([829], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([874], device='cuda:0') tensor(8.8390e-13, device='cuda:0')
L1: [7570.6284]	L2: [28.076962]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 884 pred_label: 884 pred_clean_logit 0.9595195055007935
prompt generate:  vault  	labels:  [[884]]
decoder:  [49406, 15240, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([663], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([884], device='cuda:0') tensor(8.1931e-14, device='cuda:0')
L1: [5243.286]	L2: [21.394497]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=56.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.6% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 718 pred_label: 718 pred_clean_logit 0.9708712100982666
prompt generate:  pier  	labels:  [[718]]
decoder:  [49406, 11348, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([421], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([718], device='cuda:0') tensor(3.3836e-11, device='cuda:0')
L1: [6144.988]	L2: [24.145874]	Linf: [0.5058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=12.1%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=25.4%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 964 pred_label: 964 pred_clean_logit 0.933420717716217
prompt generate:  potpie  	labels:  [[964]]
decoder:  [49406, 3547, 5319, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([923], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([964], device='cuda:0') tensor(6.6390e-11, device='cuda:0')
L1: [6583.7017]	L2: [27.994196]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 847 pred_label: 847 pred_clean_logit 0.9970357418060303
prompt generate:  tank  	labels:  [[847]]
decoder:  [49406, 6172, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([575], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([847], device='cuda:0') tensor(3.3395e-25, device='cuda:0')
L1: [10352.514]	L2: [38.000732]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=50.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.0% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 438 pred_label: 438 pred_clean_logit 0.8910071849822998
prompt generate:  beaker  	labels:  [[438]]
decoder:  [49406, 571, 3074, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([470], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([438], device='cuda:0') tensor(4.8549e-28, device='cuda:0')
L1: [3619.2708]	L2: [13.405445]	Linf: [0.49411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.2%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=59.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.4% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 981 pred_label: 981 pred_clean_logit 0.8941978812217712
prompt generate:  ballplayer  	labels:  [[981]]
decoder:  [49406, 3807, 2477, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([430], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([981], device='cuda:0') tensor(1.3800e-19, device='cuda:0')
L1: [12649.647]	L2: [47.552925]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 571 pred_label: 571 pred_clean_logit 0.9945797920227051
prompt generate:  gas pump  	labels:  [[571]]
decoder:  [49406, 2474, 9173, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([875], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([571], device='cuda:0') tensor(4.9741e-16, device='cuda:0')
L1: [5157.643]	L2: [22.539478]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 792 pred_label: 792 pred_clean_logit 0.9997056126594543
prompt generate:  shovel  	labels:  [[792]]
decoder:  [49406, 31778, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([693], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([792], device='cuda:0') tensor(9.7733e-20, device='cuda:0')
L1: [7919.164]	L2: [31.917055]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=56.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.6% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 874 pred_label: 874 pred_clean_logit 0.9790008664131165
prompt generate:  trolleybus  	labels:  [[874]]
decoder:  [49406, 10306, 2565, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([829], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([874], device='cuda:0') tensor(4.6822e-12, device='cuda:0')
L1: [10136.04]	L2: [41.333195]	Linf: [0.8784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 594 pred_label: 594 pred_clean_logit 0.8813446760177612
prompt generate:  harp  	labels:  [[594]]
decoder:  [49406, 27339, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([733], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([594], device='cuda:0') tensor(9.7734e-31, device='cuda:0')
L1: [8229.69]	L2: [35.928703]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 474 pred_label: 474 pred_clean_logit 0.9996787309646606
prompt generate:  cardigan  	labels:  [[474]]
decoder:  [49406, 30501, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([850], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([474], device='cuda:0') tensor(1.6397e-19, device='cuda:0')
L1: [4932.408]	L2: [18.472363]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.9%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 774 pred_label: 502 pred_clean_logit 0.05453459173440933
prompt generate:  sandal  	labels:  [[502]]
decoder:  [49406, 42185, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([808], device='cuda:0') tensor(0.9909, device='cuda:0')
after_true: tensor([774], device='cuda:0') tensor(4.9270e-11, device='cuda:0')
L1: [3419.1843]	L2: [20.283207]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=4.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=59.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.2% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 628 pred_label: 554 pred_clean_logit 0.035375095903873444
prompt generate:  liner  	labels:  [[554]]
decoder:  [49406, 11618, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([576], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([628], device='cuda:0') tensor(2.2391e-18, device='cuda:0')
L1: [5228.8125]	L2: [22.877186]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 671 pred_label: 671 pred_clean_logit 0.9966298937797546
prompt generate:  mountain bike  	labels:  [[671]]
decoder:  [49406, 3965, 3701, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([535], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([671], device='cuda:0') tensor(3.1231e-10, device='cuda:0')
L1: [9035.09]	L2: [37.590706]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.7%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 701 pred_label: 417 pred_clean_logit 0.04713284224271774
prompt generate:  parachute  	labels:  [[417]]
decoder:  [49406, 30122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([435], device='cuda:0') tensor(0.7008, device='cuda:0')
after_true: tensor([701], device='cuda:0') tensor(2.1898e-18, device='cuda:0')
L1: [3482.1172]	L2: [13.815965]	Linf: [0.5882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000005, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000010, Std=0.000003, Contribution=25.7%
Timestep  4: Avg Loss=0.000020, Std=0.000005, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 78 pred_label: 78 pred_clean_logit 0.9999704360961914
prompt generate:  tick  	labels:  [[78]]
decoder:  [49406, 15617, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([125], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([78], device='cuda:0') tensor(9.9162e-19, device='cuda:0')
L1: [3872.7998]	L2: [20.665226]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 946 pred_label: 946 pred_clean_logit 0.9991173148155212
prompt generate:  cardoon  	labels:  [[946]]
decoder:  [49406, 811, 36612, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([11], device='cuda:0') tensor(0.9993, device='cuda:0')
after_true: tensor([946], device='cuda:0') tensor(8.4714e-10, device='cuda:0')
L1: [6795.981]	L2: [25.849892]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 476 pred_label: 476 pred_clean_logit 0.9999852180480957
prompt generate:  carousel  	labels:  [[476]]
decoder:  [49406, 36665, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([476], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([476], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [7221.953]	L2: [28.89714]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.4%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.1%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=23.2%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=46.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.8% (timestep 4)
Min contribution: 6.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 974 pred_label: 974 pred_clean_logit 0.9999861717224121
prompt generate:  geyser  	labels:  [[974]]
decoder:  [49406, 619, 33121, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([978], device='cuda:0') tensor(0.7396, device='cuda:0')
after_true: tensor([974], device='cuda:0') tensor(4.5111e-05, device='cuda:0')
L1: [2593.898]	L2: [10.496999]	Linf: [0.4156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=4.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=9.5%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=19.8%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=63.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 63.2% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 820 pred_label: 820 pred_clean_logit 0.9997772574424744
prompt generate:  steam locomotive  	labels:  [[820]]
decoder:  [49406, 6972, 30439, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([570], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([820], device='cuda:0') tensor(2.3187e-20, device='cuda:0')
L1: [10929.568]	L2: [45.84022]	Linf: [0.9411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 311 pred_label: 311 pred_clean_logit 0.43653836846351624
prompt generate:  grasshopper  	labels:  [[311]]
decoder:  [49406, 48894, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([312], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([311], device='cuda:0') tensor(2.7739e-19, device='cuda:0')
L1: [11195.927]	L2: [42.166634]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.0% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 963 pred_label: 963 pred_clean_logit 0.9992153644561768
prompt generate:  pizza  	labels:  [[963]]
decoder:  [49406, 4474, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([956], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([963], device='cuda:0') tensor(4.0705e-25, device='cuda:0')
L1: [9827.808]	L2: [35.29343]	Linf: [0.5764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 936 pred_label: 936 pred_clean_logit 0.9740093946456909
prompt generate:  head cabbage  	labels:  [[936]]
decoder:  [49406, 1375, 18407, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([938], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([936], device='cuda:0') tensor(7.7207e-20, device='cuda:0')
L1: [8746.538]	L2: [31.269491]	Linf: [0.5803922]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 634 pred_label: 988 pred_clean_logit 0.0007151016616262496
prompt generate:  lumbermill  	labels:  [[988]]
decoder:  [49406, 27421, 6637, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([907], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([634], device='cuda:0') tensor(1.3559e-20, device='cuda:0')
L1: [12385.949]	L2: [44.99581]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.4%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 427 pred_label: 427 pred_clean_logit 0.9977086782455444
prompt generate:  barrel  	labels:  [[427]]
decoder:  [49406, 11703, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([778], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([427], device='cuda:0') tensor(1.9856e-27, device='cuda:0')
L1: [8031.436]	L2: [28.596811]	Linf: [0.60392153]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=44.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.1% (timestep 4)
Min contribution: 7.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 57 pred_label: 57 pred_clean_logit 0.9999655485153198
prompt generate:  garter snake  	labels:  [[57]]
decoder:  [49406, 48420, 8798, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([53], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([57], device='cuda:0') tensor(3.2772e-15, device='cuda:0')
L1: [9265.801]	L2: [36.185883]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 326 pred_label: 326 pred_clean_logit 0.9999710321426392
prompt generate:  lycaenid  	labels:  [[326]]
decoder:  [49406, 1251, 772, 524, 1014, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([322], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([326], device='cuda:0') tensor(1.4110e-08, device='cuda:0')
L1: [5113.6357]	L2: [21.783064]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 344 pred_label: 341 pred_clean_logit 0.0008602612651884556
prompt generate:  hippopotamus  	labels:  [[341]]
decoder:  [49406, 28398, 45825, 718, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([348], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([344], device='cuda:0') tensor(6.4254e-21, device='cuda:0')
L1: [9875.581]	L2: [41.218544]	Linf: [0.8980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 963 pred_label: 963 pred_clean_logit 0.9999651908874512
prompt generate:  pizza  	labels:  [[963]]
decoder:  [49406, 4474, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([963], device='cuda:0') tensor(0.9933, device='cuda:0')
after_true: tensor([963], device='cuda:0') tensor(0.9933, device='cuda:0')
L1: [9980.768]	L2: [34.52371]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.7%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 825 pred_label: 509 pred_clean_logit 0.10708857327699661
prompt generate:  stone wall  	labels:  [[509]]
decoder:  [49406, 2441, 2569, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([509], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([825], device='cuda:0') tensor(1.2199e-19, device='cuda:0')
L1: [13001.463]	L2: [48.001244]	Linf: [0.8980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 606 pred_label: 606 pred_clean_logit 1.0
prompt generate:  iron  	labels:  [[606]]
decoder:  [49406, 5391, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([606], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([606], device='cuda:0') tensor(1., device='cuda:0')
L1: [2664.7336]	L2: [10.236215]	Linf: [0.46274513]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.8%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.2%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=23.0%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=48.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.3% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 765 pred_label: 765 pred_clean_logit 0.9987296462059021
prompt generate:  rocking chair  	labels:  [[765]]
decoder:  [49406, 7081, 4269, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([494], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([765], device='cuda:0') tensor(4.1634e-20, device='cuda:0')
L1: [7413.2363]	L2: [27.12013]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=48.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.8% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 659 pred_label: 659 pred_clean_logit 0.9954628348350525
prompt generate:  mixing bowl  	labels:  [[659]]
decoder:  [49406, 15588, 3814, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([828], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([659], device='cuda:0') tensor(2.8648e-34, device='cuda:0')
L1: [5176.0557]	L2: [20.810436]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 478 pred_label: 478 pred_clean_logit 0.999727189540863
prompt generate:  carton  	labels:  [[478]]
decoder:  [49406, 41812, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([553], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([478], device='cuda:0') tensor(1.4548e-12, device='cuda:0')
L1: [3321.914]	L2: [13.941731]	Linf: [0.52156866]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 688 pred_label: 688 pred_clean_logit 0.9979168772697449
prompt generate:  oscilloscope  	labels:  [[688]]
decoder:  [49406, 5092, 34153, 7979, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([848], device='cuda:0') tensor(0.8060, device='cuda:0')
after_true: tensor([688], device='cuda:0') tensor(2.6857e-13, device='cuda:0')
L1: [7077.047]	L2: [27.867752]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=14.4%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.8%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 416 pred_label: 416 pred_clean_logit 0.9742431640625
prompt generate:  balance beam  	labels:  [[416]]
decoder:  [49406, 6827, 13663, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([702], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([416], device='cuda:0') tensor(1.6396e-15, device='cuda:0')
L1: [3527.2002]	L2: [13.179892]	Linf: [0.33333334]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000014, Std=0.000003, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 547 pred_label: 829 pred_clean_logit 0.21895265579223633
prompt generate:  electric locomotive  	labels:  [[829]]
decoder:  [49406, 5031, 30439, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([517], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([547], device='cuda:0') tensor(5.2316e-14, device='cuda:0')
L1: [6905.9326]	L2: [29.10679]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000010, Std=0.000002, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 708 pred_label: 708 pred_clean_logit 0.542822003364563
prompt generate:  pedestal  	labels:  [[708]]
decoder:  [49406, 12862, 5535, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([869], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([708], device='cuda:0') tensor(3.3172e-19, device='cuda:0')
L1: [5106.2954]	L2: [22.328959]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.7%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 557 pred_label: 557 pred_clean_logit 0.11254476755857468
prompt generate:  flagpole  	labels:  [[557]]
decoder:  [49406, 11536, 8170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([644], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([557], device='cuda:0') tensor(7.6273e-15, device='cuda:0')
L1: [9454.53]	L2: [37.87754]	Linf: [0.8784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 306 pred_label: 306 pred_clean_logit 0.999995231628418
prompt generate:  rhinoceros beetle  	labels:  [[306]]
decoder:  [49406, 41744, 1364, 1299, 16534, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([306], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([306], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [12049.215]	L2: [42.214615]	Linf: [0.5803922]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.8%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=11.6%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.8%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 993 pred_label: 85 pred_clean_logit 0.006713635288178921
prompt generate:  gyromitra  	labels:  [[85]]
decoder:  [49406, 2168, 532, 47703, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([85], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([993], device='cuda:0') tensor(2.1234e-25, device='cuda:0')
L1: [8693.255]	L2: [30.990147]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=27.1%
Timestep  4: Avg Loss=0.000019, Std=0.000005, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 933 pred_label: 933 pred_clean_logit 0.9009082317352295
prompt generate:  cheeseburger  	labels:  [[933]]
decoder:  [49406, 41200, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([928], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([933], device='cuda:0') tensor(3.0265e-24, device='cuda:0')
L1: [6577.3687]	L2: [24.319214]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=57.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.8% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 547 pred_label: 705 pred_clean_logit 0.4370601773262024
prompt generate:  electric locomotive  	labels:  [[705]]
decoder:  [49406, 5031, 30439, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([829], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([547], device='cuda:0') tensor(9.9918e-12, device='cuda:0')
L1: [9436.241]	L2: [33.56491]	Linf: [0.6980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=57.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.8% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 989 pred_label: 580 pred_clean_logit 0.09420613199472427
prompt generate:  hip  	labels:  [[580]]
decoder:  [49406, 6584, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([580], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([989], device='cuda:0') tensor(1.4210e-08, device='cuda:0')
L1: [11704.859]	L2: [38.984463]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=26.9%
Timestep  4: Avg Loss=0.000010, Std=0.000002, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 707 pred_label: 707 pred_clean_logit 0.9999905824661255
prompt generate:  pay-phone  	labels:  [[707]]
decoder:  [49406, 3345, 268, 1951, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([707], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([707], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [9940.718]	L2: [37.583576]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.2%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=13.8%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.0%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=48.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.4% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 819 pred_label: 819 pred_clean_logit 0.9754495024681091
prompt generate:  stage  	labels:  [[819]]
decoder:  [49406, 2170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([818], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([819], device='cuda:0') tensor(3.1111e-19, device='cuda:0')
L1: [4255.816]	L2: [19.03755]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 764 pred_label: 764 pred_clean_logit 0.9997236132621765
prompt generate:  rifle  	labels:  [[764]]
decoder:  [49406, 15354, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([413], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([764], device='cuda:0') tensor(1.1109e-09, device='cuda:0')
L1: [10507.71]	L2: [36.91572]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 779 pred_label: 779 pred_clean_logit 0.9999974966049194
prompt generate:  school bus  	labels:  [[779]]
decoder:  [49406, 1228, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([779], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([779], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6061.808]	L2: [26.316914]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=7.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.7%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=15.3%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=24.3%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=43.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.6% (timestep 4)
Min contribution: 7.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 682 pred_label: 682 pred_clean_logit 0.9999992847442627
prompt generate:  obelisk  	labels:  [[682]]
decoder:  [49406, 78, 1308, 30171, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([682], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([682], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6637.1616]	L2: [27.586117]	Linf: [0.58431375]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000006, Std=0.000001, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 734 pred_label: 734 pred_clean_logit 0.9999998807907104
prompt generate:  police van  	labels:  [[734]]
decoder:  [49406, 2120, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5903.628]	L2: [25.606384]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=9.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.6%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.4%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=22.0%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=43.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.9% (timestep 4)
Min contribution: 9.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 400 pred_label: 400 pred_clean_logit 0.6669585704803467
prompt generate:  academic gown  	labels:  [[400]]
decoder:  [49406, 7935, 13719, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([971], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([400], device='cuda:0') tensor(0., device='cuda:0')
L1: [11977.089]	L2: [44.906178]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 975 pred_label: 975 pred_clean_logit 0.9854990243911743
prompt generate:  lakeside  	labels:  [[975]]
decoder:  [49406, 30915, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([975], device='cuda:0') tensor(1.4613e-17, device='cuda:0')
L1: [8639.816]	L2: [35.754215]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 716 pred_label: 716 pred_clean_logit 0.9981945157051086
prompt generate:  picket fence  	labels:  [[716]]
decoder:  [49406, 33559, 12679, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([660], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([716], device='cuda:0') tensor(7.6286e-14, device='cuda:0')
L1: [5765.295]	L2: [22.193657]	Linf: [0.5372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 964 pred_label: 947 pred_clean_logit 0.0005876452778466046
prompt generate:  potpie  	labels:  [[947]]
decoder:  [49406, 3547, 5319, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([992], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([964], device='cuda:0') tensor(3.9770e-17, device='cuda:0')
L1: [7611.471]	L2: [29.866915]	Linf: [0.61960787]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=57.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.2% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 51 pred_label: 51 pred_clean_logit 0.9858158826828003
prompt generate:  triceratops  	labels:  [[51]]
decoder:  [49406, 9511, 517, 527, 3054, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([121], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([51], device='cuda:0') tensor(3.0729e-23, device='cuda:0')
L1: [6852.2275]	L2: [24.433401]	Linf: [0.54117644]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 654 pred_label: 654 pred_clean_logit 0.7588973641395569
prompt generate:  minibus  	labels:  [[654]]
decoder:  [49406, 1810, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([757], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([654], device='cuda:0') tensor(2.0440e-16, device='cuda:0')
L1: [5850.5024]	L2: [25.313139]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 718 pred_label: 718 pred_clean_logit 0.8809352517127991
prompt generate:  pier  	labels:  [[718]]
decoder:  [49406, 11348, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([888], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([718], device='cuda:0') tensor(8.0541e-12, device='cuda:0')
L1: [7409.6357]	L2: [36.657818]	Linf: [0.92941177]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 908 pred_label: 895 pred_clean_logit 0.2961992621421814
prompt generate:  wing  	labels:  [[895]]
decoder:  [49406, 1340, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([744], device='cuda:0') tensor(0.9750, device='cuda:0')
after_true: tensor([908], device='cuda:0') tensor(4.8443e-19, device='cuda:0')
L1: [3581.7017]	L2: [13.201564]	Linf: [0.5372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 132 pred_label: 132 pred_clean_logit 0.996842622756958
prompt generate:  American egret  	labels:  [[132]]
decoder:  [49406, 2151, 42002, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([134], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([132], device='cuda:0') tensor(5.4065e-08, device='cuda:0')
L1: [11274.563]	L2: [38.620872]	Linf: [0.59607846]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.5%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=48.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.4% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 557 pred_label: 21 pred_clean_logit 0.003174524288624525
prompt generate:  flagpole  	labels:  [[21]]
decoder:  [49406, 11536, 8170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([18], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([557], device='cuda:0') tensor(4.0701e-11, device='cuda:0')
L1: [2055.8003]	L2: [10.4636135]	Linf: [0.5921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=46.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.2% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 407 pred_label: 734 pred_clean_logit 0.46636343002319336
prompt generate:  ambulance  	labels:  [[734]]
decoder:  [49406, 15555, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([734], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([407], device='cuda:0') tensor(1.5201e-17, device='cuda:0')
L1: [8958.769]	L2: [36.439007]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=10.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=43.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.0% (timestep 4)
Min contribution: 7.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 304 pred_label: 304 pred_clean_logit 0.8008992671966553
prompt generate:  leaf beetle  	labels:  [[304]]
decoder:  [49406, 7232, 16534, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([78], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([304], device='cuda:0') tensor(1.0397e-13, device='cuda:0')
L1: [4102.7446]	L2: [15.276191]	Linf: [0.5686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=22.7%
Timestep  4: Avg Loss=0.000015, Std=0.000003, Contribution=57.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.6% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 99 pred_label: 99 pred_clean_logit 0.9999939203262329
prompt generate:  goose  	labels:  [[99]]
decoder:  [49406, 13822, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([99], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([99], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [9611.279]	L2: [32.932808]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000000, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 640 pred_label: 640 pred_clean_logit 0.9696990847587585
prompt generate:  manhole cover  	labels:  [[640]]
decoder:  [49406, 723, 5341, 2202, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([891], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([640], device='cuda:0') tensor(2.2855e-10, device='cuda:0')
L1: [7931.6543]	L2: [28.916508]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 854 pred_label: 854 pred_clean_logit 0.9992066025733948
prompt generate:  theater curtain  	labels:  [[854]]
decoder:  [49406, 6128, 17223, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([498], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([854], device='cuda:0') tensor(4.5839e-08, device='cuda:0')
L1: [7580.6895]	L2: [30.470905]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.4%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 933 pred_label: 933 pred_clean_logit 0.9998596906661987
prompt generate:  cheeseburger  	labels:  [[933]]
decoder:  [49406, 41200, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([931], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([933], device='cuda:0') tensor(1.0386e-13, device='cuda:0')
L1: [5588.859]	L2: [20.9444]	Linf: [0.54901963]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=25.0%
Timestep  4: Avg Loss=0.000011, Std=0.000005, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 979 pred_label: 979 pred_clean_logit 0.9906948804855347
prompt generate:  valley  	labels:  [[979]]
decoder:  [49406, 3136, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([14], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([979], device='cuda:0') tensor(6.2932e-26, device='cuda:0')
L1: [8610.878]	L2: [29.169907]	Linf: [0.62352943]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=60.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.3% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 440 pred_label: 440 pred_clean_logit 0.9918220639228821
prompt generate:  beer bottle  	labels:  [[440]]
decoder:  [49406, 2544, 5392, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([720], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([440], device='cuda:0') tensor(3.0019e-21, device='cuda:0')
L1: [4834.1064]	L2: [20.083849]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=24.5%
Timestep  4: Avg Loss=0.000011, Std=0.000005, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 436 pred_label: 654 pred_clean_logit 0.01740903966128826
prompt generate:  beach wagon  	labels:  [[654]]
decoder:  [49406, 2117, 13260, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([654], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([436], device='cuda:0') tensor(2.8917e-19, device='cuda:0')
L1: [7668.6313]	L2: [30.321049]	Linf: [0.9137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 489 pred_label: 489 pred_clean_logit 0.9999967813491821
prompt generate:  chainlink fence  	labels:  [[489]]
decoder:  [49406, 13898, 2468, 12679, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([489], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([489], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2983.6155]	L2: [14.705951]	Linf: [0.7215686]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=11.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=12.9%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=16.0%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=21.1%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=38.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 38.3% (timestep 4)
Min contribution: 11.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 317 pred_label: 317 pred_clean_logit 0.9617642760276794
prompt generate:  leafhopper  	labels:  [[317]]
decoder:  [49406, 9377, 21748, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([316], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([317], device='cuda:0') tensor(2.3439e-14, device='cuda:0')
L1: [3628.7373]	L2: [18.122759]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 887 pred_label: 887 pred_clean_logit 0.9733553528785706
prompt generate:  vestment  	labels:  [[887]]
decoder:  [49406, 31657, 777, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([617], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([887], device='cuda:0') tensor(3.0360e-24, device='cuda:0')
L1: [7473.773]	L2: [31.333189]	Linf: [0.8980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=48.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.7% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 829 pred_label: 829 pred_clean_logit 0.6343441605567932
prompt generate:  streetcar  	labels:  [[829]]
decoder:  [49406, 34268, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([547], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([829], device='cuda:0') tensor(5.9640e-14, device='cuda:0')
L1: [8014.09]	L2: [35.95906]	Linf: [0.8784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=47.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.2% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 340 pred_label: 340 pred_clean_logit 0.9999840259552002
prompt generate:  zebra  	labels:  [[340]]
decoder:  [49406, 22548, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([340], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([340], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [10225.121]	L2: [37.1341]	Linf: [0.69803923]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.7%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.7%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 94 pred_label: 94 pred_clean_logit 0.9999806880950928
prompt generate:  hummingbird  	labels:  [[94]]
decoder:  [49406, 33072, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([94], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([94], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3573.4077]	L2: [16.086462]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=7.2%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.8%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.3%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.2%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=46.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.6% (timestep 4)
Min contribution: 7.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 887 pred_label: 887 pred_clean_logit 0.9998829364776611
prompt generate:  vestment  	labels:  [[887]]
decoder:  [49406, 31657, 777, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([981], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([887], device='cuda:0') tensor(2.7951e-14, device='cuda:0')
L1: [7131.883]	L2: [29.652765]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.5%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 562 pred_label: 562 pred_clean_logit 0.9986673593521118
prompt generate:  fountain  	labels:  [[562]]
decoder:  [49406, 13405, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([521], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([562], device='cuda:0') tensor(3.7515e-25, device='cuda:0')
L1: [11355.974]	L2: [41.99286]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 817 pred_label: 817 pred_clean_logit 0.9962483048439026
prompt generate:  sports car  	labels:  [[817]]
decoder:  [49406, 2054, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([751], device='cuda:0') tensor(0.9992, device='cuda:0')
after_true: tensor([817], device='cuda:0') tensor(6.9102e-10, device='cuda:0')
L1: [6971.969]	L2: [32.807972]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=12.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=14.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=17.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.1%
Timestep  4: Avg Loss=0.000003, Std=0.000002, Contribution=33.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 33.8% (timestep 4)
Min contribution: 12.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 536 pred_label: 536 pred_clean_logit 0.9905998110771179
prompt generate:  dock  	labels:  [[536]]
decoder:  [49406, 8997, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([540], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([536], device='cuda:0') tensor(4.4844e-10, device='cuda:0')
L1: [6563.926]	L2: [28.788847]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=26.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 13 pred_label: 13 pred_clean_logit 0.9866503477096558
prompt generate:  junco  	labels:  [[13]]
decoder:  [49406, 1637, 1320, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([19], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([13], device='cuda:0') tensor(2.8365e-10, device='cuda:0')
L1: [4618.3135]	L2: [17.148226]	Linf: [0.43921572]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 580 pred_label: 580 pred_clean_logit 0.8455784916877747
prompt generate:  greenhouse  	labels:  [[580]]
decoder:  [49406, 20819, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([343], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([580], device='cuda:0') tensor(1.9991e-21, device='cuda:0')
L1: [12317.655]	L2: [43.261578]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=57.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.0% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 970 pred_label: 970 pred_clean_logit 0.993238091468811
prompt generate:  alp  	labels:  [[970]]
decoder:  [49406, 39342, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([143], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([970], device='cuda:0') tensor(3.0474e-15, device='cuda:0')
L1: [4490.965]	L2: [19.721037]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=56.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.4% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 719 pred_label: 719 pred_clean_logit 0.999998927116394
prompt generate:  piggy bank  	labels:  [[719]]
decoder:  [49406, 28245, 2723, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([719], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([719], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [8318.668]	L2: [32.406147]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=13.3%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.6%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 320 pred_label: 320 pred_clean_logit 0.9400641322135925
prompt generate:  damselfly  	labels:  [[320]]
decoder:  [49406, 1880, 1000, 3228, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([319], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([320], device='cuda:0') tensor(1.2139e-11, device='cuda:0')
L1: [3919.3257]	L2: [17.075703]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 437 pred_label: 437 pred_clean_logit 0.9975895881652832
prompt generate:  beacon  	labels:  [[437]]
decoder:  [49406, 18858, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([460], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([437], device='cuda:0') tensor(3.4260e-11, device='cuda:0')
L1: [4597.6553]	L2: [19.843805]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=59.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.0% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 990 pred_label: 990 pred_clean_logit 0.9954395890235901
prompt generate:  buckeye  	labels:  [[990]]
decoder:  [49406, 34549, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([738], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([990], device='cuda:0') tensor(4.2862e-13, device='cuda:0')
L1: [11080.198]	L2: [38.529064]	Linf: [0.71372545]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 685 pred_label: 479 pred_clean_logit 0.0420665517449379
prompt generate:  odometer  	labels:  [[479]]
decoder:  [49406, 78, 8515, 652, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([778], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([685], device='cuda:0') tensor(3.8597e-30, device='cuda:0')
L1: [9054.004]	L2: [37.52077]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 805 pred_label: 805 pred_clean_logit 0.9944520592689514
prompt generate:  soccer ball  	labels:  [[805]]
decoder:  [49406, 4233, 1069, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([645], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([805], device='cuda:0') tensor(1.0429e-20, device='cuda:0')
L1: [8110.407]	L2: [27.777975]	Linf: [0.7294117]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=27.6%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=49.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.6% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 580 pred_label: 580 pred_clean_logit 0.9856347441673279
prompt generate:  greenhouse  	labels:  [[580]]
decoder:  [49406, 20819, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([738], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([580], device='cuda:0') tensor(5.3226e-14, device='cuda:0')
L1: [12326.78]	L2: [45.183914]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 717 pred_label: 609 pred_clean_logit 0.19778166711330414
prompt generate:  pickup  	labels:  [[609]]
decoder:  [49406, 15382, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([609], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([717], device='cuda:0') tensor(1.5464e-22, device='cuda:0')
L1: [8976.631]	L2: [35.2673]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=43.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.4% (timestep 4)
Min contribution: 6.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 591 pred_label: 591 pred_clean_logit 0.9376627206802368
prompt generate:  handkerchief  	labels:  [[591]]
decoder:  [49406, 1722, 2352, 3455, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([619], device='cuda:0') tensor(0.9991, device='cuda:0')
after_true: tensor([591], device='cuda:0') tensor(8.5609e-09, device='cuda:0')
L1: [7582.376]	L2: [34.134968]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 955 pred_label: 951 pred_clean_logit 0.095697320997715
prompt generate:  jackfruit  	labels:  [[951]]
decoder:  [49406, 2679, 5190, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([957], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([955], device='cuda:0') tensor(1.1335e-20, device='cuda:0')
L1: [14857.497]	L2: [55.939842]	Linf: [0.92156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000009, Std=0.000002, Contribution=28.0%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 75 pred_label: 75 pred_clean_logit 0.8775942921638489
prompt generate:  black widow  	labels:  [[75]]
decoder:  [49406, 1449, 19949, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([72], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([75], device='cuda:0') tensor(8.5621e-18, device='cuda:0')
L1: [10524.075]	L2: [37.351128]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.9%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 832 pred_label: 832 pred_clean_logit 0.9999946355819702
prompt generate:  stupa  	labels:  [[832]]
decoder:  [49406, 858, 2217, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([832], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([832], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [8468.97]	L2: [33.54239]	Linf: [0.6588235]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.1%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=13.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.2%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 483 pred_label: 483 pred_clean_logit 0.5838974118232727
prompt generate:  castle  	labels:  [[483]]
decoder:  [49406, 3540, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([668], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([483], device='cuda:0') tensor(1.5250e-17, device='cuda:0')
L1: [10240.148]	L2: [42.889732]	Linf: [0.8980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 417 pred_label: 417 pred_clean_logit 0.9999140501022339
prompt generate:  balloon  	labels:  [[417]]
decoder:  [49406, 13634, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([712], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([417], device='cuda:0') tensor(3.4071e-09, device='cuda:0')
L1: [5156.9844]	L2: [23.099928]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 779 pred_label: 779 pred_clean_logit 0.9893472194671631
prompt generate:  school bus  	labels:  [[779]]
decoder:  [49406, 1228, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([829], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([779], device='cuda:0') tensor(1.2491e-13, device='cuda:0')
L1: [11213.734]	L2: [39.40342]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 698 pred_label: 538 pred_clean_logit 0.00039286792161874473
prompt generate:  palace  	labels:  [[538]]
decoder:  [49406, 6381, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([538], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([698], device='cuda:0') tensor(1.2973e-16, device='cuda:0')
L1: [8641.403]	L2: [36.67817]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=48.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.3% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 531 pred_label: 531 pred_clean_logit 0.9999167919158936
prompt generate:  digital watch  	labels:  [[531]]
decoder:  [49406, 2794, 1239, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([487], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([531], device='cuda:0') tensor(4.8361e-13, device='cuda:0')
L1: [6231.5176]	L2: [40.317116]	Linf: [0.9882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 703 pred_label: 612 pred_clean_logit 0.053224239498376846
prompt generate:  park bench  	labels:  [[612]]
decoder:  [49406, 1452, 8771, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([882], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([703], device='cuda:0') tensor(7.9567e-31, device='cuda:0')
L1: [9949.]	L2: [37.72659]	Linf: [0.972549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 922 pred_label: 922 pred_clean_logit 0.9986246824264526
prompt generate:  menu  	labels:  [[922]]
decoder:  [49406, 6225, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([415], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([922], device='cuda:0') tensor(2.5679e-23, device='cuda:0')
L1: [8018.832]	L2: [32.232758]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=46.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.5% (timestep 4)
Min contribution: 6.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 321 pred_label: 321 pred_clean_logit 0.9999778270721436
prompt generate:  admiral  	labels:  [[321]]
decoder:  [49406, 21013, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([321], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([321], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [4673.087]	L2: [18.341936]	Linf: [0.59607846]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=4.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=58.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.7% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 312 pred_label: 312 pred_clean_logit 0.9134262800216675
prompt generate:  cricket  	labels:  [[312]]
decoder:  [49406, 5373, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([311], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([312], device='cuda:0') tensor(4.6844e-13, device='cuda:0')
L1: [7415.079]	L2: [31.578638]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 480 pred_label: 480 pred_clean_logit 0.9866933226585388
prompt generate:  cash machine  	labels:  [[480]]
decoder:  [49406, 5131, 4169, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([648], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([480], device='cuda:0') tensor(1.8401e-17, device='cuda:0')
L1: [7526.45]	L2: [28.60224]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 324 pred_label: 323 pred_clean_logit 0.11940725892782211
prompt generate:  cabbage butterfly  	labels:  [[323]]
decoder:  [49406, 18407, 9738, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([620], device='cuda:0') tensor(0.9962, device='cuda:0')
after_true: tensor([324], device='cuda:0') tensor(6.8829e-17, device='cuda:0')
L1: [15098.424]	L2: [55.678345]	Linf: [0.95686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 667 pred_label: 819 pred_clean_logit 0.0022802159655839205
prompt generate:  mortarboard  	labels:  [[819]]
decoder:  [49406, 657, 2002, 1972, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([478], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([667], device='cuda:0') tensor(6.6583e-23, device='cuda:0')
L1: [7348.2793]	L2: [25.727915]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=27.3%
Timestep  4: Avg Loss=0.000015, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 603 pred_label: 603 pred_clean_logit 0.9999842643737793
prompt generate:  horse cart  	labels:  [[603]]
decoder:  [49406, 4558, 13065, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([603], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([603], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7332.153]	L2: [29.86139]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.9%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 417 pred_label: 417 pred_clean_logit 0.9998421669006348
prompt generate:  balloon  	labels:  [[417]]
decoder:  [49406, 13634, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([821], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([417], device='cuda:0') tensor(8.2803e-15, device='cuda:0')
L1: [5882.314]	L2: [25.09817]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000002, Std=0.000002, Contribution=22.5%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 759 pred_label: 759 pred_clean_logit 0.9976866245269775
prompt generate:  reflex camera  	labels:  [[759]]
decoder:  [49406, 36050, 3934, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([570], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([759], device='cuda:0') tensor(9.7337e-12, device='cuda:0')
L1: [7212.706]	L2: [33.568504]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 510 pred_label: 510 pred_clean_logit 0.9999995231628418
prompt generate:  container ship  	labels:  [[510]]
decoder:  [49406, 14913, 1158, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([510], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([510], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3783.3296]	L2: [16.261747]	Linf: [0.52156866]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.3%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.1%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 695 pred_label: 788 pred_clean_logit 0.04416026175022125
prompt generate:  padlock  	labels:  [[788]]
decoder:  [49406, 3798, 4381, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([667], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([695], device='cuda:0') tensor(2.0994e-24, device='cuda:0')
L1: [5633.114]	L2: [21.76525]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 525 pred_label: 525 pred_clean_logit 0.9209574460983276
prompt generate:  dam  	labels:  [[525]]
decoder:  [49406, 4926, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([839], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([525], device='cuda:0') tensor(3.0496e-17, device='cuda:0')
L1: [5799.369]	L2: [22.72154]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=58.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.4% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 308 pred_label: 308 pred_clean_logit 0.9999884366989136
prompt generate:  fly  	labels:  [[308]]
decoder:  [49406, 3228, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([309], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([308], device='cuda:0') tensor(1.4223e-15, device='cuda:0')
L1: [8815.792]	L2: [30.416702]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000009, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000019, Std=0.000005, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 142 pred_label: 142 pred_clean_logit 0.9990037083625793
prompt generate:  dowitcher  	labels:  [[142]]
decoder:  [49406, 639, 33684, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([129], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([142], device='cuda:0') tensor(9.9077e-09, device='cuda:0')
L1: [5831.757]	L2: [21.185884]	Linf: [0.56078434]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 897 pred_label: 897 pred_clean_logit 0.999981164932251
prompt generate:  washer  	labels:  [[897]]
decoder:  [49406, 24085, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([577], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([897], device='cuda:0') tensor(1.0206e-20, device='cuda:0')
L1: [7357.118]	L2: [28.648878]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=47.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.1% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 498 pred_label: 498 pred_clean_logit 0.6273851990699768
prompt generate:  cinema  	labels:  [[498]]
decoder:  [49406, 6443, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([687], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([498], device='cuda:0') tensor(2.4253e-18, device='cuda:0')
L1: [4925.1997]	L2: [22.524181]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=25.5%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=56.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.9% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 888 pred_label: 888 pred_clean_logit 0.9999767541885376
prompt generate:  viaduct  	labels:  [[888]]
decoder:  [49406, 39113, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([888], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([888], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [8497.627]	L2: [32.485176]	Linf: [0.6431372]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.3%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=22.7%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=56.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.2% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 303 pred_label: 303 pred_clean_logit 0.998991072177887
prompt generate:  long-horned beetle  	labels:  [[303]]
decoder:  [49406, 1538, 268, 34526, 16534, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([461], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([303], device='cuda:0') tensor(4.8513e-18, device='cuda:0')
L1: [7743.667]	L2: [36.70238]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 649 pred_label: 649 pred_clean_logit 0.9986827969551086
prompt generate:  megalith  	labels:  [[649]]
decoder:  [49406, 37650, 1757, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([818], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([649], device='cuda:0') tensor(7.9189e-21, device='cuda:0')
L1: [2779.8157]	L2: [12.116749]	Linf: [0.46666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=23.3%
Timestep  4: Avg Loss=0.000013, Std=0.000006, Contribution=58.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.3% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 406 pred_label: 917 pred_clean_logit 0.32614874839782715
prompt generate:  altar  	labels:  [[917]]
decoder:  [49406, 16385, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([894], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([406], device='cuda:0') tensor(2.1892e-22, device='cuda:0')
L1: [9466.86]	L2: [36.24445]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 841 pred_label: 841 pred_clean_logit 0.9999035596847534
prompt generate:  sweatshirt  	labels:  [[841]]
decoder:  [49406, 22442, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([451], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([841], device='cuda:0') tensor(3.2219e-18, device='cuda:0')
L1: [4547.5215]	L2: [19.174692]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000002, Std=0.000002, Contribution=21.2%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 37 pred_label: 37 pred_clean_logit 0.9998351335525513
prompt generate:  box turtle  	labels:  [[37]]
decoder:  [49406, 2063, 10912, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([36], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([37], device='cuda:0') tensor(2.3750e-09, device='cuda:0')
L1: [10658.49]	L2: [38.89839]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 320 pred_label: 320 pred_clean_logit 0.9949002861976624
prompt generate:  damselfly  	labels:  [[320]]
decoder:  [49406, 1880, 1000, 3228, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([319], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([320], device='cuda:0') tensor(5.1536e-09, device='cuda:0')
L1: [2764.73]	L2: [11.033726]	Linf: [0.3921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.8%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=58.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.4% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 580 pred_label: 124 pred_clean_logit 4.8821607379068155e-06
prompt generate:  greenhouse  	labels:  [[124]]
decoder:  [49406, 20819, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([124], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([580], device='cuda:0') tensor(8.3190e-32, device='cuda:0')
L1: [11740.632]	L2: [42.21365]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 950 pred_label: 950 pred_clean_logit 0.8942831158638
prompt generate:  orange  	labels:  [[950]]
decoder:  [49406, 4287, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([928], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([950], device='cuda:0') tensor(1.0490e-31, device='cuda:0')
L1: [5506.3726]	L2: [24.687214]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 821 pred_label: 821 pred_clean_logit 0.3734146058559418
prompt generate:  steel arch bridge  	labels:  [[821]]
decoder:  [49406, 4726, 8557, 2465, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([456], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([821], device='cuda:0') tensor(8.3272e-09, device='cuda:0')
L1: [2307.9216]	L2: [9.466654]	Linf: [0.40392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.6%
Timestep  4: Avg Loss=0.000006, Std=0.000001, Contribution=59.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.5% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 656 pred_label: 656 pred_clean_logit 0.8833780288696289
prompt generate:  minivan  	labels:  [[656]]
decoder:  [49406, 1810, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([656], device='cuda:0') tensor(2.0518e-13, device='cuda:0')
L1: [5303.855]	L2: [26.0977]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 665 pred_label: 665 pred_clean_logit 0.9894722104072571
prompt generate:  moped  	labels:  [[665]]
decoder:  [49406, 617, 2966, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([518], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([665], device='cuda:0') tensor(2.3284e-18, device='cuda:0')
L1: [9969.567]	L2: [41.507557]	Linf: [0.89411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 805 pred_label: 805 pred_clean_logit 0.9999960660934448
prompt generate:  soccer ball  	labels:  [[805]]
decoder:  [49406, 4233, 1069, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([805], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([805], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [8261.564]	L2: [32.633804]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=25.2%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=45.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.3% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 467 pred_label: 467 pred_clean_logit 0.9988794922828674
prompt generate:  butcher shop  	labels:  [[467]]
decoder:  [49406, 18732, 1557, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([942], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([467], device='cuda:0') tensor(4.3949e-23, device='cuda:0')
L1: [5788.216]	L2: [21.750584]	Linf: [0.5372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=58.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.9% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 949 pred_label: 949 pred_clean_logit 0.994217038154602
prompt generate:  strawberry  	labels:  [[949]]
decoder:  [49406, 10233, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([928], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([949], device='cuda:0') tensor(4.3000e-11, device='cuda:0')
L1: [3792.5737]	L2: [18.574923]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=20.1%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=61.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 61.0% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 471 pred_label: 612 pred_clean_logit 0.00010604959970805794
prompt generate:  cannon  	labels:  [[612]]
decoder:  [49406, 15661, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([431], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([471], device='cuda:0') tensor(1.6384e-21, device='cuda:0')
L1: [7970.0117]	L2: [31.107588]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.8%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=24.6%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 16 pred_label: 16 pred_clean_logit 0.9999977350234985
prompt generate:  bulbul  	labels:  [[16]]
decoder:  [49406, 2572, 10200, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([16], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([16], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2553.4438]	L2: [10.7051735]	Linf: [0.3803922]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.2%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=11.4%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=20.4%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 646 pred_label: 646 pred_clean_logit 0.9987748265266418
prompt generate:  maze  	labels:  [[646]]
decoder:  [49406, 21988, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([888], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([646], device='cuda:0') tensor(1.0418e-16, device='cuda:0')
L1: [11860.926]	L2: [41.86325]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=57.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.4% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 985 pred_label: 985 pred_clean_logit 0.9987509250640869
prompt generate:  daisy  	labels:  [[985]]
decoder:  [49406, 12865, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([539], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([985], device='cuda:0') tensor(1.7479e-11, device='cuda:0')
L1: [12795.928]	L2: [43.436142]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 949 pred_label: 949 pred_clean_logit 0.9995511174201965
prompt generate:  strawberry  	labels:  [[949]]
decoder:  [49406, 10233, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([949], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([949], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [4917.879]	L2: [18.513103]	Linf: [0.6]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=59.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.8% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 917 pred_label: 917 pred_clean_logit 0.9918225407600403
prompt generate:  comic book  	labels:  [[917]]
decoder:  [49406, 4962, 1116, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([481], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([917], device='cuda:0') tensor(1.3266e-13, device='cuda:0')
L1: [11628.706]	L2: [48.404354]	Linf: [0.9490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=15.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=45.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.6% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 866 pred_label: 866 pred_clean_logit 0.9821944832801819
prompt generate:  tractor  	labels:  [[866]]
decoder:  [49406, 14607, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([803], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([866], device='cuda:0') tensor(1.7139e-12, device='cuda:0')
L1: [10554.568]	L2: [41.446583]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 703 pred_label: 703 pred_clean_logit 0.9994285702705383
prompt generate:  park bench  	labels:  [[703]]
decoder:  [49406, 1452, 8771, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([706], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([703], device='cuda:0') tensor(2.0360e-16, device='cuda:0')
L1: [10561.751]	L2: [36.953312]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 874 pred_label: 874 pred_clean_logit 0.9998093247413635
prompt generate:  trolleybus  	labels:  [[874]]
decoder:  [49406, 10306, 2565, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([705], device='cuda:0') tensor(0.9993, device='cuda:0')
after_true: tensor([874], device='cuda:0') tensor(2.6246e-07, device='cuda:0')
L1: [7533.5645]	L2: [30.531704]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 144 pred_label: 144 pred_clean_logit 0.999904990196228
prompt generate:  pelican  	labels:  [[144]]
decoder:  [49406, 34131, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([146], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([144], device='cuda:0') tensor(1.0544e-18, device='cuda:0')
L1: [7162.917]	L2: [27.476864]	Linf: [0.6352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 930 pred_label: 930 pred_clean_logit 0.9984903335571289
prompt generate:  French loaf  	labels:  [[930]]
decoder:  [49406, 3461, 18273, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([994], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([930], device='cuda:0') tensor(9.3379e-13, device='cuda:0')
L1: [5627.153]	L2: [21.260994]	Linf: [0.47058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.1%
Timestep  4: Avg Loss=0.000012, Std=0.000005, Contribution=59.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.8% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 825 pred_label: 825 pred_clean_logit 0.6059644818305969
prompt generate:  stone wall  	labels:  [[825]]
decoder:  [49406, 2441, 2569, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([150], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([825], device='cuda:0') tensor(1.1325e-21, device='cuda:0')
L1: [12129.628]	L2: [40.976944]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=25.8%
Timestep  4: Avg Loss=0.000019, Std=0.000006, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 663 pred_label: 663 pred_clean_logit 0.8703387975692749
prompt generate:  monastery  	labels:  [[663]]
decoder:  [49406, 21850, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([497], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([663], device='cuda:0') tensor(2.1620e-12, device='cuda:0')
L1: [9120.815]	L2: [34.38881]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=56.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.2% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 858 pred_label: 858 pred_clean_logit 0.8173926472663879
prompt generate:  tile roof  	labels:  [[858]]
decoder:  [49406, 8227, 6449, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([428], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([858], device='cuda:0') tensor(1.7406e-32, device='cuda:0')
L1: [6902.969]	L2: [28.561504]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 489 pred_label: 489 pred_clean_logit 0.9981354475021362
prompt generate:  chainlink fence  	labels:  [[489]]
decoder:  [49406, 13898, 2468, 12679, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([177], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([489], device='cuda:0') tensor(4.5624e-23, device='cuda:0')
L1: [12716.004]	L2: [44.4795]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=57.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.1% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 616 pred_label: 60 pred_clean_logit 0.00011148564954055473
prompt generate:  knot  	labels:  [[60]]
decoder:  [49406, 18412, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([679], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([616], device='cuda:0') tensor(6.2243e-12, device='cuda:0')
L1: [9316.09]	L2: [36.82956]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 820 pred_label: 866 pred_clean_logit 0.026318661868572235
prompt generate:  steam locomotive  	labels:  [[866]]
decoder:  [49406, 6972, 30439, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([471], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([820], device='cuda:0') tensor(4.3982e-14, device='cuda:0')
L1: [6099.949]	L2: [24.013433]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 319 pred_label: 319 pred_clean_logit 0.9999967813491821
prompt generate:  dragonfly  	labels:  [[319]]
decoder:  [49406, 32824, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([308], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([319], device='cuda:0') tensor(6.7881e-17, device='cuda:0')
L1: [3526.2944]	L2: [22.137384]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=56.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.9% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 843 pred_label: 395 pred_clean_logit 0.05707969143986702
prompt generate:  swing  	labels:  [[395]]
decoder:  [49406, 7429, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([395], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([843], device='cuda:0') tensor(3.0041e-22, device='cuda:0')
L1: [6718.1494]	L2: [23.997046]	Linf: [0.69019604]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 547 pred_label: 547 pred_clean_logit 0.9977954626083374
prompt generate:  electric locomotive  	labels:  [[547]]
decoder:  [49406, 5031, 30439, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([705], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([547], device='cuda:0') tensor(3.0493e-09, device='cuda:0')
L1: [8466.722]	L2: [36.168926]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 437 pred_label: 437 pred_clean_logit 0.7933676242828369
prompt generate:  beacon  	labels:  [[437]]
decoder:  [49406, 18858, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([863], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([437], device='cuda:0') tensor(1.5707e-20, device='cuda:0')
L1: [2807.1172]	L2: [11.66819]	Linf: [0.3764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=13.1%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=24.7%
Timestep  4: Avg Loss=0.000019, Std=0.000005, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 668 pred_label: 668 pred_clean_logit 0.39873000979423523
prompt generate:  mosque  	labels:  [[668]]
decoder:  [49406, 12694, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([480], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([668], device='cuda:0') tensor(3.6957e-13, device='cuda:0')
L1: [4658.929]	L2: [21.900726]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=7.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=49.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.3% (timestep 4)
Min contribution: 7.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 521 pred_label: 521 pred_clean_logit 0.9999974966049194
prompt generate:  Crock Pot  	labels:  [[521]]
decoder:  [49406, 1192, 868, 5168, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([886], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([521], device='cuda:0') tensor(1.6820e-15, device='cuda:0')
L1: [7587.4]	L2: [34.645245]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=45.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.4% (timestep 4)
Min contribution: 6.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 652 pred_label: 737 pred_clean_logit 0.034694746136665344
prompt generate:  military uniform  	labels:  [[737]]
decoder:  [49406, 4323, 11075, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([737], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([652], device='cuda:0') tensor(4.6191e-20, device='cuda:0')
L1: [9237.654]	L2: [36.843956]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 646 pred_label: 646 pred_clean_logit 0.9999991655349731
prompt generate:  maze  	labels:  [[646]]
decoder:  [49406, 21988, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([816], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([646], device='cuda:0') tensor(3.1584e-19, device='cuda:0')
L1: [12284.326]	L2: [45.4373]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.1%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=61.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 61.1% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 882 pred_label: 882 pred_clean_logit 0.9999986886978149
prompt generate:  vacuum  	labels:  [[882]]
decoder:  [49406, 18420, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([665], device='cuda:0') tensor(0.9857, device='cuda:0')
after_true: tensor([882], device='cuda:0') tensor(7.4006e-14, device='cuda:0')
L1: [5995.662]	L2: [24.25465]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.3%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 402 pred_label: 402 pred_clean_logit 0.9656118154525757
prompt generate:  acoustic guitar  	labels:  [[402]]
decoder:  [49406, 10616, 5084, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([835], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([402], device='cuda:0') tensor(7.4257e-14, device='cuda:0')
L1: [5037.605]	L2: [20.730547]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 890 pred_label: 890 pred_clean_logit 0.5446279048919678
prompt generate:  volleyball  	labels:  [[890]]
decoder:  [49406, 7458, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([430], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([890], device='cuda:0') tensor(7.3424e-12, device='cuda:0')
L1: [5307.137]	L2: [23.48941]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=23.4%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 749 pred_label: 749 pred_clean_logit 0.9794368147850037
prompt generate:  quill  	labels:  [[749]]
decoder:  [49406, 48951, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([456], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([749], device='cuda:0') tensor(3.1154e-19, device='cuda:0')
L1: [3957.2036]	L2: [17.45523]	Linf: [0.4666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=22.7%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=58.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.5% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 825 pred_label: 865 pred_clean_logit 0.049231547862291336
prompt generate:  stone wall  	labels:  [[865]]
decoder:  [49406, 2441, 2569, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([406], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([825], device='cuda:0') tensor(2.9795e-20, device='cuda:0')
L1: [14442.286]	L2: [51.29986]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 817 pred_label: 817 pred_clean_logit 0.9993270635604858
prompt generate:  sports car  	labels:  [[817]]
decoder:  [49406, 2054, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([511], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([817], device='cuda:0') tensor(2.2436e-11, device='cuda:0')
L1: [6553.961]	L2: [29.952078]	Linf: [0.8980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=48.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.3% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 471 pred_label: 471 pred_clean_logit 0.9999980926513672
prompt generate:  cannon  	labels:  [[471]]
decoder:  [49406, 15661, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([471], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([471], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7644.463]	L2: [28.556494]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.6%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=15.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.0%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=45.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.6% (timestep 4)
Min contribution: 6.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 675 pred_label: 675 pred_clean_logit 0.999854326248169
prompt generate:  moving van  	labels:  [[675]]
decoder:  [49406, 3584, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([407], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([675], device='cuda:0') tensor(2.8021e-13, device='cuda:0')
L1: [6355.667]	L2: [30.083572]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000006, Std=0.000004, Contribution=44.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.8% (timestep 4)
Min contribution: 7.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 733 pred_label: 733 pred_clean_logit 0.9493274092674255
prompt generate:  pole  	labels:  [[733]]
decoder:  [49406, 8170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([112], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([733], device='cuda:0') tensor(3.5625e-32, device='cuda:0')
L1: [7177.1997]	L2: [27.439417]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000005, Std=0.000003, Contribution=11.6%
Timestep  3: Avg Loss=0.000011, Std=0.000005, Contribution=25.7%
Timestep  4: Avg Loss=0.000024, Std=0.000011, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 858 pred_label: 673 pred_clean_logit 0.021228397265076637
prompt generate:  tile roof  	labels:  [[673]]
decoder:  [49406, 8227, 6449, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([508], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([858], device='cuda:0') tensor(1.9446e-14, device='cuda:0')
L1: [7670.134]	L2: [37.42794]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=48.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.4% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 322 pred_label: 322 pred_clean_logit 0.9996637105941772
prompt generate:  ringlet  	labels:  [[322]]
decoder:  [49406, 8318, 1094, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([326], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([322], device='cuda:0') tensor(9.6384e-11, device='cuda:0')
L1: [5923.7886]	L2: [22.930223]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000007, Std=0.000004, Contribution=54.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.5% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 912 pred_label: 637 pred_clean_logit 0.2590751051902771
prompt generate:  worm fence  	labels:  [[637]]
decoder:  [49406, 10945, 12679, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([447], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([912], device='cuda:0') tensor(6.6558e-23, device='cuda:0')
L1: [7564.8125]	L2: [27.54441]	Linf: [0.5882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 933 pred_label: 938 pred_clean_logit 0.02602308616042137
prompt generate:  cheeseburger  	labels:  [[938]]
decoder:  [49406, 41200, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([928], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([933], device='cuda:0') tensor(9.1445e-27, device='cuda:0')
L1: [7021.4946]	L2: [27.54798]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 302 pred_label: 302 pred_clean_logit 0.9998722076416016
prompt generate:  ground beetle  	labels:  [[302]]
decoder:  [49406, 2461, 16534, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([307], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([302], device='cuda:0') tensor(4.0452e-09, device='cuda:0')
L1: [7337.51]	L2: [26.110495]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=59.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.0% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 768 pred_label: 880 pred_clean_logit 0.02052236720919609
prompt generate:  rugby ball  	labels:  [[880]]
decoder:  [49406, 4964, 1069, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([880], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([768], device='cuda:0') tensor(2.3373e-17, device='cuda:0')
L1: [6554.3022]	L2: [30.775719]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=59.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.4% (timestep 4)
Min contribution: 1.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 766 pred_label: 509 pred_clean_logit 0.04484105482697487
prompt generate:  rotisserie  	labels:  [[509]]
decoder:  [49406, 532, 28155, 7005, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([938], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([766], device='cuda:0') tensor(2.2396e-30, device='cuda:0')
L1: [10146.985]	L2: [37.216587]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000005, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000010, Std=0.000003, Contribution=25.2%
Timestep  4: Avg Loss=0.000022, Std=0.000005, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 442 pred_label: 442 pred_clean_logit 0.9955072402954102
prompt generate:  bell cote  	labels:  [[442]]
decoder:  [49406, 3718, 20751, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([663], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([442], device='cuda:0') tensor(2.0960e-13, device='cuda:0')
L1: [6720.498]	L2: [31.429266]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 911 pred_label: 911 pred_clean_logit 0.8368636965751648
prompt generate:  wool  	labels:  [[911]]
decoder:  [49406, 13283, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([463], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([911], device='cuda:0') tensor(1.2171e-21, device='cuda:0')
L1: [6602.542]	L2: [27.643732]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.5%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=16.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=45.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.4% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 974 pred_label: 974 pred_clean_logit 0.999921441078186
prompt generate:  geyser  	labels:  [[974]]
decoder:  [49406, 619, 33121, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([974], device='cuda:0') tensor(0.9995, device='cuda:0')
after_true: tensor([974], device='cuda:0') tensor(0.9995, device='cuda:0')
L1: [2787.0273]	L2: [13.755018]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.2%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.6%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.4%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 511 pred_label: 511 pred_clean_logit 0.9997277855873108
prompt generate:  convertible  	labels:  [[511]]
decoder:  [49406, 19608, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([751], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([511], device='cuda:0') tensor(6.8789e-20, device='cuda:0')
L1: [8103.867]	L2: [35.0873]	Linf: [0.8156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 640 pred_label: 640 pred_clean_logit 0.8791964054107666
prompt generate:  manhole cover  	labels:  [[640]]
decoder:  [49406, 723, 5341, 2202, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([835], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([640], device='cuda:0') tensor(3.6130e-13, device='cuda:0')
L1: [9867.91]	L2: [36.520744]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 582 pred_label: 582 pred_clean_logit 0.9563261270523071
prompt generate:  grocery store  	labels:  [[582]]
decoder:  [49406, 13826, 2183, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([734], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([582], device='cuda:0') tensor(8.2179e-22, device='cuda:0')
L1: [12168.949]	L2: [46.209652]	Linf: [0.9098039]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 661 pred_label: 661 pred_clean_logit 0.9990150928497314
prompt generate:  Model T  	labels:  [[661]]
decoder:  [49406, 2863, 339, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([609], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([661], device='cuda:0') tensor(3.2087e-23, device='cuda:0')
L1: [8371.663]	L2: [41.3821]	Linf: [0.90588236]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=43.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.3% (timestep 4)
Min contribution: 8.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 259 pred_label: 259 pred_clean_logit 0.9997252821922302
prompt generate:  Pomeranian  	labels:  [[259]]
decoder:  [49406, 35156, 9945, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([263], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([259], device='cuda:0') tensor(6.6190e-14, device='cuda:0')
L1: [4042.6433]	L2: [14.11861]	Linf: [0.36078432]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=24.1%
Timestep  4: Avg Loss=0.000011, Std=0.000006, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 99 pred_label: 99 pred_clean_logit 0.8606724143028259
prompt generate:  goose  	labels:  [[99]]
decoder:  [49406, 13822, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([97], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([99], device='cuda:0') tensor(8.7121e-16, device='cuda:0')
L1: [15168.928]	L2: [51.48412]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 323 pred_label: 324 pred_clean_logit 0.08941610157489777
prompt generate:  monarch  	labels:  [[324]]
decoder:  [49406, 22619, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([862], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([323], device='cuda:0') tensor(7.2663e-33, device='cuda:0')
L1: [6127.2393]	L2: [25.429188]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 497 pred_label: 497 pred_clean_logit 0.5860657095909119
prompt generate:  church  	labels:  [[497]]
decoder:  [49406, 2735, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([800], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([497], device='cuda:0') tensor(2.9171e-20, device='cuda:0')
L1: [18321.275]	L2: [70.3351]	Linf: [0.9372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=46.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.5% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 980 pred_label: 90 pred_clean_logit 0.000943479361012578
prompt generate:  volcano  	labels:  [[90]]
decoder:  [49406, 14581, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([1], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([980], device='cuda:0') tensor(1.4118e-18, device='cuda:0')
L1: [7334.7017]	L2: [28.698883]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 8 pred_label: 8 pred_clean_logit 0.3761666417121887
prompt generate:  hen  	labels:  [[8]]
decoder:  [49406, 8047, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([87], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([8], device='cuda:0') tensor(1.9682e-17, device='cuda:0')
L1: [8748.808]	L2: [30.783127]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000019, Std=0.000005, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 919 pred_label: 919 pred_clean_logit 0.9999768733978271
prompt generate:  street sign  	labels:  [[919]]
decoder:  [49406, 2012, 2292, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([919], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([919], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [9351.459]	L2: [32.49301]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 762 pred_label: 498 pred_clean_logit 0.37901830673217773
prompt generate:  restaurant  	labels:  [[498]]
decoder:  [49406, 4489, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([498], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([762], device='cuda:0') tensor(1.0133e-19, device='cuda:0')
L1: [7176.8354]	L2: [30.582775]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 454 pred_label: 454 pred_clean_logit 0.9992154836654663
prompt generate:  bookshop  	labels:  [[454]]
decoder:  [49406, 24705, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([799], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([454], device='cuda:0') tensor(2.7903e-16, device='cuda:0')
L1: [7251.4785]	L2: [28.770058]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 430 pred_label: 430 pred_clean_logit 0.9999947547912598
prompt generate:  basketball  	labels:  [[430]]
decoder:  [49406, 3835, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([430], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([430], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [4848.478]	L2: [20.213194]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.7%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=50.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.0% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 100 pred_label: 100 pred_clean_logit 0.9999767541885376
prompt generate:  black swan  	labels:  [[100]]
decoder:  [49406, 1449, 12530, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([100], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([100], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [3415.6118]	L2: [15.401386]	Linf: [0.46666664]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.6%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.4%
Timestep  4: Avg Loss=0.000002, Std=0.000000, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 120 pred_label: 120 pred_clean_logit 0.1733296513557434
prompt generate:  fiddler crab  	labels:  [[120]]
decoder:  [49406, 25218, 1803, 11574, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([81], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([120], device='cuda:0') tensor(5.1332e-15, device='cuda:0')
L1: [6469.985]	L2: [23.84837]	Linf: [0.4745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 737 pred_label: 898 pred_clean_logit 0.08793287724256516
prompt generate:  pop bottle  	labels:  [[898]]
decoder:  [49406, 2852, 5392, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([898], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([737], device='cuda:0') tensor(7.4908e-19, device='cuda:0')
L1: [8601.847]	L2: [35.64344]	Linf: [0.9098039]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=9.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=12.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=16.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.9%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=38.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 38.8% (timestep 4)
Min contribution: 9.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 404 pred_label: 404 pred_clean_logit 0.9830785393714905
prompt generate:  airliner  	labels:  [[404]]
decoder:  [49406, 1281, 11618, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([908], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([404], device='cuda:0') tensor(7.2444e-08, device='cuda:0')
L1: [2402.0552]	L2: [13.384949]	Linf: [0.65882355]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 455 pred_label: 893 pred_clean_logit 0.007980951108038425
prompt generate:  bottlecap  	labels:  [[893]]
decoder:  [49406, 37306, 3938, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([893], device='cuda:0') tensor(0.6239, device='cuda:0')
after_true: tensor([455], device='cuda:0') tensor(5.7671e-15, device='cuda:0')
L1: [10538.806]	L2: [35.51606]	Linf: [0.5764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.6%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.2%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 6.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 879 pred_label: 879 pred_clean_logit 0.9999449253082275
prompt generate:  umbrella  	labels:  [[879]]
decoder:  [49406, 17143, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([229], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([879], device='cuda:0') tensor(1.2658e-13, device='cuda:0')
L1: [8921.305]	L2: [39.32331]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 399 pred_label: 610 pred_clean_logit 0.05135873332619667
prompt generate:  abaya  	labels:  [[610]]
decoder:  [49406, 596, 5917, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([610], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([399], device='cuda:0') tensor(5.2548e-15, device='cuda:0')
L1: [3985.4824]	L2: [23.65668]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 640 pred_label: 401 pred_clean_logit 5.917044632042234e-09
prompt generate:  manhole cover  	labels:  [[401]]
decoder:  [49406, 723, 5341, 2202, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([401], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([640], device='cuda:0') tensor(4.0005e-24, device='cuda:0')
L1: [9385.49]	L2: [37.466022]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=50.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.0% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 829 pred_label: 829 pred_clean_logit 0.9969789981842041
prompt generate:  streetcar  	labels:  [[829]]
decoder:  [49406, 34268, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([475], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([829], device='cuda:0') tensor(3.5387e-18, device='cuda:0')
L1: [9987.455]	L2: [38.128277]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=49.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.6% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 890 pred_label: 890 pred_clean_logit 0.9999881982803345
prompt generate:  volleyball  	labels:  [[890]]
decoder:  [49406, 7458, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([645], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([890], device='cuda:0') tensor(1.8634e-10, device='cuda:0')
L1: [13111.155]	L2: [45.12487]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.3%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.8%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 975 pred_label: 975 pred_clean_logit 0.9954250454902649
prompt generate:  lakeside  	labels:  [[975]]
decoder:  [49406, 30915, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([979], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([975], device='cuda:0') tensor(1.9106e-09, device='cuda:0')
L1: [8713.031]	L2: [34.366493]	Linf: [0.61960787]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.4%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 975 pred_label: 703 pred_clean_logit 0.07209376990795135
prompt generate:  lakeside  	labels:  [[703]]
decoder:  [49406, 30915, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([703], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([975], device='cuda:0') tensor(1.1103e-18, device='cuda:0')
L1: [12594.443]	L2: [45.698734]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 980 pred_label: 980 pred_clean_logit 0.9988920092582703
prompt generate:  volcano  	labels:  [[980]]
decoder:  [49406, 14581, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([862], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([980], device='cuda:0') tensor(2.0770e-18, device='cuda:0')
L1: [1626.6906]	L2: [9.382445]	Linf: [0.5529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=20.7%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=60.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.0% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 130 pred_label: 130 pred_clean_logit 0.8761715888977051
prompt generate:  flamingo  	labels:  [[130]]
decoder:  [49406, 30323, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([128], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([130], device='cuda:0') tensor(6.0337e-15, device='cuda:0')
L1: [5749.9243]	L2: [22.22102]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000007, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000016, Std=0.000003, Contribution=57.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.6% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 535 pred_label: 535 pred_clean_logit 0.929451584815979
prompt generate:  disk brake  	labels:  [[535]]
decoder:  [49406, 17970, 14937, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([328], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([535], device='cuda:0') tensor(1.2722e-16, device='cuda:0')
L1: [5400.4907]	L2: [31.13478]	Linf: [0.99607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 142 pred_label: 140 pred_clean_logit 0.06124962493777275
prompt generate:  dowitcher  	labels:  [[140]]
decoder:  [49406, 639, 33684, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([140], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([142], device='cuda:0') tensor(1.1540e-15, device='cuda:0')
L1: [8287.7295]	L2: [31.673315]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 344 pred_label: 344 pred_clean_logit 0.6640994548797607
prompt generate:  hippopotamus  	labels:  [[344]]
decoder:  [49406, 28398, 45825, 718, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([611], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([344], device='cuda:0') tensor(9.0066e-21, device='cuda:0')
L1: [9230.549]	L2: [34.440434]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=56.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.5% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 807 pred_label: 807 pred_clean_logit 0.8774661421775818
prompt generate:  solar dish  	labels:  [[807]]
decoder:  [49406, 5199, 4531, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([706], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([807], device='cuda:0') tensor(4.3047e-19, device='cuda:0')
L1: [9498.565]	L2: [37.971565]	Linf: [0.8156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=49.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.8% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 325 pred_label: 325 pred_clean_logit 0.9998631477355957
prompt generate:  sulphur butterfly  	labels:  [[325]]
decoder:  [49406, 47659, 9738, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([324], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([325], device='cuda:0') tensor(1.3832e-11, device='cuda:0')
L1: [6771.768]	L2: [23.49973]	Linf: [0.5568627]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=49.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.6% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 661 pred_label: 661 pred_clean_logit 0.9996899366378784
prompt generate:  Model T  	labels:  [[661]]
decoder:  [49406, 2863, 339, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([803], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([661], device='cuda:0') tensor(1.8780e-14, device='cuda:0')
L1: [5800.8784]	L2: [24.911968]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 479 pred_label: 479 pred_clean_logit 0.9985999464988708
prompt generate:  car wheel  	labels:  [[479]]
decoder:  [49406, 1615, 6744, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([518], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([479], device='cuda:0') tensor(2.3673e-12, device='cuda:0')
L1: [4933.1104]	L2: [22.201294]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 479 pred_label: 479 pred_clean_logit 0.9418065547943115
prompt generate:  car wheel  	labels:  [[479]]
decoder:  [49406, 1615, 6744, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([535], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([479], device='cuda:0') tensor(6.4294e-08, device='cuda:0')
L1: [5489.1807]	L2: [22.005266]	Linf: [0.5921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.6%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 738 pred_label: 738 pred_clean_logit 0.9772093296051025
prompt generate:  pot  	labels:  [[738]]
decoder:  [49406, 5168, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([883], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([738], device='cuda:0') tensor(7.4489e-13, device='cuda:0')
L1: [8917.973]	L2: [39.23569]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 805 pred_label: 805 pred_clean_logit 0.9195852279663086
prompt generate:  soccer ball  	labels:  [[805]]
decoder:  [49406, 4233, 1069, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([890], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([805], device='cuda:0') tensor(4.0840e-10, device='cuda:0')
L1: [7332.7188]	L2: [28.044498]	Linf: [0.6509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 828 pred_label: 828 pred_clean_logit 0.4456053078174591
prompt generate:  strainer  	labels:  [[828]]
decoder:  [49406, 1894, 5155, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([677], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([828], device='cuda:0') tensor(4.9486e-22, device='cuda:0')
L1: [14564.564]	L2: [51.9695]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=27.0%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=45.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.4% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 597 pred_label: 570 pred_clean_logit 6.954539912840119e-06
prompt generate:  holster  	labels:  [[570]]
decoder:  [49406, 1187, 881, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([891], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([597], device='cuda:0') tensor(8.3606e-26, device='cuda:0')
L1: [8244.941]	L2: [32.358456]	Linf: [0.98039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=50.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.0% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 425 pred_label: 425 pred_clean_logit 0.9997956156730652
prompt generate:  barn  	labels:  [[425]]
decoder:  [49406, 10942, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([716], device='cuda:0') tensor(0.9583, device='cuda:0')
after_true: tensor([425], device='cuda:0') tensor(2.2594e-06, device='cuda:0')
L1: [10425.1]	L2: [36.365448]	Linf: [0.56470585]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=57.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.5% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 946 pred_label: 127 pred_clean_logit 0.01594463177025318
prompt generate:  cardoon  	labels:  [[127]]
decoder:  [49406, 811, 36612, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([328], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([946], device='cuda:0') tensor(7.9689e-17, device='cuda:0')
L1: [4172.569]	L2: [23.781517]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 5.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 628 pred_label: 814 pred_clean_logit 0.13112179934978485
prompt generate:  liner  	labels:  [[814]]
decoder:  [49406, 11618, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([814], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([628], device='cuda:0') tensor(2.3478e-18, device='cuda:0')
L1: [5396.3535]	L2: [22.579582]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 759 pred_label: 759 pred_clean_logit 0.999818742275238
prompt generate:  reflex camera  	labels:  [[759]]
decoder:  [49406, 36050, 3934, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([759], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([759], device='cuda:0') tensor(0.9997, device='cuda:0')
L1: [5242.3257]	L2: [29.736694]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=7.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=11.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.8%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=42.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.7% (timestep 4)
Min contribution: 7.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 532 pred_label: 526 pred_clean_logit 0.18519890308380127
prompt generate:  dining table  	labels:  [[526]]
decoder:  [49406, 8658, 2175, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([526], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([532], device='cuda:0') tensor(6.4801e-16, device='cuda:0')
L1: [5869.7017]	L2: [26.564648]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=10.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=15.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=41.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.7% (timestep 4)
Min contribution: 8.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 865 pred_label: 865 pred_clean_logit 0.9838108420372009
prompt generate:  toyshop  	labels:  [[865]]
decoder:  [49406, 14387, 1557, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([398], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([865], device='cuda:0') tensor(5.6653e-32, device='cuda:0')
L1: [10516.801]	L2: [38.38099]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=27.5%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 468 pred_label: 468 pred_clean_logit 0.9999492168426514
prompt generate:  cab  	labels:  [[468]]
decoder:  [49406, 11912, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([511], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([468], device='cuda:0') tensor(1.7463e-16, device='cuda:0')
L1: [10564.474]	L2: [43.52143]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=15.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=45.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.8% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 895 pred_label: 895 pred_clean_logit 0.9335981607437134
prompt generate:  warplane  	labels:  [[895]]
decoder:  [49406, 984, 5363, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([403], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([895], device='cuda:0') tensor(8.9561e-12, device='cuda:0')
L1: [5285.5415]	L2: [23.290606]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 309 pred_label: 309 pred_clean_logit 0.992643415927887
prompt generate:  bee  	labels:  [[309]]
decoder:  [49406, 5028, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([308], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([309], device='cuda:0') tensor(3.0277e-14, device='cuda:0')
L1: [4650.8154]	L2: [18.833109]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 656 pred_label: 656 pred_clean_logit 0.9963498115539551
prompt generate:  minivan  	labels:  [[656]]
decoder:  [49406, 1810, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([656], device='cuda:0') tensor(4.5245e-15, device='cuda:0')
L1: [5766.0503]	L2: [24.48876]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=9.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=46.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.3% (timestep 4)
Min contribution: 5.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 581 pred_label: 581 pred_clean_logit 0.949817955493927
prompt generate:  grille  	labels:  [[581]]
decoder:  [49406, 34748, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([581], device='cuda:0') tensor(2.2918e-14, device='cuda:0')
L1: [8168.467]	L2: [30.779772]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 468 pred_label: 468 pred_clean_logit 0.8685001134872437
prompt generate:  cab  	labels:  [[468]]
decoder:  [49406, 11912, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([675], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([468], device='cuda:0') tensor(7.7201e-17, device='cuda:0')
L1: [7330.106]	L2: [29.948816]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=48.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.9% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 239 pred_label: 239 pred_clean_logit 0.9729154109954834
prompt generate:  Bernese mountain dog  	labels:  [[239]]
decoder:  [49406, 867, 32220, 3965, 1929, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([240], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([239], device='cuda:0') tensor(2.1509e-13, device='cuda:0')
L1: [9858.448]	L2: [39.151585]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000010, Std=0.000005, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 565 pred_label: 565 pred_clean_logit 0.9999598264694214
prompt generate:  freight car  	labels:  [[565]]
decoder:  [49406, 17023, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([820], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([565], device='cuda:0') tensor(3.7310e-11, device='cuda:0')
L1: [10345.813]	L2: [41.749706]	Linf: [0.9098039]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 692 pred_label: 692 pred_clean_logit 0.9999041557312012
prompt generate:  packet  	labels:  [[692]]
decoder:  [49406, 25022, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([637], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([692], device='cuda:0') tensor(5.1806e-19, device='cuda:0')
L1: [6582.326]	L2: [26.54811]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 895 pred_label: 895 pred_clean_logit 0.4657135605812073
prompt generate:  warplane  	labels:  [[895]]
decoder:  [49406, 984, 5363, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([847], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([895], device='cuda:0') tensor(2.8549e-11, device='cuda:0')
L1: [3008.8079]	L2: [13.429295]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 597 pred_label: 597 pred_clean_logit 0.9978390336036682
prompt generate:  holster  	labels:  [[597]]
decoder:  [49406, 1187, 881, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([763], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([597], device='cuda:0') tensor(1.4396e-14, device='cuda:0')
L1: [5265.635]	L2: [19.817616]	Linf: [0.57254905]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 858 pred_label: 858 pred_clean_logit 0.5744660496711731
prompt generate:  tile roof  	labels:  [[858]]
decoder:  [49406, 8227, 6449, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([537], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([858], device='cuda:0') tensor(2.5497e-17, device='cuda:0')
L1: [8849.77]	L2: [35.282852]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 632 pred_label: 632 pred_clean_logit 0.9871234893798828
prompt generate:  loudspeaker  	labels:  [[632]]
decoder:  [49406, 22884, 4914, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([485], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([632], device='cuda:0') tensor(2.3119e-13, device='cuda:0')
L1: [3181.435]	L2: [19.582924]	Linf: [0.9529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=25.4%
Timestep  4: Avg Loss=0.000011, Std=0.000005, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 967 pred_label: 967 pred_clean_logit 0.5066849589347839
prompt generate:  espresso  	labels:  [[967]]
decoder:  [49406, 17098, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([535], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([967], device='cuda:0') tensor(7.0001e-18, device='cuda:0')
L1: [6684.534]	L2: [26.338634]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 504 pred_label: 504 pred_clean_logit 0.9984444975852966
prompt generate:  coffee mug  	labels:  [[504]]
decoder:  [49406, 2453, 9722, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([725], device='cuda:0') tensor(0.9883, device='cuda:0')
after_true: tensor([504], device='cuda:0') tensor(5.5129e-09, device='cuda:0')
L1: [6999.3457]	L2: [32.31735]	Linf: [0.92941177]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.4%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000006, Std=0.000004, Contribution=43.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.5% (timestep 4)
Min contribution: 6.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 751 pred_label: 919 pred_clean_logit 0.19371037185192108
prompt generate:  racer  	labels:  [[919]]
decoder:  [49406, 16798, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([919], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([751], device='cuda:0') tensor(7.8920e-16, device='cuda:0')
L1: [6871.3403]	L2: [25.380016]	Linf: [0.5294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=45.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.8% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 912 pred_label: 449 pred_clean_logit 0.19565816223621368
prompt generate:  worm fence  	labels:  [[449]]
decoder:  [49406, 10945, 12679, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([912], device='cuda:0') tensor(1.6067e-16, device='cuda:0')
L1: [7926.8076]	L2: [32.05001]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 383 pred_label: 383 pred_clean_logit 0.9419788718223572
prompt generate:  Madagascar cat  	labels:  [[383]]
decoder:  [49406, 25744, 2368, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([382], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([383], device='cuda:0') tensor(9.9174e-14, device='cuda:0')
L1: [8095.255]	L2: [31.260595]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 317 pred_label: 317 pred_clean_logit 0.7596774697303772
prompt generate:  leafhopper  	labels:  [[317]]
decoder:  [49406, 9377, 21748, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([311], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([317], device='cuda:0') tensor(1.6029e-17, device='cuda:0')
L1: [4086.6475]	L2: [21.592787]	Linf: [0.91764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 39 pred_label: 39 pred_clean_logit 0.9999864101409912
prompt generate:  common iguana  	labels:  [[39]]
decoder:  [49406, 4176, 21279, 1388, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([39], device='cuda:0') tensor(0.9976, device='cuda:0')
after_true: tensor([39], device='cuda:0') tensor(0.9976, device='cuda:0')
L1: [10324.258]	L2: [39.125694]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.8%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.5%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=25.2%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=49.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.3% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 544 pred_label: 544 pred_clean_logit 0.9999791383743286
prompt generate:  Dutch oven  	labels:  [[544]]
decoder:  [49406, 7991, 12579, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([567], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([544], device='cuda:0') tensor(1.1531e-18, device='cuda:0')
L1: [8573.702]	L2: [33.031464]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.8% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 580 pred_label: 580 pred_clean_logit 0.9999487400054932
prompt generate:  greenhouse  	labels:  [[580]]
decoder:  [49406, 20819, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([971], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([580], device='cuda:0') tensor(1.5765e-39, device='cuda:0')
L1: [14686.669]	L2: [53.038555]	Linf: [0.9764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 989 pred_label: 990 pred_clean_logit 0.007981041446328163
prompt generate:  hip  	labels:  [[990]]
decoder:  [49406, 6584, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([990], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([989], device='cuda:0') tensor(2.2964e-19, device='cuda:0')
L1: [10206.228]	L2: [36.749023]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 703 pred_label: 462 pred_clean_logit 0.1739487648010254
prompt generate:  park bench  	labels:  [[462]]
decoder:  [49406, 1452, 8771, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([696], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([703], device='cuda:0') tensor(1.8626e-23, device='cuda:0')
L1: [11504.444]	L2: [47.461765]	Linf: [0.99607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.7%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 984 pred_label: 984 pred_clean_logit 0.999592125415802
prompt generate:  rapeseed  	labels:  [[984]]
decoder:  [49406, 46099, 6488, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([986], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([984], device='cuda:0') tensor(1.0036e-19, device='cuda:0')
L1: [8814.346]	L2: [34.20479]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.7%
Timestep  4: Avg Loss=0.000010, Std=0.000002, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 844 pred_label: 844 pred_clean_logit 0.9991459846496582
prompt generate:  switch  	labels:  [[844]]
decoder:  [49406, 5893, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([662], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([844], device='cuda:0') tensor(4.5592e-10, device='cuda:0')
L1: [2762.1062]	L2: [11.773843]	Linf: [0.45490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 483 pred_label: 483 pred_clean_logit 0.9906256198883057
prompt generate:  castle  	labels:  [[483]]
decoder:  [49406, 3540, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([497], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([483], device='cuda:0') tensor(3.2542e-17, device='cuda:0')
L1: [6465.212]	L2: [26.45618]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=59.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.1% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 701 pred_label: 701 pred_clean_logit 0.8624321818351746
prompt generate:  parachute  	labels:  [[701]]
decoder:  [49406, 30122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([427], device='cuda:0') tensor(0.9945, device='cuda:0')
after_true: tensor([701], device='cuda:0') tensor(7.9408e-10, device='cuda:0')
L1: [4617.757]	L2: [18.963839]	Linf: [0.5764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=26.8%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=44.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.2% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 672 pred_label: 672 pred_clean_logit 0.9999772310256958
prompt generate:  mountain tent  	labels:  [[672]]
decoder:  [49406, 3965, 10782, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([672], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([672], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [4509.169]	L2: [20.232141]	Linf: [0.65882355]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.5%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.4%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 874 pred_label: 829 pred_clean_logit 0.05442212149500847
prompt generate:  trolleybus  	labels:  [[829]]
decoder:  [49406, 10306, 2565, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([829], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([874], device='cuda:0') tensor(2.8919e-12, device='cuda:0')
L1: [8766.156]	L2: [37.841362]	Linf: [0.90588236]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=46.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.3% (timestep 4)
Min contribution: 6.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 3 pred_label: 4 pred_clean_logit 0.08248787373304367
prompt generate:  tiger shark  	labels:  [[4]]
decoder:  [49406, 6531, 7980, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([4], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([3], device='cuda:0') tensor(4.4117e-15, device='cuda:0')
L1: [7401.3926]	L2: [28.707453]	Linf: [0.63529414]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=57.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.8% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 511 pred_label: 511 pred_clean_logit 0.9999850988388062
prompt generate:  convertible  	labels:  [[511]]
decoder:  [49406, 19608, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([511], device='cuda:0') tensor(2.1840e-17, device='cuda:0')
L1: [8623.727]	L2: [34.60827]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=7.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=15.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=42.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.1% (timestep 4)
Min contribution: 7.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 913 pred_label: 491 pred_clean_logit 2.8335009119473398e-05
prompt generate:  wreck  	labels:  [[491]]
decoder:  [49406, 15017, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([499], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([913], device='cuda:0') tensor(2.7160e-20, device='cuda:0')
L1: [7067.632]	L2: [28.12807]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 619 pred_label: 619 pred_clean_logit 0.8915828466415405
prompt generate:  lampshade  	labels:  [[619]]
decoder:  [49406, 26700, 10097, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([613], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([619], device='cuda:0') tensor(5.2212e-10, device='cuda:0')
L1: [2193.765]	L2: [11.8370695]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 751 pred_label: 573 pred_clean_logit 0.1608414649963379
prompt generate:  racer  	labels:  [[573]]
decoder:  [49406, 16798, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([573], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([751], device='cuda:0') tensor(2.3793e-08, device='cuda:0')
L1: [3392.5498]	L2: [15.329244]	Linf: [0.63529414]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=26.4%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=45.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.6% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 630 pred_label: 630 pred_clean_logit 0.6744464039802551
prompt generate:  Loafer  	labels:  [[630]]
decoder:  [49406, 26467, 528, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([845], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([630], device='cuda:0') tensor(2.8919e-22, device='cuda:0')
L1: [3864.9568]	L2: [14.506994]	Linf: [0.48235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=25.1%
Timestep  4: Avg Loss=0.000021, Std=0.000005, Contribution=57.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.0% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 975 pred_label: 975 pred_clean_logit 0.9990842342376709
prompt generate:  lakeside  	labels:  [[975]]
decoder:  [49406, 30915, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([975], device='cuda:0') tensor(5.0271e-15, device='cuda:0')
L1: [6819.208]	L2: [27.986835]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 759 pred_label: 759 pred_clean_logit 0.9999436140060425
prompt generate:  reflex camera  	labels:  [[759]]
decoder:  [49406, 36050, 3934, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([759], device='cuda:0') tensor(0.9995, device='cuda:0')
after_true: tensor([759], device='cuda:0') tensor(0.9995, device='cuda:0')
L1: [3353.4353]	L2: [16.123085]	Linf: [0.52156866]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=8.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.7%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=15.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.8%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=41.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.8% (timestep 4)
Min contribution: 8.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 933 pred_label: 923 pred_clean_logit 0.03223897144198418
prompt generate:  cheeseburger  	labels:  [[923]]
decoder:  [49406, 41200, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([923], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([933], device='cuda:0') tensor(5.8389e-16, device='cuda:0')
L1: [5060.055]	L2: [20.750767]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=48.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.9% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 624 pred_label: 454 pred_clean_logit 0.02858715131878853
prompt generate:  library  	labels:  [[454]]
decoder:  [49406, 3519, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([454], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([624], device='cuda:0') tensor(1.3202e-17, device='cuda:0')
L1: [10712.407]	L2: [43.411114]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 981 pred_label: 981 pred_clean_logit 0.6076955199241638
prompt generate:  ballplayer  	labels:  [[981]]
decoder:  [49406, 3807, 2477, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([807], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([981], device='cuda:0') tensor(4.5190e-21, device='cuda:0')
L1: [15208.686]	L2: [56.182953]	Linf: [0.8666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=57.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.0% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 472 pred_label: 576 pred_clean_logit 0.010729354806244373
prompt generate:  canoe  	labels:  [[576]]
decoder:  [49406, 23503, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([576], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([472], device='cuda:0') tensor(3.6156e-16, device='cuda:0')
L1: [8507.282]	L2: [32.40456]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 776 pred_label: 776 pred_clean_logit 0.9999891519546509
prompt generate:  sax  	labels:  [[776]]
decoder:  [49406, 23766, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([513], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([776], device='cuda:0') tensor(1.8014e-19, device='cuda:0')
L1: [7899.5845]	L2: [34.213757]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=45.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.6% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 406 pred_label: 687 pred_clean_logit 0.2847307324409485
prompt generate:  altar  	labels:  [[687]]
decoder:  [49406, 16385, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([687], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([406], device='cuda:0') tensor(2.4008e-23, device='cuda:0')
L1: [13947.734]	L2: [50.02835]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=47.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.4% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 991 pred_label: 991 pred_clean_logit 0.9999947547912598
prompt generate:  coral fungus  	labels:  [[991]]
decoder:  [49406, 12054, 30677, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([991], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([991], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7941.985]	L2: [28.669374]	Linf: [0.6196078]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 518 pred_label: 518 pred_clean_logit 0.9996885061264038
prompt generate:  crash helmet  	labels:  [[518]]
decoder:  [49406, 5033, 11122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([770], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([518], device='cuda:0') tensor(4.8878e-14, device='cuda:0')
L1: [4853.6562]	L2: [27.317213]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 351 pred_label: 351 pred_clean_logit 0.9997051358222961
prompt generate:  hartebeest  	labels:  [[351]]
decoder:  [49406, 915, 600, 571, 1509, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([353], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([351], device='cuda:0') tensor(9.9937e-15, device='cuda:0')
L1: [8519.621]	L2: [30.783813]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 489 pred_label: 489 pred_clean_logit 0.727194607257843
prompt generate:  chainlink fence  	labels:  [[489]]
decoder:  [49406, 13898, 2468, 12679, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([23], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([489], device='cuda:0') tensor(2.3555e-24, device='cuda:0')
L1: [14137.989]	L2: [49.1021]	Linf: [0.90588236]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 888 pred_label: 888 pred_clean_logit 0.999993085861206
prompt generate:  viaduct  	labels:  [[888]]
decoder:  [49406, 39113, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([668], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([888], device='cuda:0') tensor(2.2139e-11, device='cuda:0')
L1: [10867.616]	L2: [41.273952]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.4%
Timestep  1: Avg Loss=0.000000, Std=0.000001, Contribution=9.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000002, Std=0.000002, Contribution=47.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.7% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 866 pred_label: 866 pred_clean_logit 0.9998069405555725
prompt generate:  tractor  	labels:  [[866]]
decoder:  [49406, 14607, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([595], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([866], device='cuda:0') tensor(2.2956e-08, device='cuda:0')
L1: [7950.0703]	L2: [33.103218]	Linf: [0.972549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000002, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 517 pred_label: 517 pred_clean_logit 0.9999904632568359
prompt generate:  crane  	labels:  [[517]]
decoder:  [49406, 14626, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([517], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([517], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5652.3926]	L2: [26.648245]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=59.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.0% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 672 pred_label: 672 pred_clean_logit 0.9977861642837524
prompt generate:  mountain tent  	labels:  [[672]]
decoder:  [49406, 3965, 10782, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([672], device='cuda:0') tensor(3.7707e-27, device='cuda:0')
L1: [9504.29]	L2: [39.603294]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 971 pred_label: 513 pred_clean_logit 0.24814783036708832
prompt generate:  bubble  	labels:  [[513]]
decoder:  [49406, 10799, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([558], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([971], device='cuda:0') tensor(3.7603e-26, device='cuda:0')
L1: [7503.722]	L2: [31.115028]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 971 pred_label: 971 pred_clean_logit 0.8202390074729919
prompt generate:  bubble  	labels:  [[971]]
decoder:  [49406, 10799, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([107], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([971], device='cuda:0') tensor(8.7051e-11, device='cuda:0')
L1: [2682.2668]	L2: [10.2491455]	Linf: [0.4078431]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=60.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.2% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 671 pred_label: 671 pred_clean_logit 0.9939019680023193
prompt generate:  mountain bike  	labels:  [[671]]
decoder:  [49406, 3965, 3701, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([444], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([671], device='cuda:0') tensor(3.4749e-18, device='cuda:0')
L1: [11103.753]	L2: [42.66011]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.5% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 734 pred_label: 734 pred_clean_logit 0.999962329864502
prompt generate:  police van  	labels:  [[734]]
decoder:  [49406, 2120, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([407], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([734], device='cuda:0') tensor(3.4584e-24, device='cuda:0')
L1: [9081.925]	L2: [35.596508]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 347 pred_label: 347 pred_clean_logit 0.9969480633735657
prompt generate:  bison  	labels:  [[347]]
decoder:  [49406, 19741, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([410], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([347], device='cuda:0') tensor(1.3128e-20, device='cuda:0')
L1: [7016.1997]	L2: [27.5786]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=26.8%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 1.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 920 pred_label: 920 pred_clean_logit 0.9514056444168091
prompt generate:  traffic light  	labels:  [[920]]
decoder:  [49406, 3399, 1395, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([718], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([920], device='cuda:0') tensor(2.2309e-18, device='cuda:0')
L1: [7692.5454]	L2: [33.38133]	Linf: [0.9372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 442 pred_label: 442 pred_clean_logit 0.9993017911911011
prompt generate:  bell cote  	labels:  [[442]]
decoder:  [49406, 3718, 20751, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([497], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([442], device='cuda:0') tensor(3.7766e-09, device='cuda:0')
L1: [9790.239]	L2: [33.84079]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.4%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=57.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.6% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 922 pred_label: 922 pred_clean_logit 0.9718108177185059
prompt generate:  menu  	labels:  [[922]]
decoder:  [49406, 6225, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([446], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([922], device='cuda:0') tensor(7.9461e-11, device='cuda:0')
L1: [3342.9802]	L2: [14.086888]	Linf: [0.41568628]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=46.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.7% (timestep 4)
Min contribution: 6.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 832 pred_label: 697 pred_clean_logit 0.0002474179782439023
prompt generate:  stupa  	labels:  [[697]]
decoder:  [49406, 858, 2217, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([697], device='cuda:0') tensor(0.9708, device='cuda:0')
after_true: tensor([832], device='cuda:0') tensor(9.3287e-07, device='cuda:0')
L1: [3297.5098]	L2: [9.449166]	Linf: [0.35294116]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.0%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=21.3%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 144 pred_label: 144 pred_clean_logit 0.9999468326568604
prompt generate:  pelican  	labels:  [[144]]
decoder:  [49406, 34131, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([144], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([144], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3882.2043]	L2: [13.8881445]	Linf: [0.28627452]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.8%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.2%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 779 pred_label: 779 pred_clean_logit 0.9999977350234985
prompt generate:  school bus  	labels:  [[779]]
decoder:  [49406, 1228, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([779], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([779], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3474.502]	L2: [13.462137]	Linf: [0.517647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.6%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.5%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 458 pred_label: 458 pred_clean_logit 0.999879002571106
prompt generate:  brass  	labels:  [[458]]
decoder:  [49406, 11655, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([781], device='cuda:0') tensor(0.0220, device='cuda:0')
after_true: tensor([458], device='cuda:0') tensor(0.0171, device='cuda:0')
L1: [6557.933]	L2: [24.68773]	Linf: [0.41960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.2%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.8%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.5%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 6.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 94 pred_label: 94 pred_clean_logit 0.997789740562439
prompt generate:  hummingbird  	labels:  [[94]]
decoder:  [49406, 33072, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([88], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([94], device='cuda:0') tensor(9.7018e-23, device='cuda:0')
L1: [7116.8433]	L2: [26.75593]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 717 pred_label: 717 pred_clean_logit 0.9781484603881836
prompt generate:  pickup  	labels:  [[717]]
decoder:  [49406, 15382, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([717], device='cuda:0') tensor(3.9489e-14, device='cuda:0')
L1: [7870.5176]	L2: [34.569626]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.1%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=47.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.7% (timestep 4)
Min contribution: 6.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 814 pred_label: 814 pred_clean_logit 0.9971610307693481
prompt generate:  speedboat  	labels:  [[814]]
decoder:  [49406, 6860, 4440, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([554], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([814], device='cuda:0') tensor(5.7607e-15, device='cuda:0')
L1: [9188.058]	L2: [36.232906]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=47.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.3% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 985 pred_label: 985 pred_clean_logit 0.9999823570251465
prompt generate:  daisy  	labels:  [[985]]
decoder:  [49406, 12865, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([985], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([985], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2502.408]	L2: [17.254002]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=9.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=11.6%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=15.2%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=21.3%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=42.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.4% (timestep 4)
Min contribution: 9.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 978 pred_label: 978 pred_clean_logit 0.709079921245575
prompt generate:  seashore  	labels:  [[978]]
decoder:  [49406, 567, 31194, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([314], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([978], device='cuda:0') tensor(7.1047e-23, device='cuda:0')
L1: [4472.9766]	L2: [18.963074]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.0%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=10.0%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=23.8%
Timestep  4: Avg Loss=0.000021, Std=0.000006, Contribution=60.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.4% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 904 pred_label: 557 pred_clean_logit 0.038751810789108276
prompt generate:  window screen  	labels:  [[557]]
decoder:  [49406, 4879, 3750, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([557], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([904], device='cuda:0') tensor(2.3979e-24, device='cuda:0')
L1: [8005.188]	L2: [29.976534]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=44.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.3% (timestep 4)
Min contribution: 7.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 280 pred_label: 280 pred_clean_logit 0.9999494552612305
prompt generate:  grey fox  	labels:  [[280]]
decoder:  [49406, 5046, 3240, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([269], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([280], device='cuda:0') tensor(1.9184e-10, device='cuda:0')
L1: [11899.244]	L2: [44.97284]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=28.5%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=49.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.2% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 318 pred_label: 318 pred_clean_logit 0.9999991655349731
prompt generate:  lacewing  	labels:  [[318]]
decoder:  [49406, 30012, 1340, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([318], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([318], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3675.961]	L2: [19.627466]	Linf: [0.6862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.8%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.8%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.3%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 887 pred_label: 887 pred_clean_logit 0.898779571056366
prompt generate:  vestment  	labels:  [[887]]
decoder:  [49406, 31657, 777, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([617], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([887], device='cuda:0') tensor(8.6286e-22, device='cuda:0')
L1: [10986.066]	L2: [41.502422]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 347 pred_label: 347 pred_clean_logit 0.9998729228973389
prompt generate:  bison  	labels:  [[347]]
decoder:  [49406, 19741, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([348], device='cuda:0') tensor(0.9994, device='cuda:0')
after_true: tensor([347], device='cuda:0') tensor(1.6148e-20, device='cuda:0')
L1: [7779.3057]	L2: [27.009966]	Linf: [0.5568627]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 346 pred_label: 346 pred_clean_logit 0.9961179494857788
prompt generate:  water buffalo  	labels:  [[346]]
decoder:  [49406, 1573, 8054, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([345], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([346], device='cuda:0') tensor(3.0188e-12, device='cuda:0')
L1: [6649.0903]	L2: [27.237707]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.7%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 671 pred_label: 671 pred_clean_logit 0.9737207293510437
prompt generate:  mountain bike  	labels:  [[671]]
decoder:  [49406, 3965, 3701, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([444], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([671], device='cuda:0') tensor(8.3860e-09, device='cuda:0')
L1: [9048.824]	L2: [36.51181]	Linf: [0.98039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 668 pred_label: 668 pred_clean_logit 0.999828577041626
prompt generate:  mosque  	labels:  [[668]]
decoder:  [49406, 12694, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([900], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([668], device='cuda:0') tensor(5.9780e-10, device='cuda:0')
L1: [5079.4707]	L2: [25.90925]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=21.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=59.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.3% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 403 pred_label: 403 pred_clean_logit 0.999995231628418
prompt generate:  aircraft carrier  	labels:  [[403]]
decoder:  [49406, 7706, 12308, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([403], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([403], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [5054.785]	L2: [20.054138]	Linf: [0.69803923]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.8%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.8%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=58.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.3% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 322 pred_label: 322 pred_clean_logit 0.9743485450744629
prompt generate:  ringlet  	labels:  [[322]]
decoder:  [49406, 8318, 1094, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([325], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([322], device='cuda:0') tensor(5.1733e-12, device='cuda:0')
L1: [7262.392]	L2: [27.787199]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 734 pred_label: 734 pred_clean_logit 0.9410495758056641
prompt generate:  police van  	labels:  [[734]]
decoder:  [49406, 2120, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([407], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([734], device='cuda:0') tensor(4.8731e-16, device='cuda:0')
L1: [8486.228]	L2: [33.904396]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 962 pred_label: 962 pred_clean_logit 0.996957540512085
prompt generate:  meat loaf  	labels:  [[962]]
decoder:  [49406, 6480, 18273, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([941], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([962], device='cuda:0') tensor(5.2525e-20, device='cuda:0')
L1: [8418.377]	L2: [35.388702]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 675 pred_label: 675 pred_clean_logit 0.9348326921463013
prompt generate:  moving van  	labels:  [[675]]
decoder:  [49406, 3584, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([757], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([675], device='cuda:0') tensor(7.1905e-22, device='cuda:0')
L1: [8131.8823]	L2: [31.402649]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=46.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.3% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 468 pred_label: 468 pred_clean_logit 0.9999631643295288
prompt generate:  cab  	labels:  [[468]]
decoder:  [49406, 11912, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([561], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([468], device='cuda:0') tensor(1.5753e-06, device='cuda:0')
L1: [7050.9927]	L2: [29.038837]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=47.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.2% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 295 pred_label: 295 pred_clean_logit 0.9456811547279358
prompt generate:  American black bear  	labels:  [[295]]
decoder:  [49406, 2151, 1449, 4298, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([386], device='cuda:0') tensor(0.9978, device='cuda:0')
after_true: tensor([295], device='cuda:0') tensor(8.0146e-12, device='cuda:0')
L1: [6539.623]	L2: [25.184454]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 670 pred_label: 670 pred_clean_logit 0.7837015986442566
prompt generate:  motor scooter  	labels:  [[670]]
decoder:  [49406, 7659, 14199, 652, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([195], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([670], device='cuda:0') tensor(1.2325e-18, device='cuda:0')
L1: [8046.9653]	L2: [30.639687]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=25.3%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 13 pred_label: 13 pred_clean_logit 0.5057878494262695
prompt generate:  junco  	labels:  [[13]]
decoder:  [49406, 1637, 1320, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([18], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([13], device='cuda:0') tensor(3.9240e-10, device='cuda:0')
L1: [4130.6587]	L2: [15.759494]	Linf: [0.5137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000012, Std=0.000005, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 546 pred_label: 546 pred_clean_logit 0.9996010661125183
prompt generate:  electric guitar  	labels:  [[546]]
decoder:  [49406, 5031, 5084, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([714], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([546], device='cuda:0') tensor(1.2584e-24, device='cuda:0')
L1: [7829.886]	L2: [41.761]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=46.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.8% (timestep 4)
Min contribution: 5.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 737 pred_label: 737 pred_clean_logit 0.8590848445892334
prompt generate:  pop bottle  	labels:  [[737]]
decoder:  [49406, 2852, 5392, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([898], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([737], device='cuda:0') tensor(1.4630e-16, device='cuda:0')
L1: [7782.256]	L2: [34.020332]	Linf: [0.9490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 457 pred_label: 857 pred_clean_logit 0.041365161538124084
prompt generate:  bow tie  	labels:  [[857]]
decoder:  [49406, 4040, 3422, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([667], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([457], device='cuda:0') tensor(6.0702e-33, device='cuda:0')
L1: [6073.985]	L2: [23.581324]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.3%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000018, Std=0.000005, Contribution=58.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.7% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 403 pred_label: 403 pred_clean_logit 0.9994307160377502
prompt generate:  aircraft carrier  	labels:  [[403]]
decoder:  [49406, 7706, 12308, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([510], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([403], device='cuda:0') tensor(3.5935e-27, device='cuda:0')
L1: [11336.134]	L2: [43.540733]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 112 pred_label: 112 pred_clean_logit 0.9578545093536377
prompt generate:  conch  	labels:  [[112]]
decoder:  [49406, 616, 634, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([117], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([112], device='cuda:0') tensor(2.1470e-18, device='cuda:0')
L1: [3598.1023]	L2: [14.433289]	Linf: [0.42352945]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 985 pred_label: 985 pred_clean_logit 0.9999762773513794
prompt generate:  daisy  	labels:  [[985]]
decoder:  [49406, 12865, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([985], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([985], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [4086.9568]	L2: [17.144327]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.1%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 762 pred_label: 579 pred_clean_logit 0.006326517555862665
prompt generate:  restaurant  	labels:  [[579]]
decoder:  [49406, 4489, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([579], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([762], device='cuda:0') tensor(2.5119e-30, device='cuda:0')
L1: [7550.5684]	L2: [30.230259]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 908 pred_label: 475 pred_clean_logit 0.002313826931640506
prompt generate:  wing  	labels:  [[475]]
decoder:  [49406, 1340, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([475], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([908], device='cuda:0') tensor(5.5994e-14, device='cuda:0')
L1: [3421.2864]	L2: [13.560289]	Linf: [0.36862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 582 pred_label: 582 pred_clean_logit 0.9592928290367126
prompt generate:  grocery store  	labels:  [[582]]
decoder:  [49406, 13826, 2183, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([998], device='cuda:0') tensor(0.9940, device='cuda:0')
after_true: tensor([582], device='cuda:0') tensor(2.3996e-25, device='cuda:0')
L1: [6679.102]	L2: [25.185822]	Linf: [0.63529414]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=27.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 705 pred_label: 705 pred_clean_logit 0.9999663829803467
prompt generate:  passenger car  	labels:  [[705]]
decoder:  [49406, 12311, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([547], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([705], device='cuda:0') tensor(3.9995e-08, device='cuda:0')
L1: [6433.102]	L2: [25.45474]	Linf: [0.67450976]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=49.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.2% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 565 pred_label: 569 pred_clean_logit 0.13694915175437927
prompt generate:  freight car  	labels:  [[569]]
decoder:  [49406, 17023, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([569], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([565], device='cuda:0') tensor(5.1826e-19, device='cuda:0')
L1: [6013.0435]	L2: [26.939583]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 486 pred_label: 486 pred_clean_logit 0.9999998807907104
prompt generate:  cello  	labels:  [[486]]
decoder:  [49406, 23013, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([486], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([486], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6036.9805]	L2: [24.603949]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=7.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.1%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.0%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=23.1%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=46.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.8% (timestep 4)
Min contribution: 7.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 829 pred_label: 829 pred_clean_logit 0.9996174573898315
prompt generate:  streetcar  	labels:  [[829]]
decoder:  [49406, 34268, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([829], device='cuda:0') tensor(1.1094e-15, device='cuda:0')
L1: [7962.364]	L2: [29.500158]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 961 pred_label: 961 pred_clean_logit 0.9980412721633911
prompt generate:  dough  	labels:  [[961]]
decoder:  [49406, 14983, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([941], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([961], device='cuda:0') tensor(2.7171e-16, device='cuda:0')
L1: [3587.0388]	L2: [13.016804]	Linf: [0.4627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=21.3%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=60.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.5% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 471 pred_label: 471 pred_clean_logit 0.8840309977531433
prompt generate:  cannon  	labels:  [[471]]
decoder:  [49406, 15661, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([169], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([471], device='cuda:0') tensor(3.1883e-23, device='cuda:0')
L1: [12125.683]	L2: [49.38604]	Linf: [0.99607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.9%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=48.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 695 pred_label: 666 pred_clean_logit 0.059538621455430984
prompt generate:  padlock  	labels:  [[666]]
decoder:  [49406, 3798, 4381, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([666], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([695], device='cuda:0') tensor(1.8575e-33, device='cuda:0')
L1: [4775.5415]	L2: [17.6566]	Linf: [0.40392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.4%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000009, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000021, Std=0.000005, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 436 pred_label: 468 pred_clean_logit 0.06702050566673279
prompt generate:  beach wagon  	labels:  [[468]]
decoder:  [49406, 2117, 13260, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([436], device='cuda:0') tensor(2.0789e-21, device='cuda:0')
L1: [10230.479]	L2: [38.081486]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=45.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.7% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 874 pred_label: 874 pred_clean_logit 0.9488427639007568
prompt generate:  trolleybus  	labels:  [[874]]
decoder:  [49406, 10306, 2565, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([734], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([874], device='cuda:0') tensor(1.2448e-15, device='cuda:0')
L1: [8587.133]	L2: [32.38787]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 883 pred_label: 883 pred_clean_logit 0.8913714289665222
prompt generate:  vase  	labels:  [[883]]
decoder:  [49406, 20431, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([646], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([883], device='cuda:0') tensor(1.5844e-21, device='cuda:0')
L1: [9190.016]	L2: [35.53836]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=45.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.9% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 705 pred_label: 705 pred_clean_logit 0.9998832941055298
prompt generate:  passenger car  	labels:  [[705]]
decoder:  [49406, 12311, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([782], device='cuda:0') tensor(0.8374, device='cuda:0')
after_true: tensor([705], device='cuda:0') tensor(3.6144e-16, device='cuda:0')
L1: [4821.3374]	L2: [19.788084]	Linf: [0.58823526]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.3%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 347 pred_label: 347 pred_clean_logit 0.998635470867157
prompt generate:  bison  	labels:  [[347]]
decoder:  [49406, 19741, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([350], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([347], device='cuda:0') tensor(7.7451e-20, device='cuda:0')
L1: [5544.6113]	L2: [26.142807]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 746 pred_label: 746 pred_clean_logit 0.9955872297286987
prompt generate:  puck  	labels:  [[746]]
decoder:  [49406, 17550, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([768], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([746], device='cuda:0') tensor(3.0196e-16, device='cuda:0')
L1: [7470.5845]	L2: [33.61095]	Linf: [0.8980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 974 pred_label: 974 pred_clean_logit 0.9945226907730103
prompt generate:  geyser  	labels:  [[974]]
decoder:  [49406, 619, 33121, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([978], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([974], device='cuda:0') tensor(3.2697e-11, device='cuda:0')
L1: [5576.651]	L2: [21.032555]	Linf: [0.454902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=57.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.2% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 555 pred_label: 980 pred_clean_logit 0.03263266757130623
prompt generate:  fire engine  	labels:  [[980]]
decoder:  [49406, 1769, 5857, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([974], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([555], device='cuda:0') tensor(7.4785e-14, device='cuda:0')
L1: [2773.059]	L2: [14.837024]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=57.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.9% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 634 pred_label: 442 pred_clean_logit 0.0865166038274765
prompt generate:  lumbermill  	labels:  [[442]]
decoder:  [49406, 27421, 6637, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([910], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([634], device='cuda:0') tensor(1.3887e-21, device='cuda:0')
L1: [6626.6826]	L2: [24.16411]	Linf: [0.63529414]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000017, Std=0.000004, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 319 pred_label: 326 pred_clean_logit 0.00010647234739735723
prompt generate:  dragonfly  	labels:  [[326]]
decoder:  [49406, 32824, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([326], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([319], device='cuda:0') tensor(7.0457e-12, device='cuda:0')
L1: [4638.914]	L2: [24.367018]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 560 pred_label: 560 pred_clean_logit 0.9276569485664368
prompt generate:  football helmet  	labels:  [[560]]
decoder:  [49406, 1882, 11122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([615], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([560], device='cuda:0') tensor(1.7561e-20, device='cuda:0')
L1: [10668.36]	L2: [40.5606]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 762 pred_label: 498 pred_clean_logit 0.10269875079393387
prompt generate:  restaurant  	labels:  [[498]]
decoder:  [49406, 4489, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([498], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([762], device='cuda:0') tensor(2.0859e-19, device='cuda:0')
L1: [7201.1655]	L2: [30.043674]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 559 pred_label: 559 pred_clean_logit 0.9963317513465881
prompt generate:  folding chair  	labels:  [[559]]
decoder:  [49406, 15464, 4269, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([526], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([559], device='cuda:0') tensor(1.0716e-17, device='cuda:0')
L1: [6185.3413]	L2: [26.058304]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 573 pred_label: 573 pred_clean_logit 0.9909663200378418
prompt generate:  go-kart  	labels:  [[573]]
decoder:  [49406, 861, 268, 21310, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([621], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([573], device='cuda:0') tensor(1.1542e-14, device='cuda:0')
L1: [6445.6123]	L2: [27.0617]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 980 pred_label: 980 pred_clean_logit 0.999994158744812
prompt generate:  volcano  	labels:  [[980]]
decoder:  [49406, 14581, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([6], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([980], device='cuda:0') tensor(1.3357e-15, device='cuda:0')
L1: [5166.5723]	L2: [23.171919]	Linf: [0.6823529]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=11.4%
Timestep  3: Avg Loss=0.000010, Std=0.000004, Contribution=25.1%
Timestep  4: Avg Loss=0.000024, Std=0.000009, Contribution=57.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.4% (timestep 4)
Min contribution: 1.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 661 pred_label: 661 pred_clean_logit 0.9999945163726807
prompt generate:  Model T  	labels:  [[661]]
decoder:  [49406, 2863, 339, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([661], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([661], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [12211.286]	L2: [52.0961]	Linf: [0.98039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=8.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.7%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.9%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=22.7%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=42.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.8% (timestep 4)
Min contribution: 8.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 922 pred_label: 922 pred_clean_logit 0.9987751841545105
prompt generate:  menu  	labels:  [[922]]
decoder:  [49406, 6225, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([592], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([922], device='cuda:0') tensor(1.8648e-14, device='cuda:0')
L1: [4646.2783]	L2: [22.719524]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=48.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.9% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 923 pred_label: 923 pred_clean_logit 0.9961571097373962
prompt generate:  plate  	labels:  [[923]]
decoder:  [49406, 5135, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([809], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([923], device='cuda:0') tensor(4.7969e-15, device='cuda:0')
L1: [4781.172]	L2: [23.210129]	Linf: [0.6509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 661 pred_label: 661 pred_clean_logit 0.9999872446060181
prompt generate:  Model T  	labels:  [[661]]
decoder:  [49406, 2863, 339, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([661], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([661], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7271.1963]	L2: [30.600163]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 535 pred_label: 535 pred_clean_logit 0.9997857213020325
prompt generate:  disk brake  	labels:  [[535]]
decoder:  [49406, 17970, 14937, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([535], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([535], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [6166.2793]	L2: [25.3213]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.4%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=24.3%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 70 pred_label: 70 pred_clean_logit 0.999925971031189
prompt generate:  harvestman  	labels:  [[70]]
decoder:  [49406, 44495, 786, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([70], device='cuda:0') tensor(0.9988, device='cuda:0')
after_true: tensor([70], device='cuda:0') tensor(0.9988, device='cuda:0')
L1: [1674.3882]	L2: [5.8823957]	Linf: [0.27450982]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.6%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=58.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.7% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 897 pred_label: 612 pred_clean_logit 0.005177819635719061
prompt generate:  washer  	labels:  [[612]]
decoder:  [49406, 24085, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([880], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([897], device='cuda:0') tensor(4.0018e-26, device='cuda:0')
L1: [7439.694]	L2: [30.04594]	Linf: [0.6588235]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 540 pred_label: 517 pred_clean_logit 0.3675798177719116
prompt generate:  drilling platform  	labels:  [[517]]
decoder:  [49406, 18634, 5549, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([517], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([540], device='cuda:0') tensor(4.0967e-10, device='cuda:0')
L1: [10092.495]	L2: [42.41268]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 789 pred_label: 789 pred_clean_logit 0.9951889514923096
prompt generate:  shoji  	labels:  [[789]]
decoder:  [49406, 719, 2697, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([804], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([789], device='cuda:0') tensor(9.8155e-20, device='cuda:0')
L1: [5511.686]	L2: [24.49449]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=10.0%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=14.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=44.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.3% (timestep 4)
Min contribution: 7.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 791 pred_label: 791 pred_clean_logit 0.6156538128852844
prompt generate:  shopping cart  	labels:  [[791]]
decoder:  [49406, 4266, 13065, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([751], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([791], device='cuda:0') tensor(2.3066e-17, device='cuda:0')
L1: [11498.628]	L2: [42.486736]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=13.8%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.8%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 915 pred_label: 915 pred_clean_logit 0.9999884366989136
prompt generate:  yurt  	labels:  [[915]]
decoder:  [49406, 88, 24309, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([672], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([915], device='cuda:0') tensor(4.8201e-10, device='cuda:0')
L1: [12215.048]	L2: [49.30596]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 707 pred_label: 707 pred_clean_logit 0.999886155128479
prompt generate:  pay-phone  	labels:  [[707]]
decoder:  [49406, 3345, 268, 1951, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([707], device='cuda:0') tensor(0.9947, device='cuda:0')
after_true: tensor([707], device='cuda:0') tensor(0.9947, device='cuda:0')
L1: [8595.636]	L2: [32.3134]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.2%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=47.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.0% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 668 pred_label: 668 pred_clean_logit 0.9999886751174927
prompt generate:  mosque  	labels:  [[668]]
decoder:  [49406, 12694, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([668], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([668], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3436.1567]	L2: [15.461982]	Linf: [0.58431375]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.2%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=23.2%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=48.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.3% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 430 pred_label: 890 pred_clean_logit 0.06805001944303513
prompt generate:  basketball  	labels:  [[890]]
decoder:  [49406, 3835, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([202], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([430], device='cuda:0') tensor(1.4268e-29, device='cuda:0')
L1: [8630.071]	L2: [33.21055]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=47.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.9% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 497 pred_label: 497 pred_clean_logit 0.8120702505111694
prompt generate:  church  	labels:  [[497]]
decoder:  [49406, 2735, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([483], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([497], device='cuda:0') tensor(3.6490e-17, device='cuda:0')
L1: [8066.1104]	L2: [32.979538]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 324 pred_label: 324 pred_clean_logit 0.8054978251457214
prompt generate:  cabbage butterfly  	labels:  [[324]]
decoder:  [49406, 18407, 9738, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([720], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([324], device='cuda:0') tensor(5.8022e-20, device='cuda:0')
L1: [3601.5337]	L2: [15.04125]	Linf: [0.52156866]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 518 pred_label: 518 pred_clean_logit 0.9998608827590942
prompt generate:  crash helmet  	labels:  [[518]]
decoder:  [49406, 5033, 11122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([573], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([518], device='cuda:0') tensor(5.6237e-15, device='cuda:0')
L1: [9220.888]	L2: [40.812134]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=48.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.8% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 296 pred_label: 296 pred_clean_logit 0.9957441687583923
prompt generate:  ice bear  	labels:  [[296]]
decoder:  [49406, 733, 4298, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([178], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([296], device='cuda:0') tensor(5.5113e-20, device='cuda:0')
L1: [4930.8193]	L2: [17.897352]	Linf: [0.4745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 821 pred_label: 821 pred_clean_logit 0.9999947547912598
prompt generate:  steel arch bridge  	labels:  [[821]]
decoder:  [49406, 4726, 8557, 2465, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([821], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([821], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [9925.346]	L2: [37.958138]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.6%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=13.2%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.6%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 299 pred_label: 299 pred_clean_logit 0.9992008805274963
prompt generate:  meerkat  	labels:  [[299]]
decoder:  [49406, 26714, 9341, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([82], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([299], device='cuda:0') tensor(5.7736e-15, device='cuda:0')
L1: [10189.337]	L2: [38.087383]	Linf: [0.5882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.1%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=56.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.4% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 328 pred_label: 328 pred_clean_logit 0.992151141166687
prompt generate:  sea urchin  	labels:  [[328]]
decoder:  [49406, 2102, 565, 8979, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([397], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([328], device='cuda:0') tensor(1.2942e-13, device='cuda:0')
L1: [13275.803]	L2: [47.56308]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=13.4%
Timestep  3: Avg Loss=0.000011, Std=0.000004, Contribution=28.5%
Timestep  4: Avg Loss=0.000019, Std=0.000006, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 160 pred_label: 160 pred_clean_logit 0.9999719858169556
prompt generate:  Afghan hound  	labels:  [[160]]
decoder:  [49406, 15919, 13561, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([226], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([160], device='cuda:0') tensor(2.8293e-25, device='cuda:0')
L1: [9940.095]	L2: [37.402657]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 555 pred_label: 555 pred_clean_logit 0.7941935062408447
prompt generate:  fire engine  	labels:  [[555]]
decoder:  [49406, 1769, 5857, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([819], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([555], device='cuda:0') tensor(1.5508e-20, device='cuda:0')
L1: [9881.184]	L2: [45.756855]	Linf: [0.91764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 947 pred_label: 120 pred_clean_logit 0.0017091662157326937
prompt generate:  mushroom  	labels:  [[120]]
decoder:  [49406, 13011, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([470], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([947], device='cuda:0') tensor(2.7506e-32, device='cuda:0')
L1: [6307.2393]	L2: [24.81457]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=3.5%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=9.8%
Timestep  3: Avg Loss=0.000012, Std=0.000004, Contribution=24.0%
Timestep  4: Avg Loss=0.000030, Std=0.000008, Contribution=61.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 61.6% (timestep 4)
Min contribution: 1.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 985 pred_label: 985 pred_clean_logit 0.4746347963809967
prompt generate:  daisy  	labels:  [[985]]
decoder:  [49406, 12865, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([953], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([985], device='cuda:0') tensor(9.6650e-18, device='cuda:0')
L1: [3690.0474]	L2: [13.977584]	Linf: [0.61960787]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=12.6%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=25.5%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 646 pred_label: 900 pred_clean_logit 2.8906220904900692e-05
prompt generate:  maze  	labels:  [[900]]
decoder:  [49406, 21988, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([900], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([646], device='cuda:0') tensor(1.0229e-16, device='cuda:0')
L1: [12655.757]	L2: [45.936996]	Linf: [0.67450976]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 617 pred_label: 617 pred_clean_logit 0.3574599325656891
prompt generate:  lab coat  	labels:  [[617]]
decoder:  [49406, 4352, 7356, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([808], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([617], device='cuda:0') tensor(2.7253e-36, device='cuda:0')
L1: [4990.2]	L2: [19.829584]	Linf: [0.5686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 853 pred_label: 853 pred_clean_logit 0.9250163435935974
prompt generate:  thatch  	labels:  [[853]]
decoder:  [49406, 6303, 634, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([634], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([853], device='cuda:0') tensor(2.3637e-21, device='cuda:0')
L1: [9630.695]	L2: [42.46227]	Linf: [0.8784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 807 pred_label: 580 pred_clean_logit 0.0013632482150569558
prompt generate:  solar dish  	labels:  [[580]]
decoder:  [49406, 5199, 4531, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([593], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([807], device='cuda:0') tensor(1.6955e-14, device='cuda:0')
L1: [10160.69]	L2: [35.14824]	Linf: [0.5803921]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 976 pred_label: 976 pred_clean_logit 0.9852349758148193
prompt generate:  promontory  	labels:  [[976]]
decoder:  [49406, 644, 749, 4214, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([972], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([976], device='cuda:0') tensor(4.5898e-15, device='cuda:0')
L1: [5487.711]	L2: [21.572762]	Linf: [0.5529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 430 pred_label: 430 pred_clean_logit 0.9999945163726807
prompt generate:  basketball  	labels:  [[430]]
decoder:  [49406, 3835, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([890], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([430], device='cuda:0') tensor(9.0513e-19, device='cuda:0')
L1: [9281.439]	L2: [34.337234]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 832 pred_label: 832 pred_clean_logit 0.9999932050704956
prompt generate:  stupa  	labels:  [[832]]
decoder:  [49406, 858, 2217, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([832], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([832], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [11781.437]	L2: [45.499138]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 895 pred_label: 895 pred_clean_logit 0.9994791150093079
prompt generate:  warplane  	labels:  [[895]]
decoder:  [49406, 984, 5363, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([908], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([895], device='cuda:0') tensor(1.9125e-11, device='cuda:0')
L1: [5626.8945]	L2: [21.34119]	Linf: [0.5882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 985 pred_label: 985 pred_clean_logit 0.9993522763252258
prompt generate:  daisy  	labels:  [[985]]
decoder:  [49406, 12865, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([720], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([985], device='cuda:0') tensor(2.5311e-06, device='cuda:0')
L1: [8492.45]	L2: [31.458014]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=27.6%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=47.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.3% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 94 pred_label: 94 pred_clean_logit 0.999981164932251
prompt generate:  hummingbird  	labels:  [[94]]
decoder:  [49406, 33072, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([94], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([94], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2451.0005]	L2: [10.653106]	Linf: [0.41568628]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=20.8%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=59.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.7% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 763 pred_label: 763 pred_clean_logit 0.9999538660049438
prompt generate:  revolver  	labels:  [[763]]
decoder:  [49406, 38747, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([764], device='cuda:0') tensor(0.9996, device='cuda:0')
after_true: tensor([763], device='cuda:0') tensor(2.0505e-12, device='cuda:0')
L1: [5879.6357]	L2: [24.983002]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=56.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.9% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 885 pred_label: 584 pred_clean_logit 0.14043118059635162
prompt generate:  velvet  	labels:  [[584]]
decoder:  [49406, 11063, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([117], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([885], device='cuda:0') tensor(5.2773e-22, device='cuda:0')
L1: [4683.5366]	L2: [17.44469]	Linf: [0.5490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 873 pred_label: 873 pred_clean_logit 0.9374637007713318
prompt generate:  triumphal arch  	labels:  [[873]]
decoder:  [49406, 14782, 1037, 8708, 8557, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([497], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([873], device='cuda:0') tensor(1.0296e-16, device='cuda:0')
L1: [12686.333]	L2: [46.807552]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 562 pred_label: 562 pred_clean_logit 0.9293389916419983
prompt generate:  fountain  	labels:  [[562]]
decoder:  [49406, 13405, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([509], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([562], device='cuda:0') tensor(4.3378e-21, device='cuda:0')
L1: [6196.255]	L2: [26.221949]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=57.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.2% (timestep 4)
Min contribution: 1.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 472 pred_label: 472 pred_clean_logit 0.9694178104400635
prompt generate:  canoe  	labels:  [[472]]
decoder:  [49406, 23503, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([977], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([472], device='cuda:0') tensor(3.7479e-12, device='cuda:0')
L1: [5447.267]	L2: [21.159252]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 665 pred_label: 665 pred_clean_logit 0.9990094900131226
prompt generate:  moped  	labels:  [[665]]
decoder:  [49406, 617, 2966, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([661], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([665], device='cuda:0') tensor(1.0738e-18, device='cuda:0')
L1: [11716.817]	L2: [44.782494]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000002, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000004, Std=0.000003, Contribution=47.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.2% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 322 pred_label: 322 pred_clean_logit 0.9980406165122986
prompt generate:  ringlet  	labels:  [[322]]
decoder:  [49406, 8318, 1094, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([324], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([322], device='cuda:0') tensor(9.0544e-18, device='cuda:0')
L1: [5865.8945]	L2: [23.57113]	Linf: [0.61960787]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 441 pred_label: 441 pred_clean_logit 0.9939520955085754
prompt generate:  beer glass  	labels:  [[441]]
decoder:  [49406, 2544, 3313, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([967], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([441], device='cuda:0') tensor(1.9638e-13, device='cuda:0')
L1: [3921.749]	L2: [15.462641]	Linf: [0.49019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000009, Std=0.000005, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 437 pred_label: 437 pred_clean_logit 0.9997530579566956
prompt generate:  beacon  	labels:  [[437]]
decoder:  [49406, 18858, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([437], device='cuda:0') tensor(0.9987, device='cuda:0')
after_true: tensor([437], device='cuda:0') tensor(0.9987, device='cuda:0')
L1: [5118.2354]	L2: [25.850292]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=16.2%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=24.7%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=45.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.0% (timestep 4)
Min contribution: 6.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 320 pred_label: 320 pred_clean_logit 0.953711211681366
prompt generate:  damselfly  	labels:  [[320]]
decoder:  [49406, 1880, 1000, 3228, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([319], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([320], device='cuda:0') tensor(1.5385e-10, device='cuda:0')
L1: [10820.75]	L2: [39.03605]	Linf: [0.8156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.9%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 900 pred_label: 900 pred_clean_logit 0.9809850454330444
prompt generate:  water tower  	labels:  [[900]]
decoder:  [49406, 1573, 4730, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([417], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([900], device='cuda:0') tensor(2.7738e-23, device='cuda:0')
L1: [13427.512]	L2: [48.134914]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.2% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 517 pred_label: 517 pred_clean_logit 0.9952227473258972
prompt generate:  crane  	labels:  [[517]]
decoder:  [49406, 14626, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([755], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([517], device='cuda:0') tensor(2.9532e-16, device='cuda:0')
L1: [5871.369]	L2: [23.491268]	Linf: [0.5803921]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 403 pred_label: 403 pred_clean_logit 0.9999406337738037
prompt generate:  aircraft carrier  	labels:  [[403]]
decoder:  [49406, 7706, 12308, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([408], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([403], device='cuda:0') tensor(8.0861e-16, device='cuda:0')
L1: [6201.2324]	L2: [29.979103]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 814 pred_label: 814 pred_clean_logit 0.9940263032913208
prompt generate:  speedboat  	labels:  [[814]]
decoder:  [49406, 6860, 4440, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([693], device='cuda:0') tensor(0.9995, device='cuda:0')
after_true: tensor([814], device='cuda:0') tensor(4.0343e-12, device='cuda:0')
L1: [6320.913]	L2: [22.858004]	Linf: [0.62352943]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.3%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=21.8%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=59.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.2% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 877 pred_label: 877 pred_clean_logit 0.9685974717140198
prompt generate:  turnstile  	labels:  [[877]]
decoder:  [49406, 5522, 522, 989, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([877], device='cuda:0') tensor(8.4036e-20, device='cuda:0')
L1: [8635.564]	L2: [35.9541]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.0%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 21 pred_label: 21 pred_clean_logit 0.9975916147232056
prompt generate:  kite  	labels:  [[21]]
decoder:  [49406, 19867, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([91], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([21], device='cuda:0') tensor(4.1038e-13, device='cuda:0')
L1: [5278.4873]	L2: [22.742222]	Linf: [0.5764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 489 pred_label: 489 pred_clean_logit 0.9811133146286011
prompt generate:  chainlink fence  	labels:  [[489]]
decoder:  [49406, 13898, 2468, 12679, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([897], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([489], device='cuda:0') tensor(2.9849e-17, device='cuda:0')
L1: [9568.035]	L2: [39.33396]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 751 pred_label: 751 pred_clean_logit 0.9981127977371216
prompt generate:  racer  	labels:  [[751]]
decoder:  [49406, 16798, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([817], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([751], device='cuda:0') tensor(1.2605e-08, device='cuda:0')
L1: [6316.966]	L2: [27.804888]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=46.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.6% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 654 pred_label: 654 pred_clean_logit 0.9651688933372498
prompt generate:  minibus  	labels:  [[654]]
decoder:  [49406, 1810, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([762], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([654], device='cuda:0') tensor(9.7192e-17, device='cuda:0')
L1: [6507.549]	L2: [30.679]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 311 pred_label: 311 pred_clean_logit 0.6046202778816223
prompt generate:  grasshopper  	labels:  [[311]]
decoder:  [49406, 48894, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([319], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([311], device='cuda:0') tensor(5.2589e-28, device='cuda:0')
L1: [9730.809]	L2: [36.495834]	Linf: [0.65882355]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 628 pred_label: 628 pred_clean_logit 0.8001478314399719
prompt generate:  liner  	labels:  [[628]]
decoder:  [49406, 11618, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([536], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([628], device='cuda:0') tensor(3.9723e-10, device='cuda:0')
L1: [5261.788]	L2: [24.118567]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=59.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.3% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 978 pred_label: 978 pred_clean_logit 0.7111579775810242
prompt generate:  seashore  	labels:  [[978]]
decoder:  [49406, 567, 31194, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([766], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([978], device='cuda:0') tensor(8.6593e-27, device='cuda:0')
L1: [6368.7104]	L2: [24.623741]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=12.7%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=25.4%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 640 pred_label: 918 pred_clean_logit 1.1143414667458273e-05
prompt generate:  manhole cover  	labels:  [[918]]
decoder:  [49406, 723, 5341, 2202, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([918], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([640], device='cuda:0') tensor(5.0327e-33, device='cuda:0')
L1: [11534.78]	L2: [40.86137]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 39 pred_label: 39 pred_clean_logit 0.9969245791435242
prompt generate:  common iguana  	labels:  [[39]]
decoder:  [49406, 4176, 21279, 1388, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([46], device='cuda:0') tensor(0.8357, device='cuda:0')
after_true: tensor([39], device='cuda:0') tensor(1.6328e-09, device='cuda:0')
L1: [9382.214]	L2: [37.8704]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 776 pred_label: 776 pred_clean_logit 0.9999942779541016
prompt generate:  sax  	labels:  [[776]]
decoder:  [49406, 23766, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([785], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([776], device='cuda:0') tensor(1.0248e-31, device='cuda:0')
L1: [9152.7295]	L2: [34.535]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=13.0%
Timestep  3: Avg Loss=0.000011, Std=0.000003, Contribution=28.7%
Timestep  4: Avg Loss=0.000020, Std=0.000004, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 1.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 734 pred_label: 734 pred_clean_logit 0.9999997615814209
prompt generate:  police van  	labels:  [[734]]
decoder:  [49406, 2120, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5837.3496]	L2: [25.31356]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=11.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=12.6%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=15.6%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.1%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=38.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 38.6% (timestep 4)
Min contribution: 11.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 133 pred_label: 133 pred_clean_logit 0.9845970273017883
prompt generate:  bittern  	labels:  [[133]]
decoder:  [49406, 3010, 12959, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([142], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([133], device='cuda:0') tensor(4.5572e-12, device='cuda:0')
L1: [10149.07]	L2: [37.405907]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.5%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 787 pred_label: 652 pred_clean_logit 0.017077308148145676
prompt generate:  shield  	labels:  [[652]]
decoder:  [49406, 8670, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([124], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([787], device='cuda:0') tensor(7.7303e-30, device='cuda:0')
L1: [7463.623]	L2: [30.826153]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.4%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=12.0%
Timestep  3: Avg Loss=0.000011, Std=0.000003, Contribution=26.9%
Timestep  4: Avg Loss=0.000023, Std=0.000006, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 1.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 821 pred_label: 821 pred_clean_logit 0.994049072265625
prompt generate:  steel arch bridge  	labels:  [[821]]
decoder:  [49406, 4726, 8557, 2465, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([649], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([821], device='cuda:0') tensor(1.0471e-11, device='cuda:0')
L1: [4478.8936]	L2: [20.039194]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=57.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.9% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 637 pred_label: 637 pred_clean_logit 0.9998125433921814
prompt generate:  mailbox  	labels:  [[637]]
decoder:  [49406, 31482, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([412], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([637], device='cuda:0') tensor(4.2047e-17, device='cuda:0')
L1: [6030.49]	L2: [24.723059]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=57.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.8% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 448 pred_label: 824 pred_clean_logit 0.0001273123052669689
prompt generate:  birdhouse  	labels:  [[824]]
decoder:  [49406, 6908, 1212, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([824], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([448], device='cuda:0') tensor(2.3792e-17, device='cuda:0')
L1: [14085.209]	L2: [52.827354]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=56.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.6% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 654 pred_label: 654 pred_clean_logit 0.9853373169898987
prompt generate:  minibus  	labels:  [[654]]
decoder:  [49406, 1810, 2840, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([436], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([654], device='cuda:0') tensor(5.1333e-13, device='cuda:0')
L1: [6910.923]	L2: [27.63336]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=48.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.0% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 406 pred_label: 406 pred_clean_logit 0.6810405850410461
prompt generate:  altar  	labels:  [[406]]
decoder:  [49406, 16385, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([698], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([406], device='cuda:0') tensor(6.2594e-21, device='cuda:0')
L1: [8080.5728]	L2: [32.31175]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=25.3%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 646 pred_label: 787 pred_clean_logit 0.024152187630534172
prompt generate:  maze  	labels:  [[787]]
decoder:  [49406, 21988, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([292], device='cuda:0') tensor(0.9948, device='cuda:0')
after_true: tensor([646], device='cuda:0') tensor(1.8261e-08, device='cuda:0')
L1: [17137.996]	L2: [73.83158]	Linf: [0.9764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=9.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=11.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=17.0%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=36.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 36.4% (timestep 4)
Min contribution: 9.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 555 pred_label: 555 pred_clean_logit 0.9999758005142212
prompt generate:  fire engine  	labels:  [[555]]
decoder:  [49406, 1769, 5857, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([555], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([555], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [9681.271]	L2: [35.905766]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000006, Std=0.000001, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 391 pred_label: 391 pred_clean_logit 0.8128942251205444
prompt generate:  coho  	labels:  [[391]]
decoder:  [49406, 622, 2971, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([394], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([391], device='cuda:0') tensor(1.9595e-21, device='cuda:0')
L1: [8816.176]	L2: [32.145714]	Linf: [0.6666666]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=55.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.8% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 436 pred_label: 436 pred_clean_logit 0.9764544367790222
prompt generate:  beach wagon  	labels:  [[436]]
decoder:  [49406, 2117, 13260, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([436], device='cuda:0') tensor(8.7552e-20, device='cuda:0')
L1: [8808.929]	L2: [35.795383]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=48.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.8% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 117 pred_label: 117 pred_clean_logit 0.9999998807907104
prompt generate:  chambered nautilus  	labels:  [[117]]
decoder:  [49406, 1290, 9193, 5955, 6124, 718, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([117], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([117], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3415.651]	L2: [14.196612]	Linf: [0.4509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 734 pred_label: 734 pred_clean_logit 0.9999934434890747
prompt generate:  police van  	labels:  [[734]]
decoder:  [49406, 2120, 2451, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6389.5645]	L2: [26.77055]	Linf: [0.61960787]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=25.0%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=45.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.6% (timestep 4)
Min contribution: 6.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 980 pred_label: 980 pred_clean_logit 0.9990191459655762
prompt generate:  volcano  	labels:  [[980]]
decoder:  [49406, 14581, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([107], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([980], device='cuda:0') tensor(1.5213e-17, device='cuda:0')
L1: [2941.655]	L2: [10.31984]	Linf: [0.21960786]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=3.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=9.4%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=23.2%
Timestep  4: Avg Loss=0.000023, Std=0.000006, Contribution=63.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 63.0% (timestep 4)
Min contribution: 1.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 304 pred_label: 303 pred_clean_logit 0.0005008276784792542
prompt generate:  leaf beetle  	labels:  [[303]]
decoder:  [49406, 7232, 16534, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([312], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([304], device='cuda:0') tensor(4.5909e-17, device='cuda:0')
L1: [6088.659]	L2: [25.489676]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.9%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 628 pred_label: 628 pred_clean_logit 0.9998992681503296
prompt generate:  liner  	labels:  [[628]]
decoder:  [49406, 11618, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([727], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([628], device='cuda:0') tensor(5.7700e-13, device='cuda:0')
L1: [5399.0117]	L2: [27.417007]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=8.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=43.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.4% (timestep 4)
Min contribution: 8.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 518 pred_label: 518 pred_clean_logit 0.9734570980072021
prompt generate:  crash helmet  	labels:  [[518]]
decoder:  [49406, 5033, 11122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([450], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([518], device='cuda:0') tensor(2.2083e-22, device='cuda:0')
L1: [8812.462]	L2: [41.676632]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 609 pred_label: 656 pred_clean_logit 0.40826019644737244
prompt generate:  jeep  	labels:  [[656]]
decoder:  [49406, 11286, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([656], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([609], device='cuda:0') tensor(6.3965e-18, device='cuda:0')
L1: [7353.749]	L2: [28.750868]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 741 pred_label: 741 pred_clean_logit 0.9856632351875305
prompt generate:  prayer rug  	labels:  [[741]]
decoder:  [49406, 6583, 19220, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([735], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([741], device='cuda:0') tensor(2.3047e-19, device='cuda:0')
L1: [17708.873]	L2: [61.604725]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=27.9%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 562 pred_label: 562 pred_clean_logit 0.9986346364021301
prompt generate:  fountain  	labels:  [[562]]
decoder:  [49406, 13405, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([694], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([562], device='cuda:0') tensor(5.4836e-21, device='cuda:0')
L1: [5864.5684]	L2: [28.858774]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 733 pred_label: 733 pred_clean_logit 0.20303800702095032
prompt generate:  pole  	labels:  [[733]]
decoder:  [49406, 8170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([723], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([733], device='cuda:0') tensor(3.0239e-20, device='cuda:0')
L1: [4901.3174]	L2: [20.90045]	Linf: [0.72156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.6%
Timestep  4: Avg Loss=0.000013, Std=0.000006, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 442 pred_label: 442 pred_clean_logit 0.9974483251571655
prompt generate:  bell cote  	labels:  [[442]]
decoder:  [49406, 3718, 20751, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([698], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([442], device='cuda:0') tensor(2.4747e-11, device='cuda:0')
L1: [5537.635]	L2: [23.621096]	Linf: [0.62352943]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 6.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 692 pred_label: 692 pred_clean_logit 0.9882363677024841
prompt generate:  packet  	labels:  [[692]]
decoder:  [49406, 25022, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([917], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([692], device='cuda:0') tensor(1.7953e-13, device='cuda:0')
L1: [13585.405]	L2: [56.213234]	Linf: [0.91764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=16.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=44.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.9% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 310 pred_label: 310 pred_clean_logit 0.9999145269393921
prompt generate:  ant  	labels:  [[310]]
decoder:  [49406, 773, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([310], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([310], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [6392.4355]	L2: [23.129896]	Linf: [0.5254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000000, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=26.0%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 751 pred_label: 751 pred_clean_logit 0.9999052286148071
prompt generate:  racer  	labels:  [[751]]
decoder:  [49406, 16798, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([479], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([751], device='cuda:0') tensor(1.4719e-08, device='cuda:0')
L1: [8503.244]	L2: [34.93771]	Linf: [0.92941177]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=47.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.4% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 819 pred_label: 819 pred_clean_logit 0.9895803332328796
prompt generate:  stage  	labels:  [[819]]
decoder:  [49406, 2170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([573], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([819], device='cuda:0') tensor(1.8484e-18, device='cuda:0')
L1: [9007.62]	L2: [37.083805]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 535 pred_label: 686 pred_clean_logit 0.3546925187110901
prompt generate:  disk brake  	labels:  [[686]]
decoder:  [49406, 17970, 14937, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([686], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([535], device='cuda:0') tensor(2.0022e-15, device='cuda:0')
L1: [5683.5107]	L2: [22.403597]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=26.5%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=45.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.6% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 546 pred_label: 546 pred_clean_logit 0.8895503878593445
prompt generate:  electric guitar  	labels:  [[546]]
decoder:  [49406, 5031, 5084, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([747], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([546], device='cuda:0') tensor(1.6240e-30, device='cuda:0')
L1: [8204.459]	L2: [37.639633]	Linf: [0.9529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.8%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=47.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.1% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 708 pred_label: 708 pred_clean_logit 0.9999223947525024
prompt generate:  pedestal  	labels:  [[708]]
decoder:  [49406, 12862, 5535, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([863], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([708], device='cuda:0') tensor(3.1686e-19, device='cuda:0')
L1: [4276.035]	L2: [17.383396]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 366 pred_label: 366 pred_clean_logit 0.9886857271194458
prompt generate:  gorilla  	labels:  [[366]]
decoder:  [49406, 21994, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([367], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([366], device='cuda:0') tensor(4.5974e-23, device='cuda:0')
L1: [9541.992]	L2: [32.969643]	Linf: [0.72156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=25.9%
Timestep  4: Avg Loss=0.000012, Std=0.000005, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 886 pred_label: 886 pred_clean_logit 0.9999984502792358
prompt generate:  vending machine  	labels:  [[886]]
decoder:  [49406, 29202, 4169, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([860], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([886], device='cuda:0') tensor(1.4069e-13, device='cuda:0')
L1: [9831.188]	L2: [39.232662]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 705 pred_label: 705 pred_clean_logit 0.9961183071136475
prompt generate:  passenger car  	labels:  [[705]]
decoder:  [49406, 12311, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([466], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([705], device='cuda:0') tensor(7.7287e-14, device='cuda:0')
L1: [13510.19]	L2: [48.067806]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=57.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.9% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 671 pred_label: 671 pred_clean_logit 0.9998377561569214
prompt generate:  mountain bike  	labels:  [[671]]
decoder:  [49406, 3965, 3701, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([518], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([671], device='cuda:0') tensor(2.0657e-17, device='cuda:0')
L1: [7448.262]	L2: [29.185904]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=47.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.1% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 887 pred_label: 887 pred_clean_logit 0.9996987581253052
prompt generate:  vestment  	labels:  [[887]]
decoder:  [49406, 31657, 777, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([443], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([887], device='cuda:0') tensor(2.4956e-17, device='cuda:0')
L1: [7656.7803]	L2: [29.715557]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 300 pred_label: 70 pred_clean_logit 0.1907949000597
prompt generate:  tiger beetle  	labels:  [[70]]
decoder:  [49406, 6531, 16534, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([310], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([300], device='cuda:0') tensor(3.6826e-14, device='cuda:0')
L1: [8219.307]	L2: [30.359917]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=26.4%
Timestep  4: Avg Loss=0.000018, Std=0.000005, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 603 pred_label: 603 pred_clean_logit 0.9999991655349731
prompt generate:  horse cart  	labels:  [[603]]
decoder:  [49406, 4558, 13065, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([690], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([603], device='cuda:0') tensor(2.6337e-18, device='cuda:0')
L1: [10610.105]	L2: [44.37654]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 131 pred_label: 131 pred_clean_logit 0.3142428398132324
prompt generate:  little blue heron  	labels:  [[131]]
decoder:  [49406, 1274, 1746, 22593, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([261], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([131], device='cuda:0') tensor(5.9955e-15, device='cuda:0')
L1: [7077.9966]	L2: [25.170109]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.7%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=49.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.6% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 304 pred_label: 304 pred_clean_logit 0.8225816488265991
prompt generate:  leaf beetle  	labels:  [[304]]
decoder:  [49406, 7232, 16534, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([306], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([304], device='cuda:0') tensor(3.0934e-13, device='cuda:0')
L1: [5156.6167]	L2: [21.739832]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 323 pred_label: 323 pred_clean_logit 0.9999974966049194
prompt generate:  monarch  	labels:  [[323]]
decoder:  [49406, 22619, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([323], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([323], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6210.1104]	L2: [24.262716]	Linf: [0.63529414]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 525 pred_label: 525 pred_clean_logit 0.99998939037323
prompt generate:  dam  	labels:  [[525]]
decoder:  [49406, 4926, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([460], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([525], device='cuda:0') tensor(1.0751e-13, device='cuda:0')
L1: [7221.6445]	L2: [26.9163]	Linf: [0.5882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=57.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.8% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 458 pred_label: 704 pred_clean_logit 0.3650017976760864
prompt generate:  brass  	labels:  [[704]]
decoder:  [49406, 11655, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([704], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([458], device='cuda:0') tensor(4.4646e-14, device='cuda:0')
L1: [6400.823]	L2: [24.743938]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=47.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.6% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 972 pred_label: 972 pred_clean_logit 0.9769257307052612
prompt generate:  cliff  	labels:  [[972]]
decoder:  [49406, 10625, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([500], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([972], device='cuda:0') tensor(2.8937e-17, device='cuda:0')
L1: [10560.099]	L2: [38.45933]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 590 pred_label: 688 pred_clean_logit 0.4825833737850189
prompt generate:  hand-held computer  	labels:  [[688]]
decoder:  [49406, 2463, 268, 4042, 11639, 652, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([688], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([590], device='cuda:0') tensor(9.3176e-11, device='cuda:0')
L1: [6477.1494]	L2: [29.98248]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.9%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=44.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.3% (timestep 4)
Min contribution: 8.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 716 pred_label: 716 pred_clean_logit 0.9999209642410278
prompt generate:  picket fence  	labels:  [[716]]
decoder:  [49406, 33559, 12679, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([716], device='cuda:0') tensor(0.9991, device='cuda:0')
after_true: tensor([716], device='cuda:0') tensor(0.9991, device='cuda:0')
L1: [7589.2827]	L2: [30.145185]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.5%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=24.3%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=48.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.1% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 751 pred_label: 751 pred_clean_logit 0.9991602897644043
prompt generate:  racer  	labels:  [[751]]
decoder:  [49406, 16798, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([817], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([751], device='cuda:0') tensor(6.3844e-12, device='cuda:0')
L1: [9562.39]	L2: [37.562054]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=45.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.2% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 819 pred_label: 819 pred_clean_logit 0.9988442659378052
prompt generate:  stage  	labels:  [[819]]
decoder:  [49406, 2170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([577], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([819], device='cuda:0') tensor(6.9625e-37, device='cuda:0')
L1: [8939.862]	L2: [38.521908]	Linf: [0.93333334]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 888 pred_label: 888 pred_clean_logit 0.9998248219490051
prompt generate:  viaduct  	labels:  [[888]]
decoder:  [49406, 39113, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([888], device='cuda:0') tensor(0.9995, device='cuda:0')
after_true: tensor([888], device='cuda:0') tensor(0.9995, device='cuda:0')
L1: [3020.0747]	L2: [15.743516]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=48.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.9% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 630 pred_label: 630 pred_clean_logit 0.9998432397842407
prompt generate:  Loafer  	labels:  [[630]]
decoder:  [49406, 26467, 528, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([502], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([630], device='cuda:0') tensor(3.4608e-14, device='cuda:0')
L1: [4876.6543]	L2: [23.099455]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.8%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 335 pred_label: 278 pred_clean_logit 0.02432514727115631
prompt generate:  fox squirrel  	labels:  [[278]]
decoder:  [49406, 3240, 14004, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([278], device='cuda:0') tensor(0.9970, device='cuda:0')
after_true: tensor([335], device='cuda:0') tensor(3.6226e-14, device='cuda:0')
L1: [6425.3765]	L2: [24.004622]	Linf: [0.49803925]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.9%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=58.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.1% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 830 pred_label: 830 pred_clean_logit 0.7907664775848389
prompt generate:  stretcher  	labels:  [[830]]
decoder:  [49406, 12265, 3466, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([713], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([830], device='cuda:0') tensor(2.0929e-17, device='cuda:0')
L1: [6090.0513]	L2: [23.793259]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=13.2%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=25.5%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 608 pred_label: 608 pred_clean_logit 0.9996782541275024
prompt generate:  jean  	labels:  [[608]]
decoder:  [49406, 6473, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([655], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([608], device='cuda:0') tensor(6.4148e-16, device='cuda:0')
L1: [8525.731]	L2: [33.145313]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=9.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=11.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=15.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=41.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.2% (timestep 4)
Min contribution: 9.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 403 pred_label: 403 pred_clean_logit 0.9999994039535522
prompt generate:  aircraft carrier  	labels:  [[403]]
decoder:  [49406, 7706, 12308, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([744], device='cuda:0') tensor(0.9975, device='cuda:0')
after_true: tensor([403], device='cuda:0') tensor(8.1758e-11, device='cuda:0')
L1: [3545.1455]	L2: [15.786995]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.1%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 610 pred_label: 610 pred_clean_logit 0.9966341853141785
prompt generate:  jersey  	labels:  [[610]]
decoder:  [49406, 4471, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([612], device='cuda:0') tensor(0.8318, device='cuda:0')
after_true: tensor([610], device='cuda:0') tensor(4.1944e-07, device='cuda:0')
L1: [5604.1924]	L2: [29.291172]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 780 pred_label: 780 pred_clean_logit 0.9901171326637268
prompt generate:  schooner  	labels:  [[780]]
decoder:  [49406, 2493, 6071, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([724], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([780], device='cuda:0') tensor(1.1983e-05, device='cuda:0')
L1: [4257.4434]	L2: [16.942892]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=20.8%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 5.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 563 pred_label: 563 pred_clean_logit 0.9953293800354004
prompt generate:  fountain pen  	labels:  [[563]]
decoder:  [49406, 13405, 5356, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([767], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([563], device='cuda:0') tensor(7.5826e-13, device='cuda:0')
L1: [4099.557]	L2: [20.317707]	Linf: [0.99607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.7%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=55.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.7% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 668 pred_label: 668 pred_clean_logit 0.4104863107204437
prompt generate:  mosque  	labels:  [[668]]
decoder:  [49406, 12694, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([615], device='cuda:0') tensor(0.9943, device='cuda:0')
after_true: tensor([668], device='cuda:0') tensor(7.0251e-07, device='cuda:0')
L1: [2161.2236]	L2: [9.7260275]	Linf: [0.42352942]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.9%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=19.6%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 737 pred_label: 737 pred_clean_logit 0.9992697834968567
prompt generate:  pop bottle  	labels:  [[737]]
decoder:  [49406, 2852, 5392, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([907], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([737], device='cuda:0') tensor(5.4897e-17, device='cuda:0')
L1: [11419.199]	L2: [47.6777]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=46.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.8% (timestep 4)
Min contribution: 6.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 867 pred_label: 867 pred_clean_logit 0.9986116886138916
prompt generate:  trailer truck  	labels:  [[867]]
decoder:  [49406, 4700, 4629, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([675], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([867], device='cuda:0') tensor(9.7464e-17, device='cuda:0')
L1: [6055.655]	L2: [26.14057]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.8%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 119 pred_label: 124 pred_clean_logit 0.007156321778893471
prompt generate:  rock crab  	labels:  [[124]]
decoder:  [49406, 2172, 11574, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([124], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([119], device='cuda:0') tensor(4.8589e-17, device='cuda:0')
L1: [3058.2476]	L2: [13.069512]	Linf: [0.4431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 560 pred_label: 768 pred_clean_logit 0.38815703988075256
prompt generate:  football helmet  	labels:  [[768]]
decoder:  [49406, 1882, 11122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([768], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([560], device='cuda:0') tensor(5.3886e-15, device='cuda:0')
L1: [8252.357]	L2: [31.044077]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=27.1%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 284 pred_label: 192 pred_clean_logit 0.00040394303505308926
prompt generate:  Siamese cat  	labels:  [[192]]
decoder:  [49406, 43161, 2368, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([202], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([284], device='cuda:0') tensor(1.7842e-21, device='cuda:0')
L1: [6661.5967]	L2: [24.890133]	Linf: [0.61176467]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 847 pred_label: 847 pred_clean_logit 0.933610200881958
prompt generate:  tank  	labels:  [[847]]
decoder:  [49406, 6172, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([871], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([847], device='cuda:0') tensor(3.7212e-11, device='cuda:0')
L1: [5253.7534]	L2: [19.748291]	Linf: [0.6]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 979 pred_label: 979 pred_clean_logit 0.9816715121269226
prompt generate:  valley  	labels:  [[979]]
decoder:  [49406, 3136, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([970], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([979], device='cuda:0') tensor(6.8128e-12, device='cuda:0')
L1: [9663.4]	L2: [34.646843]	Linf: [0.61960787]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 817 pred_label: 817 pred_clean_logit 0.979716956615448
prompt generate:  sports car  	labels:  [[817]]
decoder:  [49406, 2054, 1615, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([511], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([817], device='cuda:0') tensor(1.2357e-12, device='cuda:0')
L1: [9426.894]	L2: [39.028877]	Linf: [0.96862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=46.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.6% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 781 pred_label: 781 pred_clean_logit 0.9054251909255981
prompt generate:  scoreboard  	labels:  [[781]]
decoder:  [49406, 30104, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([668], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([781], device='cuda:0') tensor(2.4128e-14, device='cuda:0')
L1: [6521.145]	L2: [31.786966]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 498 pred_label: 498 pred_clean_logit 0.9939370155334473
prompt generate:  cinema  	labels:  [[498]]
decoder:  [49406, 6443, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([458], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([498], device='cuda:0') tensor(9.5927e-17, device='cuda:0')
L1: [8962.827]	L2: [34.868076]	Linf: [0.69803923]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=11.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=15.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=41.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.9% (timestep 4)
Min contribution: 8.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 879 pred_label: 501 pred_clean_logit 0.022626031190156937
prompt generate:  umbrella  	labels:  [[501]]
decoder:  [49406, 17143, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([501], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([879], device='cuda:0') tensor(1.5136e-14, device='cuda:0')
L1: [3348.5608]	L2: [21.109865]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 963 pred_label: 963 pred_clean_logit 0.5682843327522278
prompt generate:  pizza  	labels:  [[963]]
decoder:  [49406, 4474, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([809], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([963], device='cuda:0') tensor(2.6671e-22, device='cuda:0')
L1: [11945.513]	L2: [46.24618]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=55.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.7% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 981 pred_label: 981 pred_clean_logit 0.8783146739006042
prompt generate:  ballplayer  	labels:  [[981]]
decoder:  [49406, 3807, 2477, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([611], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([981], device='cuda:0') tensor(2.7714e-19, device='cuda:0')
L1: [5862.4824]	L2: [22.84968]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 539 pred_label: 738 pred_clean_logit 0.0005212902324274182
prompt generate:  doormat  	labels:  [[738]]
decoder:  [49406, 7188, 9063, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([738], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([539], device='cuda:0') tensor(2.6667e-15, device='cuda:0')
L1: [6313.2783]	L2: [25.944162]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=48.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.9% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 497 pred_label: 497 pred_clean_logit 0.9679251909255981
prompt generate:  church  	labels:  [[497]]
decoder:  [49406, 2735, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([538], device='cuda:0') tensor(0.9996, device='cuda:0')
after_true: tensor([497], device='cuda:0') tensor(6.9368e-12, device='cuda:0')
L1: [8083.71]	L2: [33.47874]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=42.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.9% (timestep 4)
Min contribution: 7.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 698 pred_label: 698 pred_clean_logit 0.9917282462120056
prompt generate:  palace  	labels:  [[698]]
decoder:  [49406, 6381, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([668], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([698], device='cuda:0') tensor(1.2041e-12, device='cuda:0')
L1: [3351.9922]	L2: [13.992016]	Linf: [0.39215687]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=21.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=60.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.6% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 649 pred_label: 649 pred_clean_logit 0.9970318078994751
prompt generate:  megalith  	labels:  [[649]]
decoder:  [49406, 37650, 1757, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([386], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([649], device='cuda:0') tensor(6.8863e-14, device='cuda:0')
L1: [5502.3496]	L2: [20.52644]	Linf: [0.6509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=56.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.6% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 663 pred_label: 663 pred_clean_logit 0.9970220923423767
prompt generate:  monastery  	labels:  [[663]]
decoder:  [49406, 21850, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([442], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([663], device='cuda:0') tensor(1.1842e-17, device='cuda:0')
L1: [7681.211]	L2: [29.412827]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.9%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 989 pred_label: 989 pred_clean_logit 0.9998531341552734
prompt generate:  hip  	labels:  [[989]]
decoder:  [49406, 6584, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([844], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([989], device='cuda:0') tensor(6.2556e-18, device='cuda:0')
L1: [2752.7454]	L2: [11.154756]	Linf: [0.38431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=58.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.1% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 97 pred_label: 97 pred_clean_logit 0.842998206615448
prompt generate:  drake  	labels:  [[97]]
decoder:  [49406, 8958, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([12], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([97], device='cuda:0') tensor(6.5226e-24, device='cuda:0')
L1: [16723.385]	L2: [60.70957]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=27.2%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 385 pred_label: 385 pred_clean_logit 0.900352418422699
prompt generate:  Indian elephant  	labels:  [[385]]
decoder:  [49406, 3606, 10299, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([163], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([385], device='cuda:0') tensor(3.8165e-24, device='cuda:0')
L1: [7690.106]	L2: [31.726551]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 780 pred_label: 780 pred_clean_logit 0.9930059909820557
prompt generate:  schooner  	labels:  [[780]]
decoder:  [49406, 2493, 6071, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([724], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([780], device='cuda:0') tensor(2.0747e-09, device='cuda:0')
L1: [11096.35]	L2: [41.00033]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 741 pred_label: 741 pred_clean_logit 0.6529601216316223
prompt generate:  prayer rug  	labels:  [[741]]
decoder:  [49406, 6583, 19220, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([497], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([741], device='cuda:0') tensor(7.1869e-14, device='cuda:0')
L1: [17367.371]	L2: [60.754486]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=48.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.4% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 720 pred_label: 720 pred_clean_logit 0.7477449774742126
prompt generate:  pill bottle  	labels:  [[720]]
decoder:  [49406, 19226, 5392, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([838], device='cuda:0') tensor(0.9987, device='cuda:0')
after_true: tensor([720], device='cuda:0') tensor(5.7935e-13, device='cuda:0')
L1: [5175.804]	L2: [24.114553]	Linf: [0.6823529]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=22.1%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 6.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 348 pred_label: 348 pred_clean_logit 0.5792075395584106
prompt generate:  ram  	labels:  [[348]]
decoder:  [49406, 2007, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([341], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([348], device='cuda:0') tensor(1.8511e-17, device='cuda:0')
L1: [10218.876]	L2: [39.182194]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000020, Std=0.000005, Contribution=57.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.4% (timestep 4)
Min contribution: 1.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 442 pred_label: 873 pred_clean_logit 0.0050141713581979275
prompt generate:  bell cote  	labels:  [[873]]
decoder:  [49406, 3718, 20751, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([698], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([442], device='cuda:0') tensor(1.9898e-13, device='cuda:0')
L1: [6092.8315]	L2: [27.457642]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=7.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=44.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.8% (timestep 4)
Min contribution: 7.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 908 pred_label: 895 pred_clean_logit 0.35839611291885376
prompt generate:  wing  	labels:  [[895]]
decoder:  [49406, 1340, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([895], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([908], device='cuda:0') tensor(4.9203e-09, device='cuda:0')
L1: [6594.3687]	L2: [24.21367]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 883 pred_label: 883 pred_clean_logit 0.9551615715026855
prompt generate:  vase  	labels:  [[883]]
decoder:  [49406, 20431, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([738], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([883], device='cuda:0') tensor(1.3340e-19, device='cuda:0')
L1: [8177.4243]	L2: [35.597824]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=57.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.2% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 949 pred_label: 949 pred_clean_logit 0.9999805688858032
prompt generate:  strawberry  	labels:  [[949]]
decoder:  [49406, 10233, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([868], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([949], device='cuda:0') tensor(9.6446e-10, device='cuda:0')
L1: [10863.819]	L2: [41.671745]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.6%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=45.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.4% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 787 pred_label: 787 pred_clean_logit 0.9997919201850891
prompt generate:  shield  	labels:  [[787]]
decoder:  [49406, 8670, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([455], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([787], device='cuda:0') tensor(4.4576e-23, device='cuda:0')
L1: [16421.72]	L2: [57.071484]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=27.7%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 637 pred_label: 707 pred_clean_logit 0.04210175573825836
prompt generate:  mailbox  	labels:  [[707]]
decoder:  [49406, 31482, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([707], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([637], device='cuda:0') tensor(1.8753e-34, device='cuda:0')
L1: [10779.694]	L2: [41.517406]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 287 pred_label: 287 pred_clean_logit 0.9528716802597046
prompt generate:  lynx  	labels:  [[287]]
decoder:  [49406, 28941, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([67], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([287], device='cuda:0') tensor(2.3928e-25, device='cuda:0')
L1: [12862.152]	L2: [44.06835]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 672 pred_label: 672 pred_clean_logit 0.9999603033065796
prompt generate:  mountain tent  	labels:  [[672]]
decoder:  [49406, 3965, 10782, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([672], device='cuda:0') tensor(7.3164e-16, device='cuda:0')
L1: [7902.859]	L2: [32.808517]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 976 pred_label: 976 pred_clean_logit 0.9956900477409363
prompt generate:  promontory  	labels:  [[976]]
decoder:  [49406, 644, 749, 4214, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([972], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([976], device='cuda:0') tensor(2.1307e-10, device='cuda:0')
L1: [4958.879]	L2: [19.55818]	Linf: [0.5960784]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 566 pred_label: 566 pred_clean_logit 0.9997565150260925
prompt generate:  French horn  	labels:  [[566]]
decoder:  [49406, 3461, 9607, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([513], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([566], device='cuda:0') tensor(3.4568e-11, device='cuda:0')
L1: [7266.8354]	L2: [36.479267]	Linf: [0.9137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 917 pred_label: 917 pred_clean_logit 0.998875081539154
prompt generate:  comic book  	labels:  [[917]]
decoder:  [49406, 4962, 1116, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([704], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([917], device='cuda:0') tensor(3.8287e-18, device='cuda:0')
L1: [13620.995]	L2: [54.434326]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=47.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.8% (timestep 4)
Min contribution: 5.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 715 pred_label: 715 pred_clean_logit 0.9999849796295166
prompt generate:  pickelhaube  	labels:  [[715]]
decoder:  [49406, 901, 2825, 5152, 655, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([715], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([715], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6378.479]	L2: [27.365458]	Linf: [0.63529414]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000000, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000007, Std=0.000001, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 301 pred_label: 301 pred_clean_logit 0.9983144998550415
prompt generate:  ladybug  	labels:  [[301]]
decoder:  [49406, 40038, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([584], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([301], device='cuda:0') tensor(2.3943e-10, device='cuda:0')
L1: [4145.6787]	L2: [17.13807]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 476 pred_label: 676 pred_clean_logit 0.07343071699142456
prompt generate:  carousel  	labels:  [[676]]
decoder:  [49406, 36665, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([172], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([476], device='cuda:0') tensor(2.0469e-15, device='cuda:0')
L1: [6037.3413]	L2: [24.37258]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.8% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 560 pred_label: 560 pred_clean_logit 0.8014358282089233
prompt generate:  football helmet  	labels:  [[560]]
decoder:  [49406, 1882, 11122, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([880], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([560], device='cuda:0') tensor(2.9050e-29, device='cuda:0')
L1: [8276.715]	L2: [31.645084]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=47.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.6% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 323 pred_label: 323 pred_clean_logit 0.35187309980392456
prompt generate:  monarch  	labels:  [[323]]
decoder:  [49406, 22619, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([96], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([323], device='cuda:0') tensor(5.4238e-15, device='cuda:0')
L1: [6660.174]	L2: [25.642967]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 417 pred_label: 417 pred_clean_logit 0.9999984502792358
prompt generate:  balloon  	labels:  [[417]]
decoder:  [49406, 13634, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([417], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([417], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3130.1333]	L2: [13.994771]	Linf: [0.60392153]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=11.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.2%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.2%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=45.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.8% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 668 pred_label: 405 pred_clean_logit 0.04079585149884224
prompt generate:  mosque  	labels:  [[405]]
decoder:  [49406, 12694, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([832], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([668], device='cuda:0') tensor(5.8067e-14, device='cuda:0')
L1: [3317.8665]	L2: [17.367521]	Linf: [0.572549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=48.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.1% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 142 pred_label: 142 pred_clean_logit 0.9990795850753784
prompt generate:  dowitcher  	labels:  [[142]]
decoder:  [49406, 639, 33684, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([141], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([142], device='cuda:0') tensor(3.7948e-08, device='cuda:0')
L1: [3486.8901]	L2: [15.433243]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.7%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 84 pred_label: 84 pred_clean_logit 0.9999597072601318
prompt generate:  peacock  	labels:  [[84]]
decoder:  [49406, 661, 9463, 868, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([84], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([84], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [11851.687]	L2: [40.73072]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.8%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.3%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=23.9%
Timestep  4: Avg Loss=0.000000, Std=0.000000, Contribution=46.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.7% (timestep 4)
Min contribution: 6.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 304 pred_label: 304 pred_clean_logit 0.963917076587677
prompt generate:  leaf beetle  	labels:  [[304]]
decoder:  [49406, 7232, 16534, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([305], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([304], device='cuda:0') tensor(8.9545e-11, device='cuda:0')
L1: [6499.7646]	L2: [29.349007]	Linf: [0.93333334]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 520 pred_label: 520 pred_clean_logit 0.9963439106941223
prompt generate:  crib  	labels:  [[520]]
decoder:  [49406, 23271, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([516], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([520], device='cuda:0') tensor(2.2140e-11, device='cuda:0')
L1: [6732.992]	L2: [26.942883]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=21.4%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=55.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.7% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 770 pred_label: 770 pred_clean_logit 0.926295816898346
prompt generate:  running shoe  	labels:  [[770]]
decoder:  [49406, 2761, 7342, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([630], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([770], device='cuda:0') tensor(8.3038e-13, device='cuda:0')
L1: [3597.9136]	L2: [20.15583]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.1%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=59.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.8% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 476 pred_label: 476 pred_clean_logit 0.9999909400939941
prompt generate:  carousel  	labels:  [[476]]
decoder:  [49406, 36665, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([476], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([476], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [9152.863]	L2: [38.914257]	Linf: [0.9843137]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 528 pred_label: 528 pred_clean_logit 0.9999998807907104
prompt generate:  dial telephone  	labels:  [[528]]
decoder:  [49406, 11381, 17243, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([528], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([528], device='cuda:0') tensor(1., device='cuda:0')
L1: [4183.2197]	L2: [19.042597]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 719 pred_label: 719 pred_clean_logit 0.9999986886978149
prompt generate:  piggy bank  	labels:  [[719]]
decoder:  [49406, 28245, 2723, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([719], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([719], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7375.3247]	L2: [28.31569]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=9.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.0%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=48.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.5% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 671 pred_label: 671 pred_clean_logit 0.5509478449821472
prompt generate:  mountain bike  	labels:  [[671]]
decoder:  [49406, 3965, 3701, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([444], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([671], device='cuda:0') tensor(2.6446e-15, device='cuda:0')
L1: [11763.519]	L2: [43.265667]	Linf: [0.93333334]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 847 pred_label: 847 pred_clean_logit 0.9912029504776001
prompt generate:  tank  	labels:  [[847]]
decoder:  [49406, 6172, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([471], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([847], device='cuda:0') tensor(3.2478e-14, device='cuda:0')
L1: [7635.337]	L2: [29.754305]	Linf: [0.654902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.3%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 458 pred_label: 458 pred_clean_logit 0.9568461775779724
prompt generate:  brass  	labels:  [[458]]
decoder:  [49406, 11655, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([704], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([458], device='cuda:0') tensor(7.8441e-11, device='cuda:0')
L1: [7693.769]	L2: [30.747004]	Linf: [0.5176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=9.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.5%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 6.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 880 pred_label: 977 pred_clean_logit 0.02797248400747776
prompt generate:  unicycle  	labels:  [[977]]
decoder:  [49406, 7648, 38089, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([977], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([880], device='cuda:0') tensor(3.5060e-13, device='cuda:0')
L1: [5968.27]	L2: [24.914804]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 389 pred_label: 389 pred_clean_logit 0.9923037886619568
prompt generate:  barracouta  	labels:  [[389]]
decoder:  [49406, 40835, 35187, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([391], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([389], device='cuda:0') tensor(9.6429e-19, device='cuda:0')
L1: [9306.149]	L2: [35.152782]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=54.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.5% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 649 pred_label: 483 pred_clean_logit 0.08512304723262787
prompt generate:  megalith  	labels:  [[483]]
decoder:  [49406, 37650, 1757, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([500], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([649], device='cuda:0') tensor(4.9432e-13, device='cuda:0')
L1: [12084.73]	L2: [45.278057]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.1%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=59.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.1% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 976 pred_label: 976 pred_clean_logit 0.9963755011558533
prompt generate:  promontory  	labels:  [[976]]
decoder:  [49406, 644, 749, 4214, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([978], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([976], device='cuda:0') tensor(8.1334e-11, device='cuda:0')
L1: [5875.322]	L2: [23.130375]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 362 pred_label: 362 pred_clean_logit 0.9997445940971375
prompt generate:  badger  	labels:  [[362]]
decoder:  [49406, 22363, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([383], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([362], device='cuda:0') tensor(2.6981e-19, device='cuda:0')
L1: [15396.578]	L2: [52.231163]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 981 pred_label: 981 pred_clean_logit 0.9311038851737976
prompt generate:  ballplayer  	labels:  [[981]]
decoder:  [49406, 3807, 2477, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([977], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([981], device='cuda:0') tensor(3.0724e-11, device='cuda:0')
L1: [5739.1895]	L2: [23.650324]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=48.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.7% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 920 pred_label: 766 pred_clean_logit 0.029382331296801567
prompt generate:  traffic light  	labels:  [[766]]
decoder:  [49406, 3399, 1395, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([556], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([920], device='cuda:0') tensor(3.6336e-18, device='cuda:0')
L1: [5455.7173]	L2: [22.933609]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 743 pred_label: 743 pred_clean_logit 0.981243908405304
prompt generate:  prison  	labels:  [[743]]
decoder:  [49406, 6622, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([519], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([743], device='cuda:0') tensor(7.0842e-20, device='cuda:0')
L1: [6752.1997]	L2: [23.791416]	Linf: [0.5411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.0%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=58.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 0.0%
gt_label: 917 pred_label: 788 pred_clean_logit 0.0893533006310463
prompt generate:  comic book  	labels:  [[788]]
decoder:  [49406, 4962, 1116, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([837], device='cuda:0') tensor(0.9993, device='cuda:0')
after_true: tensor([917], device='cuda:0') tensor(1.9787e-28, device='cuda:0')
L1: [10265.894]	L2: [39.48023]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.9%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=27.5%
Timestep  4: Avg Loss=0.000017, Std=0.000006, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 962 pred_label: 962 pred_clean_logit 0.9360916018486023
prompt generate:  meat loaf  	labels:  [[962]]
decoder:  [49406, 6480, 18273, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([467], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([962], device='cuda:0') tensor(3.9741e-15, device='cuda:0')
L1: [9605.989]	L2: [34.911434]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 546 pred_label: 546 pred_clean_logit 0.99994957447052
prompt generate:  electric guitar  	labels:  [[546]]
decoder:  [49406, 5031, 5084, 49407] [49406, 49407]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([546], device='cuda:0') tensor(0.9991, device='cuda:0')
after_true: tensor([546], device='cuda:0') tensor(0.9991, device='cuda:0')
L1: [4217.62]	L2: [22.578964]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=11.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=12.7%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=15.9%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=21.1%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=39.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 39.3% (timestep 4)
Min contribution: 11.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 819 pred_label: 819 pred_clean_logit 0.7729704976081848
prompt generate:  stage  	labels:  [[819]]
decoder:  [49406, 2170, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([620], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([819], device='cuda:0') tensor(4.4843e-35, device='cuda:0')
L1: [9746.533]	L2: [44.181023]	Linf: [0.9098039]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.7%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=48.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.8% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 324 pred_label: 324 pred_clean_logit 0.9673987030982971
prompt generate:  cabbage butterfly  	labels:  [[324]]
decoder:  [49406, 18407, 9738, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([986], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([324], device='cuda:0') tensor(1.2150e-15, device='cuda:0')
L1: [6223.5454]	L2: [23.013205]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.3%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.0%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis

✓ Using AttentionControlEditFixedWeights
  Schedule type: learned
  Weights: [0.064, 0.103, 0.158, 0.269, 0.406]

Accuracy on benign examples: 100.0%
gt_label: 912 pred_label: 912 pred_clean_logit 0.9374397993087769
prompt generate:  worm fence  	labels:  [[912]]
decoder:  [49406, 10945, 12679, 49407] [49406, 49407]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([765], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([912], device='cuda:0') tensor(3.5537e-17, device='cuda:0')
L1: [4713.145]	L2: [17.69864]	Linf: [0.517647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_fixed/timestep_analysis/loss_per_timestep.png
✓ Saved: test_fixed/timestep_analysis/loss_heatmap.png
✓ Saved: test_fixed/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_fixed/timestep_analysis
Clean acc: 0.0%
Adv acc: 0.0%

*********Transfer to resnet********
Accuracy on benign examples: 92.7%
Accuracy on adversarial examples: 59.699999999999996%

*********Transfer to vgg********
Accuracy on benign examples: 88.7%
Accuracy on adversarial examples: 59.099999999999994%

*********Transfer to mobile********
Accuracy on benign examples: 86.9%
Accuracy on adversarial examples: 56.89999999999999%

*********Transfer to inception********
Accuracy on benign examples: 80.5%
Accuracy on adversarial examples: 11.3%

*********Transfer to convnext********
Accuracy on benign examples: 97.0%
Accuracy on adversarial examples: 76.6%

*********Transfer to vit********
Accuracy on benign examples: 93.7%
Accuracy on adversarial examples: 73.3%

*********Transfer to swin********
Accuracy on benign examples: 95.89999999999999%
Accuracy on adversarial examples: 75.2%

*********Transfer to deit-b********
Accuracy on benign examples: 94.5%
Accuracy on adversarial examples: 75.1%

*********Transfer to deit-s********
Accuracy on benign examples: 94.0%
Accuracy on adversarial examples: 72.3%

*********Transfer to mixer-b********
Accuracy on benign examples: 82.5%
Accuracy on adversarial examples: 57.699999999999996%

*********Transfer to mixer-l********
Accuracy on benign examples: 76.5%
Accuracy on adversarial examples: 54.900000000000006%
FID:  61.80814063276631

*********fid: 61.80814063276631********
