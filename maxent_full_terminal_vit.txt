
******Attack based on Diffusion, Attacked Dataset: imagenet_compatible*********
Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00, 24.31it/s]Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 17.06it/s]Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 17.85it/s]
Traceback (most recent call last):
  File "main.py", line 122, in <module>
    ldm_stable = StableDiffusionPipeline.from_pretrained(pretrained_diffusion_path).to('cuda:0')
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/diffusers/pipelines/pipeline_utils.py", line 431, in to
    module.to(device, dtype)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 1749, in to
    return super().to(*args, **kwargs)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/datastore/clc_hcmus/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 1.26 GiB already allocated; 16.00 MiB free; 1.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
