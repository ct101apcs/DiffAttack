
******Attack based on Diffusion, Attacked Dataset: imagenet_compatible*********

==================================================
LEARNABLE TIMESTEP WEIGHTS ENABLED (mode: learnable_detached)
==================================================
Number of timesteps: 5
Weight network learning rate: 0.0001
Detach weights: True
Initial self-attention weights: [0.05 0.08 0.13 0.24 0.5 ]
Initial cross-attention weights: [0.05 0.08 0.13 0.24 0.5 ]
==================================================


✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 388 pred_label: 388 pred_clean_logit 0.9999761581420898
prompt generate:  giant panda  	labels:  [[388]]
decoder:  [49406, 4687, 12952, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([368], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([388], device='cuda:0') tensor(1.3504e-14, device='cuda:0')
L1: [7035.682]	L2: [27.55891]	Linf: [0.57254905]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=55.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.7% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 576 pred_label: 576 pred_clean_logit 0.9961865544319153
prompt generate:  gondola  	labels:  [[576]]
decoder:  [49406, 1854, 38005, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([525], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([576], device='cuda:0') tensor(3.8300e-24, device='cuda:0')
L1: [10877.035]	L2: [41.05312]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=57.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.1% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 326 pred_label: 326 pred_clean_logit 0.9948904514312744
prompt generate:  lycaenid  	labels:  [[326]]
decoder:  [49406, 1251, 772, 524, 1014, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([322], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([326], device='cuda:0') tensor(6.6469e-13, device='cuda:0')
L1: [11155.705]	L2: [42.248016]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=2.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=13.9%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.4%
Timestep  4: Avg Loss=0.000012, Std=0.000005, Contribution=50.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.0% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 137 pred_label: 137 pred_clean_logit 0.9999957084655762
prompt generate:  American coot  	labels:  [[137]]
decoder:  [49406, 2151, 1664, 339, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([344], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([137], device='cuda:0') tensor(4.7395e-17, device='cuda:0')
L1: [11340.667]	L2: [41.152115]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=26.3%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 90 pred_label: 90 pred_clean_logit 0.999975323677063
prompt generate:  lorikeet  	labels:  [[90]]
decoder:  [49406, 20164, 643, 875, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([90], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([90], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [4652.8545]	L2: [21.77504]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.4%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.9%
Timestep  4: Avg Loss=0.000002, Std=0.000000, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 981 pred_label: 981 pred_clean_logit 0.9789443016052246
prompt generate:  ballplayer  	labels:  [[981]]
decoder:  [49406, 3807, 2477, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([768], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([981], device='cuda:0') tensor(3.5616e-13, device='cuda:0')
L1: [7664.6123]	L2: [30.38024]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=16.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=40.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 40.8% (timestep 4)
Min contribution: 7.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 9 pred_label: 9 pred_clean_logit 0.9999983310699463
prompt generate:  ostrich  	labels:  [[9]]
decoder:  [49406, 47640, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([9], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([9], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [8621.067]	L2: [33.56277]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.6%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=22.2%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 471 pred_label: 880 pred_clean_logit 0.03641903027892113
prompt generate:  cannon  	labels:  [[880]]
decoder:  [49406, 15661, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([880], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([471], device='cuda:0') tensor(7.8821e-12, device='cuda:0')
L1: [6690.106]	L2: [23.70519]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 303 pred_label: 303 pred_clean_logit 0.9998551607131958
prompt generate:  long-horned beetle  	labels:  [[303]]
decoder:  [49406, 1538, 268, 34526, 16534, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([300], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([303], device='cuda:0') tensor(1.3775e-07, device='cuda:0')
L1: [5424.471]	L2: [20.976013]	Linf: [0.6666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 967 pred_label: 967 pred_clean_logit 0.9999995231628418
prompt generate:  espresso  	labels:  [[967]]
decoder:  [49406, 17098, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([967], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([967], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3595.0588]	L2: [15.062456]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000000, Contribution=13.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=26.9%
Timestep  4: Avg Loss=0.000007, Std=0.000001, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 450 pred_label: 450 pred_clean_logit 0.999992847442627
prompt generate:  bobsled  	labels:  [[450]]
decoder:  [49406, 8444, 28438, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([744], device='cuda:0') tensor(0.9995, device='cuda:0')
after_true: tensor([450], device='cuda:0') tensor(1.9127e-21, device='cuda:0')
L1: [6900.754]	L2: [29.559938]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 326 pred_label: 307 pred_clean_logit 0.012216628529131413
prompt generate:  lycaenid  	labels:  [[307]]
decoder:  [49406, 1251, 772, 524, 1014, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([307], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([326], device='cuda:0') tensor(4.1745e-20, device='cuda:0')
L1: [6991.3926]	L2: [29.558802]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 579 pred_label: 579 pred_clean_logit 0.9999785423278809
prompt generate:  grand piano  	labels:  [[579]]
decoder:  [49406, 2991, 7894, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([526], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([579], device='cuda:0') tensor(8.2137e-19, device='cuda:0')
L1: [4916.902]	L2: [23.212948]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 974 pred_label: 974 pred_clean_logit 0.4764682650566101
prompt generate:  geyser  	labels:  [[974]]
decoder:  [49406, 619, 33121, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([33], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([974], device='cuda:0') tensor(5.4303e-15, device='cuda:0')
L1: [5791.432]	L2: [21.458847]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=57.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.4% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 624 pred_label: 884 pred_clean_logit 0.21167829632759094
prompt generate:  library  	labels:  [[884]]
decoder:  [49406, 3519, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([538], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([624], device='cuda:0') tensor(5.1869e-13, device='cuda:0')
L1: [7468.658]	L2: [31.091312]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=46.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.6% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 17 pred_label: 17 pred_clean_logit 0.5130999684333801
prompt generate:  jay  	labels:  [[17]]
decoder:  [49406, 4155, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([758], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([17], device='cuda:0') tensor(2.7132e-09, device='cuda:0')
L1: [4122.3604]	L2: [23.835144]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000000, Contribution=13.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=21.2%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 663 pred_label: 663 pred_clean_logit 0.8715879917144775
prompt generate:  monastery  	labels:  [[663]]
decoder:  [49406, 21850, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([698], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([663], device='cuda:0') tensor(4.7246e-16, device='cuda:0')
L1: [5064.7095]	L2: [20.664976]	Linf: [0.6588235]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 967 pred_label: 967 pred_clean_logit 0.999982476234436
prompt generate:  espresso  	labels:  [[967]]
decoder:  [49406, 17098, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([968], device='cuda:0') tensor(0.9986, device='cuda:0')
after_true: tensor([967], device='cuda:0') tensor(5.1277e-10, device='cuda:0')
L1: [3077.3103]	L2: [12.474875]	Linf: [0.4784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.6%
Timestep  4: Avg Loss=0.000004, Std=0.000003, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 425 pred_label: 425 pred_clean_logit 0.9992275238037109
prompt generate:  barn  	labels:  [[425]]
decoder:  [49406, 10942, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([425], device='cuda:0') tensor(1.3762e-13, device='cuda:0')
L1: [6881.2114]	L2: [26.789934]	Linf: [0.72156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 652 pred_label: 652 pred_clean_logit 0.8967668414115906
prompt generate:  military uniform  	labels:  [[652]]
decoder:  [49406, 4323, 11075, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([557], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([652], device='cuda:0') tensor(1.9373e-22, device='cuda:0')
L1: [6959.7856]	L2: [30.500017]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 464 pred_label: 816 pred_clean_logit 0.17598950862884521
prompt generate:  buckle  	labels:  [[816]]
decoder:  [49406, 21948, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([816], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([464], device='cuda:0') tensor(4.1875e-16, device='cuda:0')
L1: [5495.118]	L2: [21.079487]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 809 pred_label: 809 pred_clean_logit 0.9941885471343994
prompt generate:  soup bowl  	labels:  [[809]]
decoder:  [49406, 7077, 3814, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([925], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([809], device='cuda:0') tensor(9.7531e-12, device='cuda:0')
L1: [3261.3882]	L2: [11.554578]	Linf: [0.38039213]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.9%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 107 pred_label: 107 pred_clean_logit 0.9999765157699585
prompt generate:  jellyfish  	labels:  [[107]]
decoder:  [49406, 30988, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([903], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([107], device='cuda:0') tensor(3.1955e-16, device='cuda:0')
L1: [6023.1885]	L2: [26.19013]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 672 pred_label: 917 pred_clean_logit 0.0008617190178483725
prompt generate:  mountain tent  	labels:  [[917]]
decoder:  [49406, 3965, 10782, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([692], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([672], device='cuda:0') tensor(1.1591e-22, device='cuda:0')
L1: [7891.079]	L2: [33.691868]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 253 pred_label: 253 pred_clean_logit 0.9790931940078735
prompt generate:  basenji  	labels:  [[253]]
decoder:  [49406, 1244, 524, 2697, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([158], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([253], device='cuda:0') tensor(1.5788e-22, device='cuda:0')
L1: [12049.752]	L2: [41.987553]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 853 pred_label: 853 pred_clean_logit 0.9998495578765869
prompt generate:  thatch  	labels:  [[853]]
decoder:  [49406, 6303, 634, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([522], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([853], device='cuda:0') tensor(2.1285e-21, device='cuda:0')
L1: [8917.471]	L2: [34.15356]	Linf: [0.8666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.7%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 972 pred_label: 972 pred_clean_logit 0.741553783416748
prompt generate:  cliff  	labels:  [[972]]
decoder:  [49406, 10625, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([500], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([972], device='cuda:0') tensor(1.6240e-11, device='cuda:0')
L1: [7435.8154]	L2: [30.290129]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=57.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.6% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 703 pred_label: 765 pred_clean_logit 0.22384493052959442
prompt generate:  park bench  	labels:  [[765]]
decoder:  [49406, 1452, 8771, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([706], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([703], device='cuda:0') tensor(3.6694e-17, device='cuda:0')
L1: [8798.914]	L2: [34.546135]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 107 pred_label: 107 pred_clean_logit 0.4076721966266632
prompt generate:  jellyfish  	labels:  [[107]]
decoder:  [49406, 30988, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([801], device='cuda:0') tensor(0.5085, device='cuda:0')
after_true: tensor([107], device='cuda:0') tensor(0.0003, device='cuda:0')
L1: [4242.7256]	L2: [13.787098]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 1.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 963 pred_label: 941 pred_clean_logit 0.058770451694726944
prompt generate:  pizza  	labels:  [[941]]
decoder:  [49406, 4474, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([941], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([963], device='cuda:0') tensor(1.5043e-19, device='cuda:0')
L1: [10065.428]	L2: [39.86653]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 353 pred_label: 353 pred_clean_logit 0.9999136924743652
prompt generate:  gazelle  	labels:  [[353]]
decoder:  [49406, 4837, 4765, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([352], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([353], device='cuda:0') tensor(2.5810e-08, device='cuda:0')
L1: [5590.2827]	L2: [20.564043]	Linf: [0.63529414]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000002, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000003, Contribution=24.4%
Timestep  4: Avg Loss=0.000010, Std=0.000006, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 605 pred_label: 605 pred_clean_logit 0.9101880788803101
prompt generate:  iPod  	labels:  [[605]]
decoder:  [49406, 17889, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([487], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([605], device='cuda:0') tensor(9.1997e-12, device='cuda:0')
L1: [3366.773]	L2: [15.270761]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=57.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.4% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 759 pred_label: 759 pred_clean_logit 0.9991193413734436
prompt generate:  reflex camera  	labels:  [[759]]
decoder:  [49406, 36050, 3934, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([622], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([759], device='cuda:0') tensor(3.4092e-15, device='cuda:0')
L1: [5735.2393]	L2: [26.797413]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 982 pred_label: 982 pred_clean_logit 0.7787193655967712
prompt generate:  groom  	labels:  [[982]]
decoder:  [49406, 22813, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([523], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([982], device='cuda:0') tensor(2.0548e-28, device='cuda:0')
L1: [6578.953]	L2: [25.394157]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 483 pred_label: 483 pred_clean_logit 0.9999613761901855
prompt generate:  castle  	labels:  [[483]]
decoder:  [49406, 3540, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([483], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([483], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [7073.5405]	L2: [28.035524]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.8%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=22.7%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 733 pred_label: 733 pred_clean_logit 0.9946756362915039
prompt generate:  pole  	labels:  [[733]]
decoder:  [49406, 8170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([724], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([733], device='cuda:0') tensor(2.8978e-12, device='cuda:0')
L1: [4511.655]	L2: [23.46824]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=8.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=43.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.6% (timestep 4)
Min contribution: 8.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 560 pred_label: 560 pred_clean_logit 0.9892776012420654
prompt generate:  football helmet  	labels:  [[560]]
decoder:  [49406, 1882, 11122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([670], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([560], device='cuda:0') tensor(3.4099e-20, device='cuda:0')
L1: [7555.228]	L2: [34.069004]	Linf: [0.9490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 483 pred_label: 483 pred_clean_logit 0.9994887113571167
prompt generate:  castle  	labels:  [[483]]
decoder:  [49406, 3540, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([708], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([483], device='cuda:0') tensor(1.0316e-17, device='cuda:0')
L1: [6665.9526]	L2: [27.916533]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=59.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.1% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 560 pred_label: 541 pred_clean_logit 0.0017817472107708454
prompt generate:  football helmet  	labels:  [[541]]
decoder:  [49406, 1882, 11122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([541], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([560], device='cuda:0') tensor(3.5145e-28, device='cuda:0')
L1: [14558.256]	L2: [54.429813]	Linf: [0.8745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.0%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 565 pred_label: 519 pred_clean_logit 0.08398216217756271
prompt generate:  freight car  	labels:  [[519]]
decoder:  [49406, 17023, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([525], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([565], device='cuda:0') tensor(2.0474e-25, device='cuda:0')
L1: [8753.365]	L2: [31.052876]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 718 pred_label: 718 pred_clean_logit 0.8794013857841492
prompt generate:  pier  	labels:  [[718]]
decoder:  [49406, 11348, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([821], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([718], device='cuda:0') tensor(2.9582e-12, device='cuda:0')
L1: [4842.765]	L2: [21.608747]	Linf: [0.89411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 305 pred_label: 305 pred_clean_logit 0.8291129469871521
prompt generate:  dung beetle  	labels:  [[305]]
decoder:  [49406, 33712, 16534, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([302], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([305], device='cuda:0') tensor(1.7401e-11, device='cuda:0')
L1: [5711.6514]	L2: [20.042246]	Linf: [0.45882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=55.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.7% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 483 pred_label: 483 pred_clean_logit 0.9997243285179138
prompt generate:  castle  	labels:  [[483]]
decoder:  [49406, 3540, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([708], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([483], device='cuda:0') tensor(7.7418e-16, device='cuda:0')
L1: [5249.7534]	L2: [23.075788]	Linf: [0.5686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.7%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=62.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 62.1% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 972 pred_label: 972 pred_clean_logit 0.7421599626541138
prompt generate:  cliff  	labels:  [[972]]
decoder:  [49406, 10625, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([383], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([972], device='cuda:0') tensor(1.2019e-24, device='cuda:0')
L1: [11881.871]	L2: [42.021553]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 770 pred_label: 770 pred_clean_logit 0.9997656941413879
prompt generate:  running shoe  	labels:  [[770]]
decoder:  [49406, 2761, 7342, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([597], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([770], device='cuda:0') tensor(2.7605e-17, device='cuda:0')
L1: [4555.9805]	L2: [23.045197]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 570 pred_label: 570 pred_clean_logit 0.999969482421875
prompt generate:  gasmask  	labels:  [[570]]
decoder:  [49406, 5047, 8306, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([678], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([570], device='cuda:0') tensor(3.4204e-36, device='cuda:0')
L1: [10087.136]	L2: [43.70417]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=26.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=45.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.2% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 323 pred_label: 323 pred_clean_logit 0.9999911785125732
prompt generate:  monarch  	labels:  [[323]]
decoder:  [49406, 22619, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([323], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([323], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [9252.769]	L2: [39.512897]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.1%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=25.9%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 815 pred_label: 815 pred_clean_logit 0.9626708626747131
prompt generate:  spider web  	labels:  [[815]]
decoder:  [49406, 7622, 4601, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([815], device='cuda:0') tensor(2.8024e-22, device='cuda:0')
L1: [9709.185]	L2: [36.516888]	Linf: [0.62352943]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=27.1%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 961 pred_label: 961 pred_clean_logit 0.9996494054794312
prompt generate:  dough  	labels:  [[961]]
decoder:  [49406, 14983, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([995], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([961], device='cuda:0') tensor(4.4998e-17, device='cuda:0')
L1: [5504.6787]	L2: [22.175913]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=24.1%
Timestep  4: Avg Loss=0.000011, Std=0.000005, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 538 pred_label: 538 pred_clean_logit 0.5959685444831848
prompt generate:  dome  	labels:  [[538]]
decoder:  [49406, 9827, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([861], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([538], device='cuda:0') tensor(2.0487e-18, device='cuda:0')
L1: [10173.098]	L2: [33.75057]	Linf: [0.4392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.1%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=45.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.8% (timestep 4)
Min contribution: 7.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 113 pred_label: 113 pred_clean_logit 0.9999963045120239
prompt generate:  snail  	labels:  [[113]]
decoder:  [49406, 23132, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([113], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([113], device='cuda:0') tensor(1., device='cuda:0')
L1: [4325.2705]	L2: [15.829612]	Linf: [0.49411768]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 877 pred_label: 760 pred_clean_logit 0.17782972753047943
prompt generate:  turnstile  	labels:  [[760]]
decoder:  [49406, 5522, 522, 989, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([675], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([877], device='cuda:0') tensor(3.7297e-18, device='cuda:0')
L1: [6159.5054]	L2: [25.244791]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 821 pred_label: 821 pred_clean_logit 0.9962553977966309
prompt generate:  steel arch bridge  	labels:  [[821]]
decoder:  [49406, 4726, 8557, 2465, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([752], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([821], device='cuda:0') tensor(4.3338e-12, device='cuda:0')
L1: [5038.1406]	L2: [19.627123]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=20.4%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 6.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 366 pred_label: 366 pred_clean_logit 0.9999909400939941
prompt generate:  gorilla  	labels:  [[366]]
decoder:  [49406, 21994, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([376], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([366], device='cuda:0') tensor(1.1098e-15, device='cuda:0')
L1: [6885.734]	L2: [25.082653]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 762 pred_label: 779 pred_clean_logit 0.0791083350777626
prompt generate:  restaurant  	labels:  [[779]]
decoder:  [49406, 4489, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([779], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([762], device='cuda:0') tensor(1.0603e-22, device='cuda:0')
L1: [8640.507]	L2: [33.324802]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 752 pred_label: 752 pred_clean_logit 0.8864291310310364
prompt generate:  racket  	labels:  [[752]]
decoder:  [49406, 37691, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([890], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([752], device='cuda:0') tensor(1.0354e-15, device='cuda:0')
L1: [4493.306]	L2: [19.54576]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 759 pred_label: 759 pred_clean_logit 0.9999091625213623
prompt generate:  reflex camera  	labels:  [[759]]
decoder:  [49406, 36050, 3934, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([759], device='cuda:0') tensor(0.9984, device='cuda:0')
after_true: tensor([759], device='cuda:0') tensor(0.9984, device='cuda:0')
L1: [5288.299]	L2: [22.348898]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 743 pred_label: 698 pred_clean_logit 0.0007994522457011044
prompt generate:  prison  	labels:  [[698]]
decoder:  [49406, 6622, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([698], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([743], device='cuda:0') tensor(2.1790e-14, device='cuda:0')
L1: [10728.345]	L2: [42.3039]	Linf: [0.90588236]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 893 pred_label: 893 pred_clean_logit 0.4368836283683777
prompt generate:  wallet  	labels:  [[893]]
decoder:  [49406, 12154, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([626], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([893], device='cuda:0') tensor(1.1118e-18, device='cuda:0')
L1: [7081.8857]	L2: [28.286022]	Linf: [0.95686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=57.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.1% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 49 pred_label: 49 pred_clean_logit 0.9981182813644409
prompt generate:  African crocodile  	labels:  [[49]]
decoder:  [49406, 4736, 24757, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([50], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([49], device='cuda:0') tensor(3.0341e-17, device='cuda:0')
L1: [10154.055]	L2: [40.620514]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 22 pred_label: 22 pred_clean_logit 0.9888076186180115
prompt generate:  bald eagle  	labels:  [[22]]
decoder:  [49406, 14875, 7517, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([21], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([22], device='cuda:0') tensor(4.3463e-13, device='cuda:0')
L1: [4116.4204]	L2: [19.72888]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=21.8%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.2% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 825 pred_label: 825 pred_clean_logit 0.9365487098693848
prompt generate:  stone wall  	labels:  [[825]]
decoder:  [49406, 2441, 2569, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([931], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([825], device='cuda:0') tensor(2.9249e-29, device='cuda:0')
L1: [13033.07]	L2: [45.5205]	Linf: [0.6862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=25.7%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 476 pred_label: 792 pred_clean_logit 1.4199355064192787e-05
prompt generate:  carousel  	labels:  [[792]]
decoder:  [49406, 36665, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([792], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([476], device='cuda:0') tensor(4.3173e-23, device='cuda:0')
L1: [5218.526]	L2: [23.960064]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 458 pred_label: 458 pred_clean_logit 0.9929064512252808
prompt generate:  brass  	labels:  [[458]]
decoder:  [49406, 11655, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([509], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([458], device='cuda:0') tensor(1.4396e-15, device='cuda:0')
L1: [7968.1494]	L2: [27.116045]	Linf: [0.48235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 470 pred_label: 470 pred_clean_logit 0.9999986886978149
prompt generate:  candle  	labels:  [[470]]
decoder:  [49406, 12674, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([470], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([470], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2888.1257]	L2: [16.230469]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=16.4%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.2%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=46.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.2% (timestep 4)
Min contribution: 5.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 97 pred_label: 97 pred_clean_logit 0.997694194316864
prompt generate:  drake  	labels:  [[97]]
decoder:  [49406, 8958, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([91], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([97], device='cuda:0') tensor(1.7852e-16, device='cuda:0')
L1: [13110.53]	L2: [45.91711]	Linf: [0.6862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=26.5%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 814 pred_label: 814 pred_clean_logit 0.999995231628418
prompt generate:  speedboat  	labels:  [[814]]
decoder:  [49406, 6860, 4440, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([814], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([814], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [1986.1099]	L2: [8.368475]	Linf: [0.43137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.6%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.8%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=49.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.8% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 582 pred_label: 582 pred_clean_logit 0.9996342658996582
prompt generate:  grocery store  	labels:  [[582]]
decoder:  [49406, 13826, 2183, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([762], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([582], device='cuda:0') tensor(7.0586e-15, device='cuda:0')
L1: [11456.149]	L2: [44.320602]	Linf: [0.91764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.3%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 580 pred_label: 580 pred_clean_logit 0.8767382502555847
prompt generate:  greenhouse  	labels:  [[580]]
decoder:  [49406, 20819, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([580], device='cuda:0') tensor(1.8992e-26, device='cuda:0')
L1: [13802.647]	L2: [48.198826]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 619 pred_label: 611 pred_clean_logit 0.001399543834850192
prompt generate:  lampshade  	labels:  [[611]]
decoder:  [49406, 26700, 10097, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([905], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([619], device='cuda:0') tensor(1.6514e-16, device='cuda:0')
L1: [7132.145]	L2: [31.773376]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=9.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=21.5%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=59.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.7% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 875 pred_label: 875 pred_clean_logit 0.9964978694915771
prompt generate:  trombone  	labels:  [[875]]
decoder:  [49406, 44423, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([870], device='cuda:0') tensor(0.9996, device='cuda:0')
after_true: tensor([875], device='cuda:0') tensor(2.8326e-10, device='cuda:0')
L1: [5064.1333]	L2: [29.560633]	Linf: [0.972549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 609 pred_label: 436 pred_clean_logit 0.1649796962738037
prompt generate:  jeep  	labels:  [[436]]
decoder:  [49406, 11286, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([436], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([609], device='cuda:0') tensor(1.2255e-12, device='cuda:0')
L1: [8492.389]	L2: [29.76977]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 421 pred_label: 421 pred_clean_logit 0.9511080980300903
prompt generate:  bannister  	labels:  [[421]]
decoder:  [49406, 1159, 36640, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([567], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([421], device='cuda:0') tensor(1.5734e-30, device='cuda:0')
L1: [7574.44]	L2: [32.34008]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 513 pred_label: 513 pred_clean_logit 0.9999873638153076
prompt generate:  cornet  	labels:  [[513]]
decoder:  [49406, 851, 2315, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([558], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([513], device='cuda:0') tensor(1.0520e-24, device='cuda:0')
L1: [6884.2227]	L2: [29.356667]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.0%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=47.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.8% (timestep 4)
Min contribution: 6.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 775 pred_label: 775 pred_clean_logit 0.9971038699150085
prompt generate:  sarong  	labels:  [[775]]
decoder:  [49406, 1808, 846, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([514], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([775], device='cuda:0') tensor(1.3367e-26, device='cuda:0')
L1: [12654.973]	L2: [43.636684]	Linf: [0.6431372]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 701 pred_label: 701 pred_clean_logit 0.9999696016311646
prompt generate:  parachute  	labels:  [[701]]
decoder:  [49406, 30122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([417], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([701], device='cuda:0') tensor(6.1085e-12, device='cuda:0')
L1: [2915.2783]	L2: [13.593157]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 922 pred_label: 922 pred_clean_logit 0.9999139308929443
prompt generate:  menu  	labels:  [[922]]
decoder:  [49406, 6225, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([922], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([922], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [4950.6]	L2: [21.643278]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.4%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 468 pred_label: 436 pred_clean_logit 0.12694910168647766
prompt generate:  cab  	labels:  [[436]]
decoder:  [49406, 11912, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([562], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([468], device='cuda:0') tensor(3.8909e-28, device='cuda:0')
L1: [8420.204]	L2: [34.100693]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 94 pred_label: 94 pred_clean_logit 0.629352867603302
prompt generate:  hummingbird  	labels:  [[94]]
decoder:  [49406, 33072, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([95], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([94], device='cuda:0') tensor(1.4541e-11, device='cuda:0')
L1: [4179.5293]	L2: [16.716707]	Linf: [0.4666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 978 pred_label: 978 pred_clean_logit 0.7827085852622986
prompt generate:  seashore  	labels:  [[978]]
decoder:  [49406, 567, 31194, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([980], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([978], device='cuda:0') tensor(3.9406e-15, device='cuda:0')
L1: [4865.4517]	L2: [20.155775]	Linf: [0.46666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=56.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.2% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 141 pred_label: 141 pred_clean_logit 0.9998656511306763
prompt generate:  redshank  	labels:  [[141]]
decoder:  [49406, 1893, 24685, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([142], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([141], device='cuda:0') tensor(1.2651e-09, device='cuda:0')
L1: [4959.1606]	L2: [20.026953]	Linf: [0.58431375]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.0%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 227 pred_label: 227 pred_clean_logit 0.7454649806022644
prompt generate:  kelpie  	labels:  [[227]]
decoder:  [49406, 2825, 5319, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([269], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([227], device='cuda:0') tensor(5.2036e-18, device='cuda:0')
L1: [6075.6553]	L2: [24.027039]	Linf: [0.53333336]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 565 pred_label: 779 pred_clean_logit 3.6322679079603404e-05
prompt generate:  freight car  	labels:  [[779]]
decoder:  [49406, 17023, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([779], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([565], device='cuda:0') tensor(8.3923e-21, device='cuda:0')
L1: [5043.074]	L2: [22.925169]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.1%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 555 pred_label: 555 pred_clean_logit 0.9998262524604797
prompt generate:  fire engine  	labels:  [[555]]
decoder:  [49406, 1769, 5857, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([407], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([555], device='cuda:0') tensor(5.6875e-18, device='cuda:0')
L1: [6297.534]	L2: [31.366581]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=26.9%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=44.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.9% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 965 pred_label: 965 pred_clean_logit 0.9312538504600525
prompt generate:  burrito  	labels:  [[965]]
decoder:  [49406, 23473, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([935], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([965], device='cuda:0') tensor(1.6509e-25, device='cuda:0')
L1: [8171.239]	L2: [32.010857]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 990 pred_label: 990 pred_clean_logit 0.6793997287750244
prompt generate:  buckeye  	labels:  [[990]]
decoder:  [49406, 34549, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([113], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([990], device='cuda:0') tensor(2.4357e-22, device='cuda:0')
L1: [8718.503]	L2: [31.800879]	Linf: [0.5764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 858 pred_label: 858 pred_clean_logit 0.9375647306442261
prompt generate:  tile roof  	labels:  [[858]]
decoder:  [49406, 8227, 6449, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([858], device='cuda:0') tensor(2.6181e-16, device='cuda:0')
L1: [9445.581]	L2: [37.32725]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 517 pred_label: 517 pred_clean_logit 0.9975014328956604
prompt generate:  crane  	labels:  [[517]]
decoder:  [49406, 14626, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([724], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([517], device='cuda:0') tensor(1.2773e-12, device='cuda:0')
L1: [6592.757]	L2: [27.430645]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 814 pred_label: 814 pred_clean_logit 0.9999502897262573
prompt generate:  speedboat  	labels:  [[814]]
decoder:  [49406, 6860, 4440, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([814], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([814], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2551.2786]	L2: [16.136032]	Linf: [0.92156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=12.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=14.5%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=18.5%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=21.9%
Timestep  4: Avg Loss=0.000000, Std=0.000000, Contribution=32.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 32.5% (timestep 4)
Min contribution: 12.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 760 pred_label: 760 pred_clean_logit 0.9999169111251831
prompt generate:  refrigerator  	labels:  [[760]]
decoder:  [49406, 36662, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([771], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([760], device='cuda:0') tensor(1.2094e-12, device='cuda:0')
L1: [5437.008]	L2: [25.620548]	Linf: [0.9411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=11.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=13.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=15.9%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=21.5%
Timestep  4: Avg Loss=0.000002, Std=0.000002, Contribution=37.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 37.6% (timestep 4)
Min contribution: 11.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 777 pred_label: 777 pred_clean_logit 0.9999723434448242
prompt generate:  scabbard  	labels:  [[777]]
decoder:  [49406, 31716, 17514, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([597], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([777], device='cuda:0') tensor(3.2983e-16, device='cuda:0')
L1: [5302.2944]	L2: [21.233736]	Linf: [0.7294117]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.1%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 984 pred_label: 984 pred_clean_logit 0.9997513890266418
prompt generate:  rapeseed  	labels:  [[984]]
decoder:  [49406, 46099, 6488, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([704], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([984], device='cuda:0') tensor(6.7229e-20, device='cuda:0')
L1: [13032.805]	L2: [43.762962]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 854 pred_label: 881 pred_clean_logit 0.11427261680364609
prompt generate:  theater curtain  	labels:  [[881]]
decoder:  [49406, 6128, 17223, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([881], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([854], device='cuda:0') tensor(1.8507e-22, device='cuda:0')
L1: [6587.855]	L2: [31.393024]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 931 pred_label: 931 pred_clean_logit 0.6596606969833374
prompt generate:  bagel  	labels:  [[931]]
decoder:  [49406, 28777, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([666], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([931], device='cuda:0') tensor(4.4736e-18, device='cuda:0')
L1: [3327.408]	L2: [11.978405]	Linf: [0.3137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 607 pred_label: 607 pred_clean_logit 0.9977635145187378
prompt generate:  jack-o'-lantern  	labels:  [[607]]
decoder:  [49406, 3267, 268, 334, 262, 268, 17185, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([844], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([607], device='cuda:0') tensor(7.6552e-19, device='cuda:0')
L1: [5423.992]	L2: [31.813477]	Linf: [0.92156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 869 pred_label: 869 pred_clean_logit 0.9990527033805847
prompt generate:  trench coat  	labels:  [[869]]
decoder:  [49406, 23846, 7356, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([652], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([869], device='cuda:0') tensor(7.4513e-10, device='cuda:0')
L1: [3747.192]	L2: [19.199903]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.6%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=58.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.6% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 656 pred_label: 656 pred_clean_logit 0.5572025775909424
prompt generate:  minivan  	labels:  [[656]]
decoder:  [49406, 1810, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([436], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([656], device='cuda:0') tensor(8.6998e-09, device='cuda:0')
L1: [6591.953]	L2: [26.640394]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 897 pred_label: 589 pred_clean_logit 0.0016921766800805926
prompt generate:  washer  	labels:  [[589]]
decoder:  [49406, 24085, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([589], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([897], device='cuda:0') tensor(0., device='cuda:0')
L1: [9283.17]	L2: [37.304127]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 959 pred_label: 959 pred_clean_logit 0.9973006844520569
prompt generate:  carbonara  	labels:  [[959]]
decoder:  [49406, 14038, 3340, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([923], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([959], device='cuda:0') tensor(1.1287e-15, device='cuda:0')
L1: [9383.173]	L2: [37.06684]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 959 pred_label: 959 pred_clean_logit 0.8642897009849548
prompt generate:  carbonara  	labels:  [[959]]
decoder:  [49406, 14038, 3340, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([947], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([959], device='cuda:0') tensor(1.4629e-21, device='cuda:0')
L1: [7886.941]	L2: [29.49664]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.7%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 422 pred_label: 422 pred_clean_logit 0.9980229139328003
prompt generate:  barbell  	labels:  [[422]]
decoder:  [49406, 1040, 3718, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([409], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([422], device='cuda:0') tensor(1.3031e-14, device='cuda:0')
L1: [4048.5103]	L2: [20.172907]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 859 pred_label: 859 pred_clean_logit 1.0
prompt generate:  toaster  	labels:  [[859]]
decoder:  [49406, 39061, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([859], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([859], device='cuda:0') tensor(1., device='cuda:0')
L1: [3680.9846]	L2: [16.400728]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.6%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=22.1%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 640 pred_label: 640 pred_clean_logit 0.9999562501907349
prompt generate:  manhole cover  	labels:  [[640]]
decoder:  [49406, 723, 5341, 2202, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([892], device='cuda:0') tensor(0.9995, device='cuda:0')
after_true: tensor([640], device='cuda:0') tensor(4.1383e-19, device='cuda:0')
L1: [10578.934]	L2: [37.579666]	Linf: [0.69803923]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=11.9%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=24.6%
Timestep  4: Avg Loss=0.000014, Std=0.000006, Contribution=55.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.7% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 649 pred_label: 649 pred_clean_logit 0.9936981797218323
prompt generate:  megalith  	labels:  [[649]]
decoder:  [49406, 37650, 1757, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([978], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([649], device='cuda:0') tensor(3.6417e-15, device='cuda:0')
L1: [5274.4043]	L2: [20.470348]	Linf: [0.5882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 57 pred_label: 57 pred_clean_logit 0.9991514682769775
prompt generate:  garter snake  	labels:  [[57]]
decoder:  [49406, 48420, 8798, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([311], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([57], device='cuda:0') tensor(1.1122e-17, device='cuda:0')
L1: [10045.883]	L2: [37.189255]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.4%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.3%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=28.3%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 409 pred_label: 409 pred_clean_logit 0.5246387720108032
prompt generate:  analog clock  	labels:  [[409]]
decoder:  [49406, 19963, 6716, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([826], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([409], device='cuda:0') tensor(1.4339e-22, device='cuda:0')
L1: [7948.891]	L2: [36.48299]	Linf: [0.9098039]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=48.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.1% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 472 pred_label: 472 pred_clean_logit 0.9619584083557129
prompt generate:  canoe  	labels:  [[472]]
decoder:  [49406, 23503, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([693], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([472], device='cuda:0') tensor(9.1757e-12, device='cuda:0')
L1: [6831.788]	L2: [28.899483]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 430 pred_label: 430 pred_clean_logit 0.7333475351333618
prompt generate:  basketball  	labels:  [[430]]
decoder:  [49406, 3835, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([793], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([430], device='cuda:0') tensor(6.7333e-38, device='cuda:0')
L1: [10320.177]	L2: [40.553623]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 421 pred_label: 421 pred_clean_logit 0.4874691963195801
prompt generate:  bannister  	labels:  [[421]]
decoder:  [49406, 1159, 36640, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([839], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([421], device='cuda:0') tensor(6.2339e-20, device='cuda:0')
L1: [11319.062]	L2: [42.99169]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 140 pred_label: 140 pred_clean_logit 0.9996304512023926
prompt generate:  red-backed sandpiper  	labels:  [[140]]
decoder:  [49406, 736, 268, 12721, 2147, 16293, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([142], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([140], device='cuda:0') tensor(7.1929e-11, device='cuda:0')
L1: [6243.5615]	L2: [26.348112]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.6% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 498 pred_label: 498 pred_clean_logit 0.9737256765365601
prompt generate:  cinema  	labels:  [[498]]
decoder:  [49406, 6443, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([727], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([498], device='cuda:0') tensor(6.5855e-22, device='cuda:0')
L1: [4400.628]	L2: [20.903547]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=24.6%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=57.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.2% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 565 pred_label: 565 pred_clean_logit 0.9999967813491821
prompt generate:  freight car  	labels:  [[565]]
decoder:  [49406, 17023, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([565], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([565], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6644.8555]	L2: [30.286919]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 404 pred_label: 404 pred_clean_logit 0.796248197555542
prompt generate:  airliner  	labels:  [[404]]
decoder:  [49406, 1281, 11618, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([786], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([404], device='cuda:0') tensor(3.1610e-22, device='cuda:0')
L1: [5162.7646]	L2: [21.410639]	Linf: [0.72156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=2.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=12.1%
Timestep  3: Avg Loss=0.000010, Std=0.000004, Contribution=25.9%
Timestep  4: Avg Loss=0.000020, Std=0.000008, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 581 pred_label: 581 pred_clean_logit 0.9992809891700745
prompt generate:  grille  	labels:  [[581]]
decoder:  [49406, 34748, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([717], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([581], device='cuda:0') tensor(1.1697e-11, device='cuda:0')
L1: [9365.427]	L2: [44.708588]	Linf: [0.99215686]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=46.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.5% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 415 pred_label: 949 pred_clean_logit 0.10014360398054123
prompt generate:  bakery  	labels:  [[949]]
decoder:  [49406, 13377, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([943], device='cuda:0') tensor(0.9873, device='cuda:0')
after_true: tensor([415], device='cuda:0') tensor(1.0638e-10, device='cuda:0')
L1: [7088.4863]	L2: [29.220373]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 538 pred_label: 538 pred_clean_logit 0.9873365759849548
prompt generate:  dome  	labels:  [[538]]
decoder:  [49406, 9827, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([406], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([538], device='cuda:0') tensor(2.2742e-10, device='cuda:0')
L1: [11641.201]	L2: [43.000206]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=9.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=16.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=38.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 38.5% (timestep 4)
Min contribution: 9.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 768 pred_label: 701 pred_clean_logit 0.0005935734952799976
prompt generate:  rugby ball  	labels:  [[701]]
decoder:  [49406, 4964, 1069, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([837], device='cuda:0') tensor(0.9994, device='cuda:0')
after_true: tensor([768], device='cuda:0') tensor(2.7272e-32, device='cuda:0')
L1: [6396.381]	L2: [27.361782]	Linf: [0.6117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.4%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=25.7%
Timestep  4: Avg Loss=0.000019, Std=0.000005, Contribution=57.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.2% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 819 pred_label: 819 pred_clean_logit 0.928184449672699
prompt generate:  stage  	labels:  [[819]]
decoder:  [49406, 2170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([420], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([819], device='cuda:0') tensor(3.5054e-30, device='cuda:0')
L1: [5506.043]	L2: [21.524996]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.0%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=25.7%
Timestep  4: Avg Loss=0.000019, Std=0.000006, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 439 pred_label: 439 pred_clean_logit 0.9990158081054688
prompt generate:  bearskin  	labels:  [[439]]
decoder:  [49406, 6375, 3575, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([645], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([439], device='cuda:0') tensor(7.7136e-19, device='cuda:0')
L1: [7919.5796]	L2: [34.06087]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 336 pred_label: 336 pred_clean_logit 0.9687944650650024
prompt generate:  marmot  	labels:  [[336]]
decoder:  [49406, 675, 15452, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([212], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([336], device='cuda:0') tensor(1.2427e-19, device='cuda:0')
L1: [9982.005]	L2: [33.65245]	Linf: [0.6509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 50 pred_label: 50 pred_clean_logit 0.9998533725738525
prompt generate:  American alligator  	labels:  [[50]]
decoder:  [49406, 2151, 28574, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([71], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([50], device='cuda:0') tensor(2.0669e-19, device='cuda:0')
L1: [6476.675]	L2: [22.989902]	Linf: [0.45490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=59.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.4% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 303 pred_label: 303 pred_clean_logit 0.999924898147583
prompt generate:  long-horned beetle  	labels:  [[303]]
decoder:  [49406, 1538, 268, 34526, 16534, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([304], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([303], device='cuda:0') tensor(1.8846e-09, device='cuda:0')
L1: [4910.8555]	L2: [19.112755]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 33 pred_label: 33 pred_clean_logit 0.9924934506416321
prompt generate:  loggerhead  	labels:  [[33]]
decoder:  [49406, 549, 12367, 1375, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([123], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([33], device='cuda:0') tensor(5.2709e-19, device='cuda:0')
L1: [7634.69]	L2: [28.737469]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 708 pred_label: 708 pred_clean_logit 0.9683083295822144
prompt generate:  pedestal  	labels:  [[708]]
decoder:  [49406, 12862, 5535, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([873], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([708], device='cuda:0') tensor(1.2052e-14, device='cuda:0')
L1: [7632.1567]	L2: [29.030579]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 475 pred_label: 475 pred_clean_logit 0.8436539173126221
prompt generate:  car mirror  	labels:  [[475]]
decoder:  [49406, 1615, 7220, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([454], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([475], device='cuda:0') tensor(6.4280e-16, device='cuda:0')
L1: [6970.9644]	L2: [29.97131]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 441 pred_label: 441 pred_clean_logit 0.9957113265991211
prompt generate:  beer glass  	labels:  [[441]]
decoder:  [49406, 2544, 3313, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([438], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([441], device='cuda:0') tensor(3.7028e-22, device='cuda:0')
L1: [5937.035]	L2: [23.018213]	Linf: [0.6]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=47.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.0% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 308 pred_label: 308 pred_clean_logit 0.9999992847442627
prompt generate:  fly  	labels:  [[308]]
decoder:  [49406, 3228, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([309], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([308], device='cuda:0') tensor(1.5555e-10, device='cuda:0')
L1: [6650.4194]	L2: [26.915382]	Linf: [0.9372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 990 pred_label: 990 pred_clean_logit 0.9986425042152405
prompt generate:  buckeye  	labels:  [[990]]
decoder:  [49406, 34549, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([626], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([990], device='cuda:0') tensor(1.0395e-07, device='cuda:0')
L1: [11047.504]	L2: [46.24047]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.7%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 511 pred_label: 511 pred_clean_logit 0.9980359673500061
prompt generate:  convertible  	labels:  [[511]]
decoder:  [49406, 19608, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([436], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([511], device='cuda:0') tensor(3.0899e-11, device='cuda:0')
L1: [8203.459]	L2: [34.590683]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.3% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 644 pred_label: 644 pred_clean_logit 0.9999889135360718
prompt generate:  matchstick  	labels:  [[644]]
decoder:  [49406, 7733, 4987, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([644], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([644], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2317.1567]	L2: [11.592148]	Linf: [0.62745094]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000000, Contribution=18.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=48.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.8% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 341 pred_label: 341 pred_clean_logit 0.9999947547912598
prompt generate:  hog  	labels:  [[341]]
decoder:  [49406, 13255, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([341], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([341], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [4910.553]	L2: [17.90546]	Linf: [0.38823527]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 582 pred_label: 582 pred_clean_logit 0.9999464750289917
prompt generate:  grocery store  	labels:  [[582]]
decoder:  [49406, 13826, 2183, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([509], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([582], device='cuda:0') tensor(1.2858e-19, device='cuda:0')
L1: [11122.702]	L2: [42.485268]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.8%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 698 pred_label: 698 pred_clean_logit 0.6386620998382568
prompt generate:  palace  	labels:  [[698]]
decoder:  [49406, 6381, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([624], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([698], device='cuda:0') tensor(7.6172e-20, device='cuda:0')
L1: [5683.6943]	L2: [21.48879]	Linf: [0.57254905]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 919 pred_label: 919 pred_clean_logit 0.9713510274887085
prompt generate:  street sign  	labels:  [[919]]
decoder:  [49406, 2012, 2292, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([737], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([919], device='cuda:0') tensor(1.7663e-13, device='cuda:0')
L1: [5555.196]	L2: [21.914244]	Linf: [0.5058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 974 pred_label: 974 pred_clean_logit 0.9999333620071411
prompt generate:  geyser  	labels:  [[974]]
decoder:  [49406, 619, 33121, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([977], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([974], device='cuda:0') tensor(2.4017e-12, device='cuda:0')
L1: [6034.8433]	L2: [24.949972]	Linf: [0.69803923]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.6%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=60.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.6% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 310 pred_label: 310 pred_clean_logit 0.9997653365135193
prompt generate:  ant  	labels:  [[310]]
decoder:  [49406, 773, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([599], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([310], device='cuda:0') tensor(5.9017e-23, device='cuda:0')
L1: [18450.996]	L2: [64.67386]	Linf: [0.91764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000009, Std=0.000002, Contribution=27.2%
Timestep  4: Avg Loss=0.000018, Std=0.000004, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 881 pred_label: 881 pred_clean_logit 0.9991846680641174
prompt generate:  upright  	labels:  [[881]]
decoder:  [49406, 29818, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([699], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([881], device='cuda:0') tensor(9.5288e-44, device='cuda:0')
L1: [8939.663]	L2: [32.627056]	Linf: [0.5686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 897 pred_label: 897 pred_clean_logit 0.9986914992332458
prompt generate:  washer  	labels:  [[897]]
decoder:  [49406, 24085, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([577], device='cuda:0') tensor(0.9982, device='cuda:0')
after_true: tensor([897], device='cuda:0') tensor(1.8996e-10, device='cuda:0')
L1: [3350.263]	L2: [15.814639]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 973 pred_label: 327 pred_clean_logit 0.16259407997131348
prompt generate:  coral reef  	labels:  [[327]]
decoder:  [49406, 12054, 15624, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([327], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([973], device='cuda:0') tensor(3.9822e-23, device='cuda:0')
L1: [11100.412]	L2: [38.934566]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=54.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.5% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 480 pred_label: 480 pred_clean_logit 0.9999616146087646
prompt generate:  cash machine  	labels:  [[480]]
decoder:  [49406, 5131, 4169, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([480], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([480], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3659.761]	L2: [16.759148]	Linf: [0.72156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=7.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.6%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=13.5%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.3%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=47.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.9% (timestep 4)
Min contribution: 7.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 309 pred_label: 309 pred_clean_logit 0.9999958276748657
prompt generate:  bee  	labels:  [[309]]
decoder:  [49406, 5028, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([309], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([309], device='cuda:0') tensor(0.9998, device='cuda:0')
L1: [4599.8667]	L2: [21.567837]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.8%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.3%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 619 pred_label: 786 pred_clean_logit 0.022109828889369965
prompt generate:  lampshade  	labels:  [[786]]
decoder:  [49406, 26700, 10097, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([665], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([619], device='cuda:0') tensor(4.6978e-19, device='cuda:0')
L1: [7867.3374]	L2: [36.581158]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=26.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 114 pred_label: 114 pred_clean_logit 0.9981143474578857
prompt generate:  slug  	labels:  [[114]]
decoder:  [49406, 34190, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([34], device='cuda:0') tensor(0.9946, device='cuda:0')
after_true: tensor([114], device='cuda:0') tensor(2.8129e-13, device='cuda:0')
L1: [16009.16]	L2: [53.256073]	Linf: [0.6823529]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.3%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 475 pred_label: 575 pred_clean_logit 0.47145891189575195
prompt generate:  car mirror  	labels:  [[575]]
decoder:  [49406, 1615, 7220, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([575], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([475], device='cuda:0') tensor(6.5258e-23, device='cuda:0')
L1: [3246.561]	L2: [12.103624]	Linf: [0.43137258]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 971 pred_label: 971 pred_clean_logit 1.0
prompt generate:  bubble  	labels:  [[971]]
decoder:  [49406, 10799, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([971], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([971], device='cuda:0') tensor(1., device='cuda:0')
L1: [7922.7134]	L2: [27.385862]	Linf: [0.5647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.1%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=27.3%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=45.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.3% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 478 pred_label: 478 pred_clean_logit 0.9523612260818481
prompt generate:  carton  	labels:  [[478]]
decoder:  [49406, 41812, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([561], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([478], device='cuda:0') tensor(9.8430e-16, device='cuda:0')
L1: [4653.103]	L2: [20.80731]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 707 pred_label: 707 pred_clean_logit 0.9693230390548706
prompt generate:  pay-phone  	labels:  [[707]]
decoder:  [49406, 3345, 268, 1951, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([528], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([707], device='cuda:0') tensor(6.1563e-12, device='cuda:0')
L1: [4809.1377]	L2: [20.259794]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 873 pred_label: 873 pred_clean_logit 0.9999966621398926
prompt generate:  triumphal arch  	labels:  [[873]]
decoder:  [49406, 14782, 1037, 8708, 8557, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([886], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([873], device='cuda:0') tensor(7.9366e-23, device='cuda:0')
L1: [7736.761]	L2: [31.36329]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000012, Std=0.000005, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 544 pred_label: 544 pred_clean_logit 0.6786356568336487
prompt generate:  Dutch oven  	labels:  [[544]]
decoder:  [49406, 7991, 12579, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([938], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([544], device='cuda:0') tensor(1.5596e-25, device='cuda:0')
L1: [7108.7095]	L2: [28.953842]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=54.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.5% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 436 pred_label: 436 pred_clean_logit 0.8622145652770996
prompt generate:  beach wagon  	labels:  [[436]]
decoder:  [49406, 2117, 13260, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([436], device='cuda:0') tensor(3.6375e-20, device='cuda:0')
L1: [7237.632]	L2: [31.75072]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=42.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.0% (timestep 4)
Min contribution: 8.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 853 pred_label: 853 pred_clean_logit 0.9991968274116516
prompt generate:  thatch  	labels:  [[853]]
decoder:  [49406, 6303, 634, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([448], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([853], device='cuda:0') tensor(8.7221e-17, device='cuda:0')
L1: [5189.153]	L2: [21.375761]	Linf: [0.5921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=57.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.5% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 479 pred_label: 479 pred_clean_logit 0.8860898017883301
prompt generate:  car wheel  	labels:  [[479]]
decoder:  [49406, 1615, 6744, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([817], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([479], device='cuda:0') tensor(1.0322e-12, device='cuda:0')
L1: [7632.2427]	L2: [31.202494]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=47.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.2% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 912 pred_label: 912 pred_clean_logit 0.9958374500274658
prompt generate:  worm fence  	labels:  [[912]]
decoder:  [49406, 10945, 12679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([730], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([912], device='cuda:0') tensor(1.1749e-15, device='cuda:0')
L1: [8335.645]	L2: [33.100365]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 879 pred_label: 879 pred_clean_logit 0.9997814297676086
prompt generate:  umbrella  	labels:  [[879]]
decoder:  [49406, 17143, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([701], device='cuda:0') tensor(0.9875, device='cuda:0')
after_true: tensor([879], device='cuda:0') tensor(1.1798e-12, device='cuda:0')
L1: [6731.0977]	L2: [27.601027]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=46.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.7% (timestep 4)
Min contribution: 6.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 307 pred_label: 307 pred_clean_logit 0.9932476282119751
prompt generate:  weevil  	labels:  [[307]]
decoder:  [49406, 716, 3000, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([304], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([307], device='cuda:0') tensor(1.3799e-15, device='cuda:0')
L1: [7505.282]	L2: [31.829493]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 470 pred_label: 470 pred_clean_logit 1.0
prompt generate:  candle  	labels:  [[470]]
decoder:  [49406, 12674, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([902], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([470], device='cuda:0') tensor(1.8861e-19, device='cuda:0')
L1: [2085.0864]	L2: [9.212563]	Linf: [0.61176467]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=21.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=57.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.4% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 457 pred_label: 457 pred_clean_logit 1.0
prompt generate:  bow tie  	labels:  [[457]]
decoder:  [49406, 4040, 3422, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([457], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([457], device='cuda:0') tensor(1., device='cuda:0')
L1: [3089.5215]	L2: [15.65694]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.7%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=25.1%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 360 pred_label: 360 pred_clean_logit 0.9999902248382568
prompt generate:  otter  	labels:  [[360]]
decoder:  [49406, 22456, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([356], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([360], device='cuda:0') tensor(7.6715e-21, device='cuda:0')
L1: [6287.4595]	L2: [23.262045]	Linf: [0.5176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 79 pred_label: 79 pred_clean_logit 0.9998062252998352
prompt generate:  centipede  	labels:  [[79]]
decoder:  [49406, 48889, 19560, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([599], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([79], device='cuda:0') tensor(4.8895e-10, device='cuda:0')
L1: [15906.857]	L2: [52.445232]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 649 pred_label: 863 pred_clean_logit 1.2027113598378492e-06
prompt generate:  megalith  	labels:  [[863]]
decoder:  [49406, 37650, 1757, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([899], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([649], device='cuda:0') tensor(3.3803e-39, device='cuda:0')
L1: [7000.628]	L2: [27.238913]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 442 pred_label: 442 pred_clean_logit 0.28843700885772705
prompt generate:  bell cote  	labels:  [[442]]
decoder:  [49406, 3718, 20751, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([863], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([442], device='cuda:0') tensor(9.4669e-25, device='cuda:0')
L1: [6061.0347]	L2: [26.224333]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.7%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=14.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=46.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.7% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 107 pred_label: 107 pred_clean_logit 0.9990320205688477
prompt generate:  jellyfish  	labels:  [[107]]
decoder:  [49406, 30988, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([749], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([107], device='cuda:0') tensor(1.5375e-25, device='cuda:0')
L1: [4411.3496]	L2: [19.663006]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 637 pred_label: 637 pred_clean_logit 0.5035318732261658
prompt generate:  mailbox  	labels:  [[637]]
decoder:  [49406, 31482, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([860], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([637], device='cuda:0') tensor(4.2765e-13, device='cuda:0')
L1: [7297.542]	L2: [30.92761]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=45.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.9% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 970 pred_label: 970 pred_clean_logit 0.9996525049209595
prompt generate:  alp  	labels:  [[970]]
decoder:  [49406, 39342, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([34], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([970], device='cuda:0') tensor(1.5439e-21, device='cuda:0')
L1: [5784.737]	L2: [23.347815]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000009, Std=0.000005, Contribution=56.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.5% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 785 pred_label: 785 pred_clean_logit 0.38467782735824585
prompt generate:  seat belt  	labels:  [[785]]
decoder:  [49406, 4922, 7373, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([748], device='cuda:0') tensor(0.9905, device='cuda:0')
after_true: tensor([785], device='cuda:0') tensor(6.6195e-10, device='cuda:0')
L1: [2748.3296]	L2: [12.15036]	Linf: [0.5803921]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.3%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 933 pred_label: 933 pred_clean_logit 0.9997177720069885
prompt generate:  cheeseburger  	labels:  [[933]]
decoder:  [49406, 41200, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([441], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([933], device='cuda:0') tensor(4.8718e-15, device='cuda:0')
L1: [6196.886]	L2: [25.871012]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=48.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.0% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 656 pred_label: 656 pred_clean_logit 0.999908447265625
prompt generate:  minivan  	labels:  [[656]]
decoder:  [49406, 1810, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([675], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([656], device='cuda:0') tensor(2.9702e-17, device='cuda:0')
L1: [7369.3574]	L2: [28.218983]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=47.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.9% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 521 pred_label: 124 pred_clean_logit 0.007873756811022758
prompt generate:  Crock Pot  	labels:  [[124]]
decoder:  [49406, 1192, 868, 5168, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([932], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([521], device='cuda:0') tensor(1.0456e-20, device='cuda:0')
L1: [7817.3374]	L2: [31.081436]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 510 pred_label: 510 pred_clean_logit 0.8898465037345886
prompt generate:  container ship  	labels:  [[510]]
decoder:  [49406, 14913, 1158, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([536], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([510], device='cuda:0') tensor(1.5991e-10, device='cuda:0')
L1: [10278.815]	L2: [43.008198]	Linf: [0.9764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 865 pred_label: 865 pred_clean_logit 0.9999620914459229
prompt generate:  toyshop  	labels:  [[865]]
decoder:  [49406, 14387, 1557, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([760], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([865], device='cuda:0') tensor(6.4552e-21, device='cuda:0')
L1: [10011.955]	L2: [37.73912]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=47.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.9% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 23 pred_label: 85 pred_clean_logit 0.32775434851646423
prompt generate:  vulture  	labels:  [[85]]
decoder:  [49406, 34593, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([85], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([23], device='cuda:0') tensor(2.3260e-22, device='cuda:0')
L1: [8830.589]	L2: [39.23715]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 857 pred_label: 857 pred_clean_logit 0.9999997615814209
prompt generate:  throne  	labels:  [[857]]
decoder:  [49406, 15999, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([857], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([857], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7642.196]	L2: [29.163584]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.2%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.4%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=49.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.8% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 498 pred_label: 498 pred_clean_logit 0.9988260865211487
prompt generate:  cinema  	labels:  [[498]]
decoder:  [49406, 6443, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([733], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([498], device='cuda:0') tensor(1.9311e-15, device='cuda:0')
L1: [5459.074]	L2: [23.076342]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 518 pred_label: 518 pred_clean_logit 0.9924168586730957
prompt generate:  crash helmet  	labels:  [[518]]
decoder:  [49406, 5033, 11122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([746], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([518], device='cuda:0') tensor(3.1900e-18, device='cuda:0')
L1: [9310.823]	L2: [41.49641]	Linf: [0.9411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=15.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=29.2%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=45.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.9% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 762 pred_label: 762 pred_clean_logit 0.9736002683639526
prompt generate:  restaurant  	labels:  [[762]]
decoder:  [49406, 4489, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([782], device='cuda:0') tensor(0.9943, device='cuda:0')
after_true: tensor([762], device='cuda:0') tensor(8.2427e-22, device='cuda:0')
L1: [10150.902]	L2: [39.258835]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 865 pred_label: 865 pred_clean_logit 0.9338913559913635
prompt generate:  toyshop  	labels:  [[865]]
decoder:  [49406, 14387, 1557, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([606], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([865], device='cuda:0') tensor(3.5529e-13, device='cuda:0')
L1: [12831.056]	L2: [49.94599]	Linf: [0.9607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.9%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=48.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.5% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 480 pred_label: 480 pred_clean_logit 0.9750290513038635
prompt generate:  cash machine  	labels:  [[480]]
decoder:  [49406, 5131, 4169, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([827], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([480], device='cuda:0') tensor(3.3216e-23, device='cuda:0')
L1: [4183.8545]	L2: [17.30576]	Linf: [0.6980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=14.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=46.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.9% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 873 pred_label: 873 pred_clean_logit 0.999998927116394
prompt generate:  triumphal arch  	labels:  [[873]]
decoder:  [49406, 14782, 1037, 8708, 8557, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([873], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([873], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6103.1885]	L2: [27.420069]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 476 pred_label: 724 pred_clean_logit 0.14773455262184143
prompt generate:  carousel  	labels:  [[724]]
decoder:  [49406, 36665, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([724], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([476], device='cuda:0') tensor(5.2441e-17, device='cuda:0')
L1: [7638.8276]	L2: [36.43667]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=57.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.5% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 315 pred_label: 315 pred_clean_logit 0.5958958864212036
prompt generate:  mantis  	labels:  [[315]]
decoder:  [49406, 39946, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([312], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([315], device='cuda:0') tensor(1.6431e-10, device='cuda:0')
L1: [4364.757]	L2: [19.848522]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.1% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 609 pred_label: 609 pred_clean_logit 0.9999547004699707
prompt generate:  jeep  	labels:  [[609]]
decoder:  [49406, 11286, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([717], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([609], device='cuda:0') tensor(6.0826e-14, device='cuda:0')
L1: [7121.711]	L2: [31.151497]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 911 pred_label: 574 pred_clean_logit 0.0004941265215165913
prompt generate:  wool  	labels:  [[574]]
decoder:  [49406, 13283, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([936], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([911], device='cuda:0') tensor(3.6205e-22, device='cuda:0')
L1: [4699.298]	L2: [17.146534]	Linf: [0.59607846]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 497 pred_label: 497 pred_clean_logit 0.9978299736976624
prompt generate:  church  	labels:  [[497]]
decoder:  [49406, 2735, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([663], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([497], device='cuda:0') tensor(2.4719e-11, device='cuda:0')
L1: [8765.844]	L2: [34.412987]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=45.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.0% (timestep 4)
Min contribution: 8.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 346 pred_label: 730 pred_clean_logit 0.035400208085775375
prompt generate:  water buffalo  	labels:  [[730]]
decoder:  [49406, 1573, 8054, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([471], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([346], device='cuda:0') tensor(4.6751e-14, device='cuda:0')
L1: [12549.675]	L2: [43.24525]	Linf: [0.61960787]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=56.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.6% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 825 pred_label: 825 pred_clean_logit 0.972687304019928
prompt generate:  stone wall  	labels:  [[825]]
decoder:  [49406, 2441, 2569, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([500], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([825], device='cuda:0') tensor(5.7060e-14, device='cuda:0')
L1: [9189.443]	L2: [33.14183]	Linf: [0.6509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=25.0%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=58.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.6% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 738 pred_label: 738 pred_clean_logit 0.9999055862426758
prompt generate:  pot  	labels:  [[738]]
decoder:  [49406, 5168, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([937], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([738], device='cuda:0') tensor(1.4641e-20, device='cuda:0')
L1: [11293.332]	L2: [45.718433]	Linf: [0.8980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000003, Std=0.000002, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 839 pred_label: 839 pred_clean_logit 0.9979560375213623
prompt generate:  suspension bridge  	labels:  [[839]]
decoder:  [49406, 15417, 2465, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([670], device='cuda:0') tensor(0.9840, device='cuda:0')
after_true: tensor([839], device='cuda:0') tensor(9.6164e-16, device='cuda:0')
L1: [12485.295]	L2: [44.027157]	Linf: [0.72156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.9% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 497 pred_label: 818 pred_clean_logit 0.04767782986164093
prompt generate:  church  	labels:  [[818]]
decoder:  [49406, 2735, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([832], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([497], device='cuda:0') tensor(2.2692e-21, device='cuda:0')
L1: [3267.894]	L2: [14.076041]	Linf: [0.47450984]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 805 pred_label: 768 pred_clean_logit 0.004618999548256397
prompt generate:  soccer ball  	labels:  [[768]]
decoder:  [49406, 4233, 1069, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([768], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([805], device='cuda:0') tensor(8.4310e-18, device='cuda:0')
L1: [10320.263]	L2: [40.377705]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=47.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.7% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 326 pred_label: 326 pred_clean_logit 0.9957454800605774
prompt generate:  lycaenid  	labels:  [[326]]
decoder:  [49406, 1251, 772, 524, 1014, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([36], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([326], device='cuda:0') tensor(7.9050e-16, device='cuda:0')
L1: [7218.9536]	L2: [32.745956]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.4%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=60.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.1% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 703 pred_label: 706 pred_clean_logit 0.001056979293935001
prompt generate:  park bench  	labels:  [[706]]
decoder:  [49406, 1452, 8771, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([706], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([703], device='cuda:0') tensor(5.3736e-21, device='cuda:0')
L1: [9385.61]	L2: [35.289787]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 533 pred_label: 533 pred_clean_logit 0.9999505281448364
prompt generate:  dishrag  	labels:  [[533]]
decoder:  [49406, 11039, 20687, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([824], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([533], device='cuda:0') tensor(2.6113e-15, device='cuda:0')
L1: [9826.912]	L2: [41.736507]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.8%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.0%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=21.4%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 847 pred_label: 847 pred_clean_logit 0.9997543692588806
prompt generate:  tank  	labels:  [[847]]
decoder:  [49406, 6172, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([586], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([847], device='cuda:0') tensor(5.4224e-15, device='cuda:0')
L1: [9667.052]	L2: [34.16551]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=11.4%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=25.7%
Timestep  4: Avg Loss=0.000017, Std=0.000006, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 311 pred_label: 311 pred_clean_logit 0.9828616380691528
prompt generate:  grasshopper  	labels:  [[311]]
decoder:  [49406, 48894, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([312], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([311], device='cuda:0') tensor(6.0906e-13, device='cuda:0')
L1: [7794.533]	L2: [30.935402]	Linf: [0.69019604]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=58.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.4% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 923 pred_label: 124 pred_clean_logit 0.11381392180919647
prompt generate:  plate  	labels:  [[124]]
decoder:  [49406, 5135, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([947], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([923], device='cuda:0') tensor(1.7098e-20, device='cuda:0')
L1: [10103.07]	L2: [38.66334]	Linf: [0.8745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.7%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 948 pred_label: 948 pred_clean_logit 0.6165761351585388
prompt generate:  Granny Smith  	labels:  [[948]]
decoder:  [49406, 22710, 2915, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([988], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([948], device='cuda:0') tensor(7.2765e-23, device='cuda:0')
L1: [17769.744]	L2: [59.633938]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=28.3%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 385 pred_label: 101 pred_clean_logit 0.1479695737361908
prompt generate:  Indian elephant  	labels:  [[101]]
decoder:  [49406, 3606, 10299, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([349], device='cuda:0') tensor(0.9810, device='cuda:0')
after_true: tensor([385], device='cuda:0') tensor(3.7154e-18, device='cuda:0')
L1: [11373.408]	L2: [43.393715]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 915 pred_label: 915 pred_clean_logit 1.0
prompt generate:  yurt  	labels:  [[915]]
decoder:  [49406, 88, 24309, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([915], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([915], device='cuda:0') tensor(1., device='cuda:0')
L1: [6159.4087]	L2: [24.584206]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.8%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 768 pred_label: 768 pred_clean_logit 0.7848653793334961
prompt generate:  rugby ball  	labels:  [[768]]
decoder:  [49406, 4964, 1069, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([981], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([768], device='cuda:0') tensor(1.5473e-10, device='cuda:0')
L1: [8004.5874]	L2: [30.429499]	Linf: [0.91764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.3%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=48.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.9% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 687 pred_label: 687 pred_clean_logit 0.999998927116394
prompt generate:  organ  	labels:  [[687]]
decoder:  [49406, 13213, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([687], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([687], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [8518.188]	L2: [33.196056]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.5%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.8%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=22.6%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=46.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.2% (timestep 4)
Min contribution: 6.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 979 pred_label: 979 pred_clean_logit 0.992219090461731
prompt generate:  valley  	labels:  [[979]]
decoder:  [49406, 3136, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([975], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([979], device='cuda:0') tensor(3.3019e-15, device='cuda:0')
L1: [10551.118]	L2: [38.79744]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 884 pred_label: 884 pred_clean_logit 0.9838377833366394
prompt generate:  vault  	labels:  [[884]]
decoder:  [49406, 15240, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([588], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([884], device='cuda:0') tensor(1.2270e-17, device='cuda:0')
L1: [5792.4077]	L2: [20.50302]	Linf: [0.5019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 572 pred_label: 478 pred_clean_logit 0.00017374652088619769
prompt generate:  goblet  	labels:  [[478]]
decoder:  [49406, 29559, 1094, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([478], device='cuda:0') tensor(0.9224, device='cuda:0')
after_true: tensor([572], device='cuda:0') tensor(2.2472e-07, device='cuda:0')
L1: [443.9412]	L2: [8.104206]	Linf: [0.45098037]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=19.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=24.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=20.8%
Timestep  4: Avg Loss=0.000002, Std=0.000000, Contribution=30.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 30.3% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 805 pred_label: 805 pred_clean_logit 0.9868813753128052
prompt generate:  soccer ball  	labels:  [[805]]
decoder:  [49406, 4233, 1069, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([843], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([805], device='cuda:0') tensor(5.7874e-20, device='cuda:0')
L1: [9706.254]	L2: [35.230377]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 663 pred_label: 663 pred_clean_logit 0.9325855374336243
prompt generate:  monastery  	labels:  [[663]]
decoder:  [49406, 21850, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([497], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([663], device='cuda:0') tensor(9.3799e-14, device='cuda:0')
L1: [9347.216]	L2: [37.58073]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=48.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.5% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 779 pred_label: 779 pred_clean_logit 0.9999645948410034
prompt generate:  school bus  	labels:  [[779]]
decoder:  [49406, 1228, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([779], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([779], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5354.471]	L2: [22.322432]	Linf: [0.6117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.0%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=25.4%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 959 pred_label: 959 pred_clean_logit 0.9839047789573669
prompt generate:  carbonara  	labels:  [[959]]
decoder:  [49406, 14038, 3340, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([659], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([959], device='cuda:0') tensor(3.6450e-16, device='cuda:0')
L1: [11780.957]	L2: [48.17204]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 908 pred_label: 475 pred_clean_logit 0.000902454077731818
prompt generate:  wing  	labels:  [[475]]
decoder:  [49406, 1340, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([475], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([908], device='cuda:0') tensor(8.2147e-15, device='cuda:0')
L1: [3112.498]	L2: [11.130899]	Linf: [0.2588235]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=56.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.5% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 599 pred_label: 599 pred_clean_logit 0.9998639822006226
prompt generate:  honeycomb  	labels:  [[599]]
decoder:  [49406, 48583, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([599], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([599], device='cuda:0') tensor(0.9998, device='cuda:0')
L1: [3035.157]	L2: [11.322122]	Linf: [0.3529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.1%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 132 pred_label: 132 pred_clean_logit 0.6876798868179321
prompt generate:  American egret  	labels:  [[132]]
decoder:  [49406, 2151, 42002, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([144], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([132], device='cuda:0') tensor(2.8494e-23, device='cuda:0')
L1: [6799.008]	L2: [29.462387]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 895 pred_label: 895 pred_clean_logit 0.5041800737380981
prompt generate:  warplane  	labels:  [[895]]
decoder:  [49406, 984, 5363, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([744], device='cuda:0') tensor(0.9715, device='cuda:0')
after_true: tensor([895], device='cuda:0') tensor(1.9223e-09, device='cuda:0')
L1: [3336.8232]	L2: [15.080975]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 421 pred_label: 904 pred_clean_logit 0.028392525389790535
prompt generate:  bannister  	labels:  [[904]]
decoder:  [49406, 1159, 36640, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([900], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([421], device='cuda:0') tensor(2.2120e-21, device='cuda:0')
L1: [3843.9807]	L2: [15.990371]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 979 pred_label: 979 pred_clean_logit 0.2783050835132599
prompt generate:  valley  	labels:  [[979]]
decoder:  [49406, 3136, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([298], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([979], device='cuda:0') tensor(1.5589e-18, device='cuda:0')
L1: [11268.922]	L2: [38.502834]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000017, Std=0.000004, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 327 pred_label: 327 pred_clean_logit 0.9997052550315857
prompt generate:  starfish  	labels:  [[327]]
decoder:  [49406, 44283, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([112], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([327], device='cuda:0') tensor(6.8905e-20, device='cuda:0')
L1: [6245.581]	L2: [26.52367]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 696 pred_label: 420 pred_clean_logit 0.3145133852958679
prompt generate:  paintbrush  	labels:  [[420]]
decoder:  [49406, 7948, 8594, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([420], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([696], device='cuda:0') tensor(3.2567e-38, device='cuda:0')
L1: [4889.7964]	L2: [19.335814]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 675 pred_label: 675 pred_clean_logit 0.9976876974105835
prompt generate:  moving van  	labels:  [[675]]
decoder:  [49406, 3584, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([757], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([675], device='cuda:0') tensor(1.6028e-16, device='cuda:0')
L1: [6271.745]	L2: [25.561954]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 637 pred_label: 672 pred_clean_logit 0.030851498246192932
prompt generate:  mailbox  	labels:  [[672]]
decoder:  [49406, 31482, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([704], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([637], device='cuda:0') tensor(4.7594e-18, device='cuda:0')
L1: [9995.718]	L2: [40.618584]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000018, Std=0.000004, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 789 pred_label: 789 pred_clean_logit 0.9862051606178284
prompt generate:  shoji  	labels:  [[789]]
decoder:  [49406, 719, 2697, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([918], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([789], device='cuda:0') tensor(7.7204e-23, device='cuda:0')
L1: [6705.33]	L2: [24.541327]	Linf: [0.42745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=45.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.8% (timestep 4)
Min contribution: 5.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 741 pred_label: 492 pred_clean_logit 0.01284546684473753
prompt generate:  prayer rug  	labels:  [[492]]
decoder:  [49406, 6583, 19220, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([496], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([741], device='cuda:0') tensor(1.1960e-23, device='cuda:0')
L1: [18198.14]	L2: [60.84258]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=54.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.5% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 821 pred_label: 821 pred_clean_logit 0.9921053647994995
prompt generate:  steel arch bridge  	labels:  [[821]]
decoder:  [49406, 4726, 8557, 2465, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([701], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([821], device='cuda:0') tensor(1.8079e-15, device='cuda:0')
L1: [4274.8984]	L2: [21.500256]	Linf: [0.9137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 920 pred_label: 844 pred_clean_logit 0.025535937398672104
prompt generate:  traffic light  	labels:  [[844]]
decoder:  [49406, 3399, 1395, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([844], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([920], device='cuda:0') tensor(6.5879e-08, device='cuda:0')
L1: [3484.792]	L2: [16.03427]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=10.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=15.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=42.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.8% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 705 pred_label: 705 pred_clean_logit 0.6326198577880859
prompt generate:  passenger car  	labels:  [[705]]
decoder:  [49406, 12311, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([757], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([705], device='cuda:0') tensor(5.0917e-15, device='cuda:0')
L1: [5513.8945]	L2: [25.704853]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=49.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.3% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 779 pred_label: 779 pred_clean_logit 0.999976396560669
prompt generate:  school bus  	labels:  [[779]]
decoder:  [49406, 1228, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([874], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([779], device='cuda:0') tensor(1.5138e-08, device='cuda:0')
L1: [5966.5015]	L2: [22.654942]	Linf: [0.49803922]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 861 pred_label: 861 pred_clean_logit 0.9999635219573975
prompt generate:  toilet seat  	labels:  [[861]]
decoder:  [49406, 11071, 4922, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([876], device='cuda:0') tensor(0.9497, device='cuda:0')
after_true: tensor([861], device='cuda:0') tensor(1.2898e-11, device='cuda:0')
L1: [4968.161]	L2: [19.201748]	Linf: [0.5529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=10.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=12.5%
Timestep  2: Avg Loss=0.000002, Std=0.000002, Contribution=15.5%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=21.4%
Timestep  4: Avg Loss=0.000005, Std=0.000004, Contribution=39.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 39.8% (timestep 4)
Min contribution: 10.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 511 pred_label: 817 pred_clean_logit 0.22803382575511932
prompt generate:  convertible  	labels:  [[817]]
decoder:  [49406, 19608, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([751], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([511], device='cuda:0') tensor(9.3838e-14, device='cuda:0')
L1: [4322.0547]	L2: [24.906128]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.4%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=47.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.2% (timestep 4)
Min contribution: 7.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 150 pred_label: 150 pred_clean_logit 0.9671045541763306
prompt generate:  sea lion  	labels:  [[150]]
decoder:  [49406, 2102, 5567, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([63], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([150], device='cuda:0') tensor(9.7694e-20, device='cuda:0')
L1: [5630.3604]	L2: [23.445162]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=58.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.6% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 603 pred_label: 603 pred_clean_logit 0.9999992847442627
prompt generate:  horse cart  	labels:  [[603]]
decoder:  [49406, 4558, 13065, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([603], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([603], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7020.498]	L2: [28.718145]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.8%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=13.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.1%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 954 pred_label: 954 pred_clean_logit 0.6939844489097595
prompt generate:  banana  	labels:  [[954]]
decoder:  [49406, 8922, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([618], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([954], device='cuda:0') tensor(4.4043e-18, device='cuda:0')
L1: [5985.561]	L2: [28.918531]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 820 pred_label: 820 pred_clean_logit 0.9999632835388184
prompt generate:  steam locomotive  	labels:  [[820]]
decoder:  [49406, 6972, 30439, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([895], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([820], device='cuda:0') tensor(7.1778e-14, device='cuda:0')
L1: [4354.216]	L2: [19.788515]	Linf: [0.61960787]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 293 pred_label: 293 pred_clean_logit 0.9996901750564575
prompt generate:  cheetah  	labels:  [[293]]
decoder:  [49406, 27431, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([290], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([293], device='cuda:0') tensor(1.0248e-09, device='cuda:0')
L1: [14642.668]	L2: [50.717354]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 707 pred_label: 707 pred_clean_logit 0.9771887063980103
prompt generate:  pay-phone  	labels:  [[707]]
decoder:  [49406, 3345, 268, 1951, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([480], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([707], device='cuda:0') tensor(5.0962e-12, device='cuda:0')
L1: [6638.934]	L2: [26.826302]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=44.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.4% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 630 pred_label: 630 pred_clean_logit 0.9936056137084961
prompt generate:  Loafer  	labels:  [[630]]
decoder:  [49406, 26467, 528, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([413], device='cuda:0') tensor(0.9653, device='cuda:0')
after_true: tensor([630], device='cuda:0') tensor(6.1004e-13, device='cuda:0')
L1: [4647.0864]	L2: [17.55483]	Linf: [0.48235297]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=57.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.9% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 468 pred_label: 656 pred_clean_logit 0.48606282472610474
prompt generate:  cab  	labels:  [[656]]
decoder:  [49406, 11912, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([656], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([468], device='cuda:0') tensor(2.6392e-16, device='cuda:0')
L1: [9994.443]	L2: [39.14292]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=45.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.5% (timestep 4)
Min contribution: 6.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 331 pred_label: 331 pred_clean_logit 0.9772195219993591
prompt generate:  hare  	labels:  [[331]]
decoder:  [49406, 18464, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([216], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([331], device='cuda:0') tensor(8.6557e-19, device='cuda:0')
L1: [4822.698]	L2: [17.88143]	Linf: [0.4627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 99 pred_label: 130 pred_clean_logit 0.08163087069988251
prompt generate:  goose  	labels:  [[130]]
decoder:  [49406, 13822, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([130], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([99], device='cuda:0') tensor(5.1656e-18, device='cuda:0')
L1: [9168.844]	L2: [34.85187]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 736 pred_label: 642 pred_clean_logit 0.005423789843916893
prompt generate:  pool table  	labels:  [[642]]
decoder:  [49406, 2831, 2175, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([642], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([736], device='cuda:0') tensor(9.4847e-28, device='cuda:0')
L1: [7232.4395]	L2: [31.143562]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 514 pred_label: 514 pred_clean_logit 0.867717981338501
prompt generate:  cowboy boot  	labels:  [[514]]
decoder:  [49406, 13657, 8087, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([792], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([514], device='cuda:0') tensor(1.1968e-23, device='cuda:0')
L1: [5066.942]	L2: [19.491999]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 652 pred_label: 819 pred_clean_logit 0.13466507196426392
prompt generate:  military uniform  	labels:  [[819]]
decoder:  [49406, 4323, 11075, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([627], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([652], device='cuda:0') tensor(3.2133e-17, device='cuda:0')
L1: [5349.867]	L2: [25.63669]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 972 pred_label: 972 pred_clean_logit 0.933601975440979
prompt generate:  cliff  	labels:  [[972]]
decoder:  [49406, 10625, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([483], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([972], device='cuda:0') tensor(2.1058e-08, device='cuda:0')
L1: [4819.6157]	L2: [24.97184]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=60.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.7% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 391 pred_label: 391 pred_clean_logit 0.7406815886497498
prompt generate:  coho  	labels:  [[391]]
decoder:  [49406, 622, 2971, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([670], device='cuda:0') tensor(0.9956, device='cuda:0')
after_true: tensor([391], device='cuda:0') tensor(2.2971e-16, device='cuda:0')
L1: [3671.765]	L2: [14.247519]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=13.5%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=26.8%
Timestep  4: Avg Loss=0.000018, Std=0.000005, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 847 pred_label: 847 pred_clean_logit 0.5072548389434814
prompt generate:  tank  	labels:  [[847]]
decoder:  [49406, 6172, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([575], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([847], device='cuda:0') tensor(7.8701e-26, device='cuda:0')
L1: [10983.696]	L2: [39.614273]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.8%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 595 pred_label: 595 pred_clean_logit 0.8919341564178467
prompt generate:  harvester  	labels:  [[595]]
decoder:  [49406, 6405, 881, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([428], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([595], device='cuda:0') tensor(2.0292e-22, device='cuda:0')
L1: [6333.784]	L2: [28.523146]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 132 pred_label: 132 pred_clean_logit 0.7530587911605835
prompt generate:  American egret  	labels:  [[132]]
decoder:  [49406, 2151, 42002, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([140], device='cuda:0') tensor(0.9995, device='cuda:0')
after_true: tensor([132], device='cuda:0') tensor(9.3359e-12, device='cuda:0')
L1: [5850.3413]	L2: [22.493715]	Linf: [0.6862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 492 pred_label: 492 pred_clean_logit 0.9999997615814209
prompt generate:  chest  	labels:  [[492]]
decoder:  [49406, 10563, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([492], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([492], device='cuda:0') tensor(1., device='cuda:0')
L1: [9995.319]	L2: [38.524567]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=7.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.0%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=15.0%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=22.8%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=45.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.0% (timestep 4)
Min contribution: 7.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 917 pred_label: 921 pred_clean_logit 0.27635592222213745
prompt generate:  comic book  	labels:  [[921]]
decoder:  [49406, 4962, 1116, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([611], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([917], device='cuda:0') tensor(1.4915e-18, device='cuda:0')
L1: [18795.172]	L2: [69.3695]	Linf: [0.9490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=27.8%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 81 pred_label: 81 pred_clean_logit 0.9998487234115601
prompt generate:  ptarmigan  	labels:  [[81]]
decoder:  [49406, 79, 2002, 714, 1670, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([82], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([81], device='cuda:0') tensor(2.2813e-20, device='cuda:0')
L1: [15106.061]	L2: [52.751472]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=56.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.9% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 763 pred_label: 763 pred_clean_logit 0.9999973773956299
prompt generate:  revolver  	labels:  [[763]]
decoder:  [49406, 38747, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([764], device='cuda:0') tensor(0.9279, device='cuda:0')
after_true: tensor([763], device='cuda:0') tensor(0.0002, device='cuda:0')
L1: [4061.0273]	L2: [18.135456]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 50 pred_label: 50 pred_clean_logit 0.9881885647773743
prompt generate:  American alligator  	labels:  [[50]]
decoder:  [49406, 2151, 28574, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([49], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([50], device='cuda:0') tensor(2.7643e-12, device='cuda:0')
L1: [14072.797]	L2: [47.320152]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=56.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.5% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 970 pred_label: 970 pred_clean_logit 0.48951083421707153
prompt generate:  alp  	labels:  [[970]]
decoder:  [49406, 39342, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([979], device='cuda:0') tensor(0.9992, device='cuda:0')
after_true: tensor([970], device='cuda:0') tensor(1.8426e-06, device='cuda:0')
L1: [3023.243]	L2: [12.914481]	Linf: [0.42745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=59.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.2% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 113 pred_label: 113 pred_clean_logit 0.9999996423721313
prompt generate:  snail  	labels:  [[113]]
decoder:  [49406, 23132, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([113], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([113], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6719.675]	L2: [26.782333]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=25.3%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=48.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.1% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 973 pred_label: 33 pred_clean_logit 0.015518898144364357
prompt generate:  coral reef  	labels:  [[33]]
decoder:  [49406, 12054, 15624, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([299], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([973], device='cuda:0') tensor(2.2101e-19, device='cuda:0')
L1: [7209.2036]	L2: [25.186735]	Linf: [0.40392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=54.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.5% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 850 pred_label: 850 pred_clean_logit 0.9103261232376099
prompt generate:  teddy  	labels:  [[850]]
decoder:  [49406, 11798, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([154], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([850], device='cuda:0') tensor(9.7942e-22, device='cuda:0')
L1: [5457.3213]	L2: [20.220861]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000006, Std=0.000002, Contribution=12.4%
Timestep  3: Avg Loss=0.000012, Std=0.000005, Contribution=26.8%
Timestep  4: Avg Loss=0.000025, Std=0.000008, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 1 pred_label: 1 pred_clean_logit 0.9878992438316345
prompt generate:  goldfish  	labels:  [[1]]
decoder:  [49406, 40293, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([33], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([1], device='cuda:0') tensor(1.8433e-17, device='cuda:0')
L1: [9428.389]	L2: [33.913887]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=55.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.8% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 978 pred_label: 978 pred_clean_logit 0.8638083338737488
prompt generate:  seashore  	labels:  [[978]]
decoder:  [49406, 567, 31194, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([975], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([978], device='cuda:0') tensor(1.1713e-11, device='cuda:0')
L1: [3795.384]	L2: [18.784143]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.9%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 132 pred_label: 132 pred_clean_logit 0.9952736496925354
prompt generate:  American egret  	labels:  [[132]]
decoder:  [49406, 2151, 42002, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([131], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([132], device='cuda:0') tensor(1.6662e-09, device='cuda:0')
L1: [4186.9844]	L2: [17.76908]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=22.7%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 335 pred_label: 335 pred_clean_logit 0.9996229410171509
prompt generate:  fox squirrel  	labels:  [[335]]
decoder:  [49406, 3240, 14004, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([225], device='cuda:0') tensor(0.9280, device='cuda:0')
after_true: tensor([335], device='cuda:0') tensor(5.2386e-09, device='cuda:0')
L1: [3857.5845]	L2: [14.654504]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 143 pred_label: 143 pred_clean_logit 0.9998998641967773
prompt generate:  oystercatcher  	labels:  [[143]]
decoder:  [49406, 40545, 15965, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([143], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([143], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3008.549]	L2: [13.144663]	Linf: [0.61176467]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.2%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.7%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=48.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.5% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 921 pred_label: 921 pred_clean_logit 0.9422560930252075
prompt generate:  book jacket  	labels:  [[921]]
decoder:  [49406, 1116, 6164, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([709], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([921], device='cuda:0') tensor(1.0670e-27, device='cuda:0')
L1: [8281.243]	L2: [33.636925]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 562 pred_label: 562 pred_clean_logit 0.999990701675415
prompt generate:  fountain  	labels:  [[562]]
decoder:  [49406, 13405, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([819], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([562], device='cuda:0') tensor(1.5264e-19, device='cuda:0')
L1: [11201.683]	L2: [46.75136]	Linf: [0.91764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 321 pred_label: 321 pred_clean_logit 0.9999843835830688
prompt generate:  admiral  	labels:  [[321]]
decoder:  [49406, 21013, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([325], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([321], device='cuda:0') tensor(3.3787e-10, device='cuda:0')
L1: [7194.7964]	L2: [29.048386]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 879 pred_label: 879 pred_clean_logit 1.0
prompt generate:  umbrella  	labels:  [[879]]
decoder:  [49406, 17143, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
L1: [3870.2036]	L2: [15.954813]	Linf: [0.654902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.5%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.0%
Timestep  4: Avg Loss=0.000002, Std=0.000000, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 303 pred_label: 303 pred_clean_logit 0.998391330242157
prompt generate:  long-horned beetle  	labels:  [[303]]
decoder:  [49406, 1538, 268, 34526, 16534, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([302], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([303], device='cuda:0') tensor(8.2020e-12, device='cuda:0')
L1: [5248.886]	L2: [20.335026]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 355 pred_label: 355 pred_clean_logit 0.9999997615814209
prompt generate:  llama  	labels:  [[355]]
decoder:  [49406, 36679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([348], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([355], device='cuda:0') tensor(4.1774e-21, device='cuda:0')
L1: [6529.3774]	L2: [22.978409]	Linf: [0.5137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.7%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 436 pred_label: 734 pred_clean_logit 0.20202402770519257
prompt generate:  beach wagon  	labels:  [[734]]
decoder:  [49406, 2117, 13260, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([734], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([436], device='cuda:0') tensor(9.7671e-19, device='cuda:0')
L1: [7985.1104]	L2: [31.390728]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=7.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=45.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.0% (timestep 4)
Min contribution: 7.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 99 pred_label: 99 pred_clean_logit 0.6791041493415833
prompt generate:  goose  	labels:  [[99]]
decoder:  [49406, 13822, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([99], device='cuda:0') tensor(4.6119e-16, device='cuda:0')
L1: [9076.3955]	L2: [32.936348]	Linf: [0.61960787]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 919 pred_label: 919 pred_clean_logit 0.9829590320587158
prompt generate:  street sign  	labels:  [[919]]
decoder:  [49406, 2012, 2292, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([491], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([919], device='cuda:0') tensor(8.3273e-10, device='cuda:0')
L1: [7295.287]	L2: [28.940472]	Linf: [0.95686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 283 pred_label: 283 pred_clean_logit 0.999998927116394
prompt generate:  Persian cat  	labels:  [[283]]
decoder:  [49406, 19859, 2368, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([283], device='cuda:0') tensor(0.9753, device='cuda:0')
after_true: tensor([283], device='cuda:0') tensor(0.9753, device='cuda:0')
L1: [6882.247]	L2: [23.502295]	Linf: [0.3647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.9%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 541 pred_label: 541 pred_clean_logit 0.9958629608154297
prompt generate:  drum  	labels:  [[541]]
decoder:  [49406, 8698, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([401], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([541], device='cuda:0') tensor(3.8255e-43, device='cuda:0')
L1: [14464.262]	L2: [53.077896]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=27.0%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 317 pred_label: 317 pred_clean_logit 0.9621515870094299
prompt generate:  leafhopper  	labels:  [[317]]
decoder:  [49406, 9377, 21748, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([312], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([317], device='cuda:0') tensor(4.6540e-18, device='cuda:0')
L1: [7282.0405]	L2: [26.7819]	Linf: [0.54901963]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=57.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.9% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 754 pred_label: 754 pred_clean_logit 0.9735011458396912
prompt generate:  radio  	labels:  [[754]]
decoder:  [49406, 2638, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([662], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([754], device='cuda:0') tensor(7.0852e-13, device='cuda:0')
L1: [10122.307]	L2: [38.40409]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 404 pred_label: 404 pred_clean_logit 0.7148678302764893
prompt generate:  airliner  	labels:  [[404]]
decoder:  [49406, 1281, 11618, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([657], device='cuda:0') tensor(0.9737, device='cuda:0')
after_true: tensor([404], device='cuda:0') tensor(3.4526e-14, device='cuda:0')
L1: [5573.]	L2: [25.159822]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 537 pred_label: 537 pred_clean_logit 0.9617815017700195
prompt generate:  dogsled  	labels:  [[537]]
decoder:  [49406, 4326, 28438, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([830], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([537], device='cuda:0') tensor(7.3353e-23, device='cuda:0')
L1: [9076.656]	L2: [33.951954]	Linf: [0.6862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=13.4%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=27.5%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 830 pred_label: 830 pred_clean_logit 0.9945694804191589
prompt generate:  stretcher  	labels:  [[830]]
decoder:  [49406, 12265, 3466, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([424], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([830], device='cuda:0') tensor(3.4373e-21, device='cuda:0')
L1: [10852.629]	L2: [42.21241]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000009, Std=0.000002, Contribution=26.9%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 308 pred_label: 308 pred_clean_logit 0.9999985694885254
prompt generate:  fly  	labels:  [[308]]
decoder:  [49406, 3228, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([308], device='cuda:0') tensor(0.9972, device='cuda:0')
after_true: tensor([308], device='cuda:0') tensor(0.9972, device='cuda:0')
L1: [6219.376]	L2: [23.668499]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 931 pred_label: 931 pred_clean_logit 0.9999984502792358
prompt generate:  bagel  	labels:  [[931]]
decoder:  [49406, 28777, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([932], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([931], device='cuda:0') tensor(1.2635e-16, device='cuda:0')
L1: [7283.915]	L2: [26.730375]	Linf: [0.62352943]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 489 pred_label: 489 pred_clean_logit 0.4623035490512848
prompt generate:  chainlink fence  	labels:  [[489]]
decoder:  [49406, 13898, 2468, 12679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([408], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([489], device='cuda:0') tensor(1.4195e-16, device='cuda:0')
L1: [8286.303]	L2: [38.33533]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 406 pred_label: 884 pred_clean_logit 0.3160266876220703
prompt generate:  altar  	labels:  [[884]]
decoder:  [49406, 16385, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([619], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([406], device='cuda:0') tensor(7.9008e-22, device='cuda:0')
L1: [8365.988]	L2: [30.700579]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000018, Std=0.000005, Contribution=58.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.9% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 597 pred_label: 597 pred_clean_logit 0.5692209601402283
prompt generate:  holster  	labels:  [[597]]
decoder:  [49406, 1187, 881, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([491], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([597], device='cuda:0') tensor(7.9950e-31, device='cuda:0')
L1: [10037.944]	L2: [38.701275]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 919 pred_label: 919 pred_clean_logit 1.0
prompt generate:  street sign  	labels:  [[919]]
decoder:  [49406, 2012, 2292, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([919], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([919], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6649.342]	L2: [27.932531]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.5%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=47.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.0% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 799 pred_label: 799 pred_clean_logit 0.7673892378807068
prompt generate:  sliding door  	labels:  [[799]]
decoder:  [49406, 21468, 2489, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([905], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([799], device='cuda:0') tensor(6.9725e-12, device='cuda:0')
L1: [6378.706]	L2: [25.199644]	Linf: [0.5490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 944 pred_label: 944 pred_clean_logit 0.979377269744873
prompt generate:  artichoke  	labels:  [[944]]
decoder:  [49406, 39647, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([936], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([944], device='cuda:0') tensor(1.7243e-14, device='cuda:0')
L1: [11645.9375]	L2: [41.91448]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 97 pred_label: 97 pred_clean_logit 0.9999605417251587
prompt generate:  drake  	labels:  [[97]]
decoder:  [49406, 8958, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([18], device='cuda:0') tensor(0.9990, device='cuda:0')
after_true: tensor([97], device='cuda:0') tensor(0.0006, device='cuda:0')
L1: [7395.4043]	L2: [27.00548]	Linf: [0.60392153]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 959 pred_label: 937 pred_clean_logit 0.0006518891896121204
prompt generate:  carbonara  	labels:  [[937]]
decoder:  [49406, 14038, 3340, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([937], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([959], device='cuda:0') tensor(6.3378e-37, device='cuda:0')
L1: [8252.956]	L2: [30.993587]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=56.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.9% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 541 pred_label: 859 pred_clean_logit 0.08317650109529495
prompt generate:  drum  	labels:  [[859]]
decoder:  [49406, 8698, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([859], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([541], device='cuda:0') tensor(1.2928e-38, device='cuda:0')
L1: [9934.506]	L2: [40.560947]	Linf: [0.91764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 900 pred_label: 900 pred_clean_logit 0.9999905824661255
prompt generate:  water tower  	labels:  [[900]]
decoder:  [49406, 1573, 4730, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([602], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([900], device='cuda:0') tensor(2.4238e-15, device='cuda:0')
L1: [6202.541]	L2: [26.813309]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 865 pred_label: 865 pred_clean_logit 0.9740009903907776
prompt generate:  toyshop  	labels:  [[865]]
decoder:  [49406, 14387, 1557, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([859], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([865], device='cuda:0') tensor(3.0512e-35, device='cuda:0')
L1: [12538.703]	L2: [51.01249]	Linf: [0.9490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=15.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=47.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.4% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 33 pred_label: 33 pred_clean_logit 0.9927560687065125
prompt generate:  loggerhead  	labels:  [[33]]
decoder:  [49406, 549, 12367, 1375, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([34], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([33], device='cuda:0') tensor(3.7183e-10, device='cuda:0')
L1: [5270.3726]	L2: [19.381636]	Linf: [0.41960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=58.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.2% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 146 pred_label: 146 pred_clean_logit 0.9954948425292969
prompt generate:  albatross  	labels:  [[146]]
decoder:  [49406, 42797, 2158, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([143], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([146], device='cuda:0') tensor(3.3038e-10, device='cuda:0')
L1: [7204.9414]	L2: [28.896486]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=48.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.4% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 661 pred_label: 609 pred_clean_logit 0.4493834376335144
prompt generate:  Model T  	labels:  [[609]]
decoder:  [49406, 2863, 339, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([609], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([661], device='cuda:0') tensor(5.8225e-26, device='cuda:0')
L1: [9461.953]	L2: [36.529114]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=49.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.3% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 995 pred_label: 954 pred_clean_logit 0.003298370400443673
prompt generate:  earthstar  	labels:  [[954]]
decoder:  [49406, 5184, 1565, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([954], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([995], device='cuda:0') tensor(3.0265e-33, device='cuda:0')
L1: [9597.9375]	L2: [34.788616]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 32 pred_label: 32 pred_clean_logit 0.9967165589332581
prompt generate:  tailed frog  	labels:  [[32]]
decoder:  [49406, 20626, 11438, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([30], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([32], device='cuda:0') tensor(3.1575e-10, device='cuda:0')
L1: [5368.542]	L2: [28.103031]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.2%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 718 pred_label: 718 pred_clean_logit 0.9997300505638123
prompt generate:  pier  	labels:  [[718]]
decoder:  [49406, 11348, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([525], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([718], device='cuda:0') tensor(1.2793e-10, device='cuda:0')
L1: [3662.361]	L2: [18.720129]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 107 pred_label: 107 pred_clean_logit 0.887060821056366
prompt generate:  jellyfish  	labels:  [[107]]
decoder:  [49406, 30988, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([883], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([107], device='cuda:0') tensor(2.1338e-11, device='cuda:0')
L1: [6771.0195]	L2: [23.891157]	Linf: [0.4745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=27.1%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 679 pred_label: 679 pred_clean_logit 0.9999774694442749
prompt generate:  necklace  	labels:  [[679]]
decoder:  [49406, 7385, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([679], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([679], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [4875.2466]	L2: [22.313705]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.3%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 814 pred_label: 814 pred_clean_logit 0.9997606873512268
prompt generate:  speedboat  	labels:  [[814]]
decoder:  [49406, 6860, 4440, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([466], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([814], device='cuda:0') tensor(1.8599e-09, device='cuda:0')
L1: [3226.8584]	L2: [19.073132]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=12.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=13.0%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=15.3%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=20.6%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=39.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 39.0% (timestep 4)
Min contribution: 12.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 526 pred_label: 406 pred_clean_logit 0.0047531211748719215
prompt generate:  desk  	labels:  [[406]]
decoder:  [49406, 6550, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([406], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([526], device='cuda:0') tensor(9.2741e-23, device='cuda:0')
L1: [8442.29]	L2: [33.89855]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 1 pred_label: 876 pred_clean_logit 0.00022884794452693313
prompt generate:  goldfish  	labels:  [[876]]
decoder:  [49406, 40293, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([876], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([1], device='cuda:0') tensor(3.7684e-29, device='cuda:0')
L1: [5348.569]	L2: [20.565142]	Linf: [0.5529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 873 pred_label: 873 pred_clean_logit 0.9977003931999207
prompt generate:  triumphal arch  	labels:  [[873]]
decoder:  [49406, 14782, 1037, 8708, 8557, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([812], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([873], device='cuda:0') tensor(1.3983e-17, device='cuda:0')
L1: [6843.89]	L2: [30.520258]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 338 pred_label: 338 pred_clean_logit 0.9999836683273315
prompt generate:  guinea pig  	labels:  [[338]]
decoder:  [49406, 18537, 9619, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([338], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([338], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [4738.734]	L2: [18.050722]	Linf: [0.56078434]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.0%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.0%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=45.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.6% (timestep 4)
Min contribution: 6.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 718 pred_label: 718 pred_clean_logit 0.9980873465538025
prompt generate:  pier  	labels:  [[718]]
decoder:  [49406, 11348, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([525], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([718], device='cuda:0') tensor(9.0432e-19, device='cuda:0')
L1: [9584.723]	L2: [38.961037]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 839 pred_label: 839 pred_clean_logit 0.4390246272087097
prompt generate:  suspension bridge  	labels:  [[839]]
decoder:  [49406, 15417, 2465, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([433], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([839], device='cuda:0') tensor(9.5723e-29, device='cuda:0')
L1: [10129.542]	L2: [38.992874]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 975 pred_label: 975 pred_clean_logit 0.5519164204597473
prompt generate:  lakeside  	labels:  [[975]]
decoder:  [49406, 30915, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([144], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([975], device='cuda:0') tensor(2.4290e-12, device='cuda:0')
L1: [8957.228]	L2: [33.333603]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 396 pred_label: 396 pred_clean_logit 0.9989557266235352
prompt generate:  lionfish  	labels:  [[396]]
decoder:  [49406, 8872, 2759, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([71], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([396], device='cuda:0') tensor(6.1826e-20, device='cuda:0')
L1: [9035.795]	L2: [36.517216]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 884 pred_label: 884 pred_clean_logit 0.9990087151527405
prompt generate:  vault  	labels:  [[884]]
decoder:  [49406, 15240, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([750], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([884], device='cuda:0') tensor(2.5071e-13, device='cuda:0')
L1: [8554.871]	L2: [31.059446]	Linf: [0.5254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.4%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=11.3%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=25.0%
Timestep  4: Avg Loss=0.000021, Std=0.000006, Contribution=57.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.6% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 57 pred_label: 57 pred_clean_logit 0.9379867911338806
prompt generate:  garter snake  	labels:  [[57]]
decoder:  [49406, 48420, 8798, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([58], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([57], device='cuda:0') tensor(5.0327e-14, device='cuda:0')
L1: [16774.984]	L2: [56.98185]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=27.4%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 243 pred_label: 243 pred_clean_logit 0.9999736547470093
prompt generate:  bull mastiff  	labels:  [[243]]
decoder:  [49406, 6029, 42311, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([159], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([243], device='cuda:0') tensor(2.0291e-19, device='cuda:0')
L1: [10518.224]	L2: [36.303284]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 770 pred_label: 770 pred_clean_logit 0.9964955449104309
prompt generate:  running shoe  	labels:  [[770]]
decoder:  [49406, 2761, 7342, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([676], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([770], device='cuda:0') tensor(6.9287e-11, device='cuda:0')
L1: [3113.499]	L2: [12.994125]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=56.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.5% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 820 pred_label: 745 pred_clean_logit 0.41332727670669556
prompt generate:  steam locomotive  	labels:  [[745]]
decoder:  [49406, 6972, 30439, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([745], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([820], device='cuda:0') tensor(2.2996e-25, device='cuda:0')
L1: [6995.]	L2: [28.116884]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 479 pred_label: 479 pred_clean_logit 0.9981909394264221
prompt generate:  car wheel  	labels:  [[479]]
decoder:  [49406, 1615, 6744, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([501], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([479], device='cuda:0') tensor(7.4659e-17, device='cuda:0')
L1: [3889.9963]	L2: [19.304987]	Linf: [0.5803922]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 820 pred_label: 820 pred_clean_logit 0.9997398257255554
prompt generate:  steam locomotive  	labels:  [[820]]
decoder:  [49406, 6972, 30439, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([864], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([820], device='cuda:0') tensor(1.6576e-22, device='cuda:0')
L1: [10157.106]	L2: [39.40877]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000005, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000010, Std=0.000002, Contribution=28.3%
Timestep  4: Avg Loss=0.000018, Std=0.000004, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 1.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 320 pred_label: 319 pred_clean_logit 0.2723246216773987
prompt generate:  damselfly  	labels:  [[319]]
decoder:  [49406, 1880, 1000, 3228, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([74], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([320], device='cuda:0') tensor(4.4956e-13, device='cuda:0')
L1: [6514.855]	L2: [23.295355]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.5%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 630 pred_label: 630 pred_clean_logit 0.213254913687706
prompt generate:  Loafer  	labels:  [[630]]
decoder:  [49406, 26467, 528, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([491], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([630], device='cuda:0') tensor(4.3336e-33, device='cuda:0')
L1: [3638.2942]	L2: [13.087408]	Linf: [0.32156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=57.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.9% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 113 pred_label: 113 pred_clean_logit 0.9999902248382568
prompt generate:  snail  	labels:  [[113]]
decoder:  [49406, 23132, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([988], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([113], device='cuda:0') tensor(2.4737e-16, device='cuda:0')
L1: [8636.553]	L2: [32.811718]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 873 pred_label: 873 pred_clean_logit 0.9992402791976929
prompt generate:  triumphal arch  	labels:  [[873]]
decoder:  [49406, 14782, 1037, 8708, 8557, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([483], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([873], device='cuda:0') tensor(3.0417e-14, device='cuda:0')
L1: [5005.753]	L2: [22.405775]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=57.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.8% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 429 pred_label: 429 pred_clean_logit 0.9999788999557495
prompt generate:  baseball  	labels:  [[429]]
decoder:  [49406, 3470, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([429], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([429], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3818.1921]	L2: [21.971212]	Linf: [0.9490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.5%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.0%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=46.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.7% (timestep 4)
Min contribution: 6.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 970 pred_label: 970 pred_clean_logit 0.999798595905304
prompt generate:  alp  	labels:  [[970]]
decoder:  [49406, 39342, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([979], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([970], device='cuda:0') tensor(3.0421e-10, device='cuda:0')
L1: [6936.8984]	L2: [25.655895]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=56.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.6% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 967 pred_label: 463 pred_clean_logit 0.09133784472942352
prompt generate:  espresso  	labels:  [[463]]
decoder:  [49406, 17098, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([809], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([967], device='cuda:0') tensor(9.8620e-16, device='cuda:0')
L1: [5962.7334]	L2: [21.439049]	Linf: [0.52549016]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 976 pred_label: 976 pred_clean_logit 0.9949560761451721
prompt generate:  promontory  	labels:  [[976]]
decoder:  [49406, 644, 749, 4214, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([978], device='cuda:0') tensor(0.9959, device='cuda:0')
after_true: tensor([976], device='cuda:0') tensor(3.3841e-08, device='cuda:0')
L1: [6198.573]	L2: [25.426287]	Linf: [0.72156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 603 pred_label: 603 pred_clean_logit 0.7516590356826782
prompt generate:  horse cart  	labels:  [[603]]
decoder:  [49406, 4558, 13065, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([690], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([603], device='cuda:0') tensor(6.4789e-11, device='cuda:0')
L1: [7159.3843]	L2: [29.169403]	Linf: [0.65882355]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 570 pred_label: 570 pred_clean_logit 0.9999947547912598
prompt generate:  gasmask  	labels:  [[570]]
decoder:  [49406, 5047, 8306, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([570], device='cuda:0') tensor(0.8476, device='cuda:0')
after_true: tensor([570], device='cuda:0') tensor(0.8476, device='cuda:0')
L1: [6617.314]	L2: [29.943499]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.6%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.3%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 853 pred_label: 853 pred_clean_logit 0.999946117401123
prompt generate:  thatch  	labels:  [[853]]
decoder:  [49406, 6303, 634, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([846], device='cuda:0') tensor(0.5859, device='cuda:0')
after_true: tensor([853], device='cuda:0') tensor(4.6598e-15, device='cuda:0')
L1: [4859.972]	L2: [20.043926]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=21.7%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=62.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 62.7% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 229 pred_label: 229 pred_clean_logit 0.7925835251808167
prompt generate:  Old English sheepdog  	labels:  [[229]]
decoder:  [49406, 896, 3469, 23604, 1929, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([170], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([229], device='cuda:0') tensor(3.5524e-14, device='cuda:0')
L1: [8084.675]	L2: [29.329779]	Linf: [0.58431375]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 945 pred_label: 945 pred_clean_logit 0.9999370574951172
prompt generate:  bell pepper  	labels:  [[945]]
decoder:  [49406, 3718, 8253, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([747], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([945], device='cuda:0') tensor(1.2395e-26, device='cuda:0')
L1: [4653.2114]	L2: [23.074041]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 319 pred_label: 319 pred_clean_logit 0.9999920129776001
prompt generate:  dragonfly  	labels:  [[319]]
decoder:  [49406, 32824, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([316], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([319], device='cuda:0') tensor(1.0531e-15, device='cuda:0')
L1: [6874.9844]	L2: [27.926311]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=55.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.7% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 535 pred_label: 573 pred_clean_logit 0.0008028927259147167
prompt generate:  disk brake  	labels:  [[573]]
decoder:  [49406, 17970, 14937, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([573], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([535], device='cuda:0') tensor(4.6003e-16, device='cuda:0')
L1: [5826.0234]	L2: [24.158033]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 656 pred_label: 656 pred_clean_logit 0.9991450309753418
prompt generate:  minivan  	labels:  [[656]]
decoder:  [49406, 1810, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([569], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([656], device='cuda:0') tensor(2.9644e-13, device='cuda:0')
L1: [5660.8193]	L2: [24.834297]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=48.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.9% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 144 pred_label: 144 pred_clean_logit 0.9851330518722534
prompt generate:  pelican  	labels:  [[144]]
decoder:  [49406, 34131, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([146], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([144], device='cuda:0') tensor(1.0040e-11, device='cuda:0')
L1: [2467.3374]	L2: [10.924383]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.9%
Timestep  4: Avg Loss=0.000012, Std=0.000005, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 919 pred_label: 919 pred_clean_logit 0.9409171938896179
prompt generate:  street sign  	labels:  [[919]]
decoder:  [49406, 2012, 2292, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([557], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([919], device='cuda:0') tensor(4.2731e-21, device='cuda:0')
L1: [8538.754]	L2: [33.41638]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 917 pred_label: 917 pred_clean_logit 0.9529033303260803
prompt generate:  comic book  	labels:  [[917]]
decoder:  [49406, 4962, 1116, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([805], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([917], device='cuda:0') tensor(7.1789e-27, device='cuda:0')
L1: [9126.02]	L2: [34.932007]	Linf: [0.6666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 883 pred_label: 883 pred_clean_logit 0.3995674252510071
prompt generate:  vase  	labels:  [[883]]
decoder:  [49406, 20431, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([911], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([883], device='cuda:0') tensor(2.8735e-26, device='cuda:0')
L1: [5093.2236]	L2: [20.201538]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=56.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.5% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 73 pred_label: 73 pred_clean_logit 0.7488833665847778
prompt generate:  barn spider  	labels:  [[73]]
decoder:  [49406, 10942, 7622, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([74], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([73], device='cuda:0') tensor(1.4858e-09, device='cuda:0')
L1: [6948.1997]	L2: [28.237843]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=25.7%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 385 pred_label: 385 pred_clean_logit 0.9989179372787476
prompt generate:  Indian elephant  	labels:  [[385]]
decoder:  [49406, 3606, 10299, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([386], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([385], device='cuda:0') tensor(2.5457e-18, device='cuda:0')
L1: [6083.149]	L2: [21.468462]	Linf: [0.517647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 927 pred_label: 927 pred_clean_logit 0.9303990602493286
prompt generate:  trifle  	labels:  [[927]]
decoder:  [49406, 924, 44964, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([773], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([927], device='cuda:0') tensor(4.2628e-20, device='cuda:0')
L1: [6287.302]	L2: [23.922836]	Linf: [0.58431375]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.8%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=14.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=46.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.4% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 472 pred_label: 472 pred_clean_logit 0.993735134601593
prompt generate:  canoe  	labels:  [[472]]
decoder:  [49406, 23503, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([625], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([472], device='cuda:0') tensor(7.2478e-26, device='cuda:0')
L1: [8132.6206]	L2: [33.78543]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 746 pred_label: 746 pred_clean_logit 0.9948793649673462
prompt generate:  puck  	labels:  [[746]]
decoder:  [49406, 17550, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([795], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([746], device='cuda:0') tensor(1.4062e-10, device='cuda:0')
L1: [4479.377]	L2: [22.853848]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 421 pred_label: 818 pred_clean_logit 0.00024304479302372783
prompt generate:  bannister  	labels:  [[818]]
decoder:  [49406, 1159, 36640, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([818], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([421], device='cuda:0') tensor(2.1837e-24, device='cuda:0')
L1: [3012.8982]	L2: [14.368803]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.5%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=13.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=48.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.6% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 910 pred_label: 910 pred_clean_logit 0.2607631981372833
prompt generate:  wooden spoon  	labels:  [[910]]
decoder:  [49406, 9057, 14024, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([113], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([910], device='cuda:0') tensor(3.3168e-23, device='cuda:0')
L1: [5170.628]	L2: [20.800808]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.3%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 879 pred_label: 879 pred_clean_logit 0.9999943971633911
prompt generate:  umbrella  	labels:  [[879]]
decoder:  [49406, 17143, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([936], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([879], device='cuda:0') tensor(1.3369e-26, device='cuda:0')
L1: [14804.574]	L2: [50.495296]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 967 pred_label: 967 pred_clean_logit 0.9998666048049927
prompt generate:  espresso  	labels:  [[967]]
decoder:  [49406, 17098, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([935], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([967], device='cuda:0') tensor(5.0443e-22, device='cuda:0')
L1: [5725.882]	L2: [25.61165]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=13.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 557 pred_label: 775 pred_clean_logit 0.002792698796838522
prompt generate:  flagpole  	labels:  [[775]]
decoder:  [49406, 11536, 8170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([775], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([557], device='cuda:0') tensor(2.7294e-22, device='cuda:0')
L1: [7147.212]	L2: [36.112003]	Linf: [0.99215686]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 554 pred_label: 718 pred_clean_logit 0.02032981812953949
prompt generate:  fireboat  	labels:  [[718]]
decoder:  [49406, 2951, 4440, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([718], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([554], device='cuda:0') tensor(1.4299e-10, device='cuda:0')
L1: [6591.9966]	L2: [28.456463]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 253 pred_label: 253 pred_clean_logit 0.9998292922973633
prompt generate:  basenji  	labels:  [[253]]
decoder:  [49406, 1244, 524, 2697, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([286], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([253], device='cuda:0') tensor(2.9290e-17, device='cuda:0')
L1: [5494.087]	L2: [21.366766]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000003, Contribution=25.0%
Timestep  4: Avg Loss=0.000009, Std=0.000005, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 440 pred_label: 440 pred_clean_logit 0.9945927262306213
prompt generate:  beer bottle  	labels:  [[440]]
decoder:  [49406, 2544, 5392, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([631], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([440], device='cuda:0') tensor(3.0903e-31, device='cuda:0')
L1: [10518.612]	L2: [41.72902]	Linf: [0.93333334]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=26.2%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 987 pred_label: 987 pred_clean_logit 0.8130600452423096
prompt generate:  corn  	labels:  [[987]]
decoder:  [49406, 5894, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([943], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([987], device='cuda:0') tensor(8.4061e-29, device='cuda:0')
L1: [7323.5845]	L2: [28.216179]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 547 pred_label: 547 pred_clean_logit 0.9996097683906555
prompt generate:  electric locomotive  	labels:  [[547]]
decoder:  [49406, 5031, 30439, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([625], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([547], device='cuda:0') tensor(2.0411e-12, device='cuda:0')
L1: [5854.2705]	L2: [26.44193]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 922 pred_label: 782 pred_clean_logit 0.4194594621658325
prompt generate:  menu  	labels:  [[782]]
decoder:  [49406, 6225, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([782], device='cuda:0') tensor(0.9670, device='cuda:0')
after_true: tensor([922], device='cuda:0') tensor(3.3470e-10, device='cuda:0')
L1: [4457.682]	L2: [19.317415]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=10.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=12.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.1%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=41.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.3% (timestep 4)
Min contribution: 10.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 137 pred_label: 137 pred_clean_logit 0.9923145174980164
prompt generate:  American coot  	labels:  [[137]]
decoder:  [49406, 2151, 1664, 339, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([99], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([137], device='cuda:0') tensor(5.0163e-11, device='cuda:0')
L1: [11049.274]	L2: [38.475887]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 533 pred_label: 533 pred_clean_logit 0.42179757356643677
prompt generate:  dishrag  	labels:  [[533]]
decoder:  [49406, 11039, 20687, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([824], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([533], device='cuda:0') tensor(2.0589e-11, device='cuda:0')
L1: [8911.38]	L2: [39.00723]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=26.4%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=47.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.9% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 698 pred_label: 698 pred_clean_logit 0.9976786971092224
prompt generate:  palace  	labels:  [[698]]
decoder:  [49406, 6381, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([665], device='cuda:0') tensor(0.9660, device='cuda:0')
after_true: tensor([698], device='cuda:0') tensor(4.3934e-14, device='cuda:0')
L1: [9805.043]	L2: [37.239834]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=45.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.7% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 487 pred_label: 662 pred_clean_logit 1.2032273843942676e-07
prompt generate:  cellular telephone  	labels:  [[662]]
decoder:  [49406, 23268, 17243, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([662], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([487], device='cuda:0') tensor(7.5902e-24, device='cuda:0')
L1: [5064.741]	L2: [24.65825]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 990 pred_label: 990 pred_clean_logit 0.9973151087760925
prompt generate:  buckeye  	labels:  [[990]]
decoder:  [49406, 34549, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([118], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([990], device='cuda:0') tensor(2.5390e-24, device='cuda:0')
L1: [8881.804]	L2: [34.487396]	Linf: [0.8156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 417 pred_label: 417 pred_clean_logit 0.9999970197677612
prompt generate:  balloon  	labels:  [[417]]
decoder:  [49406, 13634, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([417], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([417], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3354.843]	L2: [14.378855]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=7.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.2%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.7%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=43.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.4% (timestep 4)
Min contribution: 7.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 603 pred_label: 603 pred_clean_logit 0.9999796152114868
prompt generate:  horse cart  	labels:  [[603]]
decoder:  [49406, 4558, 13065, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([822], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([603], device='cuda:0') tensor(7.1642e-33, device='cuda:0')
L1: [9257.232]	L2: [34.20275]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 624 pred_label: 624 pred_clean_logit 0.9639179706573486
prompt generate:  library  	labels:  [[624]]
decoder:  [49406, 3519, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([498], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([624], device='cuda:0') tensor(5.7261e-23, device='cuda:0')
L1: [6676.447]	L2: [28.333462]	Linf: [0.9137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 517 pred_label: 483 pred_clean_logit 0.17049628496170044
prompt generate:  crane  	labels:  [[483]]
decoder:  [49406, 14626, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([731], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([517], device='cuda:0') tensor(2.0114e-30, device='cuda:0')
L1: [8280.008]	L2: [36.96042]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=55.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.7% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 327 pred_label: 327 pred_clean_logit 0.973945677280426
prompt generate:  starfish  	labels:  [[327]]
decoder:  [49406, 44283, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([112], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([327], device='cuda:0') tensor(2.5287e-11, device='cuda:0')
L1: [4775.2866]	L2: [25.680164]	Linf: [0.972549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.5%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=56.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.4% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 319 pred_label: 319 pred_clean_logit 0.999854326248169
prompt generate:  dragonfly  	labels:  [[319]]
decoder:  [49406, 32824, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([326], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([319], device='cuda:0') tensor(1.2661e-10, device='cuda:0')
L1: [3575.2083]	L2: [16.224918]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.4%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 518 pred_label: 518 pred_clean_logit 0.9996545314788818
prompt generate:  crash helmet  	labels:  [[518]]
decoder:  [49406, 5033, 11122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([746], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([518], device='cuda:0') tensor(5.1979e-12, device='cuda:0')
L1: [7054.4272]	L2: [36.35667]	Linf: [0.9098039]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=48.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.1% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 386 pred_label: 386 pred_clean_logit 0.9997387528419495
prompt generate:  African elephant  	labels:  [[386]]
decoder:  [49406, 4736, 10299, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([101], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([386], device='cuda:0') tensor(1.0416e-13, device='cuda:0')
L1: [11015.061]	L2: [41.859715]	Linf: [0.9137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 404 pred_label: 404 pred_clean_logit 0.999975323677063
prompt generate:  airliner  	labels:  [[404]]
decoder:  [49406, 1281, 11618, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([404], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([404], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2680.2312]	L2: [13.034002]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 749 pred_label: 749 pred_clean_logit 1.0
prompt generate:  quill  	labels:  [[749]]
decoder:  [49406, 48951, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([749], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([749], device='cuda:0') tensor(1., device='cuda:0')
L1: [10021.993]	L2: [33.944386]	Linf: [0.5058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=58.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.0% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 415 pred_label: 415 pred_clean_logit 0.998011589050293
prompt generate:  bakery  	labels:  [[415]]
decoder:  [49406, 13377, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([955], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([415], device='cuda:0') tensor(1.8242e-25, device='cuda:0')
L1: [8879.707]	L2: [37.079777]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.3%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 569 pred_label: 569 pred_clean_logit 0.988713800907135
prompt generate:  garbage truck  	labels:  [[569]]
decoder:  [49406, 13760, 4629, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([450], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([569], device='cuda:0') tensor(6.2676e-23, device='cuda:0')
L1: [7876.177]	L2: [34.02527]	Linf: [0.9607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 990 pred_label: 990 pred_clean_logit 0.9999728202819824
prompt generate:  buckeye  	labels:  [[990]]
decoder:  [49406, 34549, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([952], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([990], device='cuda:0') tensor(2.3754e-18, device='cuda:0')
L1: [7535.1846]	L2: [32.249382]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 851 pred_label: 851 pred_clean_logit 0.43955257534980774
prompt generate:  television  	labels:  [[851]]
decoder:  [49406, 8608, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([920], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([851], device='cuda:0') tensor(1.4411e-22, device='cuda:0')
L1: [4029.3452]	L2: [17.733131]	Linf: [0.54901963]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 9 pred_label: 9 pred_clean_logit 0.9999959468841553
prompt generate:  ostrich  	labels:  [[9]]
decoder:  [49406, 47640, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([355], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([9], device='cuda:0') tensor(3.4863e-19, device='cuda:0')
L1: [7267.227]	L2: [25.710314]	Linf: [0.65098035]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 717 pred_label: 717 pred_clean_logit 0.9997900128364563
prompt generate:  pickup  	labels:  [[717]]
decoder:  [49406, 15382, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([436], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([717], device='cuda:0') tensor(4.9752e-13, device='cuda:0')
L1: [6947.8286]	L2: [26.400606]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=44.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.1% (timestep 4)
Min contribution: 7.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 347 pred_label: 347 pred_clean_logit 0.999990701675415
prompt generate:  bison  	labels:  [[347]]
decoder:  [49406, 19741, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([294], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([347], device='cuda:0') tensor(2.4221e-16, device='cuda:0')
L1: [6074.8076]	L2: [24.942724]	Linf: [0.5647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=22.9%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=58.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.0% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 555 pred_label: 555 pred_clean_logit 0.9999994039535522
prompt generate:  fire engine  	labels:  [[555]]
decoder:  [49406, 1769, 5857, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([555], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([555], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [10106.573]	L2: [41.633022]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=10.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=16.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.9%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=42.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.3% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 817 pred_label: 817 pred_clean_logit 0.9987474679946899
prompt generate:  sports car  	labels:  [[817]]
decoder:  [49406, 2054, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([436], device='cuda:0') tensor(0.9992, device='cuda:0')
after_true: tensor([817], device='cuda:0') tensor(2.0053e-10, device='cuda:0')
L1: [5524.874]	L2: [21.212337]	Linf: [0.5921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.4%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 865 pred_label: 865 pred_clean_logit 0.9949308037757874
prompt generate:  toyshop  	labels:  [[865]]
decoder:  [49406, 14387, 1557, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([621], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([865], device='cuda:0') tensor(6.3383e-18, device='cuda:0')
L1: [8837.411]	L2: [35.069603]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 411 pred_label: 411 pred_clean_logit 0.9960911870002747
prompt generate:  apron  	labels:  [[411]]
decoder:  [49406, 29502, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([823], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([411], device='cuda:0') tensor(5.8144e-27, device='cuda:0')
L1: [4949.7534]	L2: [22.931402]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.6% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 629 pred_label: 629 pred_clean_logit 0.9999837875366211
prompt generate:  lipstick  	labels:  [[629]]
decoder:  [49406, 15618, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([258], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([629], device='cuda:0') tensor(1.3974e-11, device='cuda:0')
L1: [2820.2197]	L2: [9.549498]	Linf: [0.21960786]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=20.5%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=61.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 61.6% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 963 pred_label: 963 pred_clean_logit 0.8544861078262329
prompt generate:  pizza  	labels:  [[963]]
decoder:  [49406, 4474, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([941], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([963], device='cuda:0') tensor(7.4998e-12, device='cuda:0')
L1: [13644.446]	L2: [47.039]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.8%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 517 pred_label: 517 pred_clean_logit 0.9979812502861023
prompt generate:  crane  	labels:  [[517]]
decoder:  [49406, 14626, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([744], device='cuda:0') tensor(0.9910, device='cuda:0')
after_true: tensor([517], device='cuda:0') tensor(1.3594e-17, device='cuda:0')
L1: [10242.126]	L2: [40.774437]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 264 pred_label: 264 pred_clean_logit 0.9998538494110107
prompt generate:  Cardigan  	labels:  [[264]]
decoder:  [49406, 30501, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([232], device='cuda:0') tensor(0.9402, device='cuda:0')
after_true: tensor([264], device='cuda:0') tensor(5.1299e-11, device='cuda:0')
L1: [6354.811]	L2: [23.299793]	Linf: [0.5411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000004, Std=0.000003, Contribution=25.5%
Timestep  4: Avg Loss=0.000008, Std=0.000005, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 895 pred_label: 895 pred_clean_logit 0.45393046736717224
prompt generate:  warplane  	labels:  [[895]]
decoder:  [49406, 984, 5363, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([822], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([895], device='cuda:0') tensor(3.0881e-28, device='cuda:0')
L1: [6004.365]	L2: [28.635279]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 546 pred_label: 546 pred_clean_logit 0.8347919583320618
prompt generate:  electric guitar  	labels:  [[546]]
decoder:  [49406, 5031, 5084, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([402], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([546], device='cuda:0') tensor(4.2320e-08, device='cuda:0')
L1: [6269.9062]	L2: [31.328156]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.2%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=43.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.0% (timestep 4)
Min contribution: 8.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 903 pred_label: 903 pred_clean_logit 0.9996589422225952
prompt generate:  wig  	labels:  [[903]]
decoder:  [49406, 12216, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([616], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([903], device='cuda:0') tensor(3.4142e-15, device='cuda:0')
L1: [6668.8125]	L2: [25.468172]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=12.6%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.8%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 708 pred_label: 708 pred_clean_logit 0.9963271021842957
prompt generate:  pedestal  	labels:  [[708]]
decoder:  [49406, 12862, 5535, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([863], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([708], device='cuda:0') tensor(4.4841e-26, device='cuda:0')
L1: [13229.638]	L2: [46.40777]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=12.8%
Timestep  3: Avg Loss=0.000010, Std=0.000003, Contribution=27.2%
Timestep  4: Avg Loss=0.000020, Std=0.000006, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 317 pred_label: 317 pred_clean_logit 0.9999699592590332
prompt generate:  leafhopper  	labels:  [[317]]
decoder:  [49406, 9377, 21748, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([316], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([317], device='cuda:0') tensor(1.5166e-17, device='cuda:0')
L1: [5400.475]	L2: [21.55144]	Linf: [0.5490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=58.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.9% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 141 pred_label: 141 pred_clean_logit 0.9998247027397156
prompt generate:  redshank  	labels:  [[141]]
decoder:  [49406, 1893, 24685, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([143], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([141], device='cuda:0') tensor(7.2004e-07, device='cuda:0')
L1: [3959.9297]	L2: [17.344755]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 22 pred_label: 22 pred_clean_logit 0.9998936653137207
prompt generate:  bald eagle  	labels:  [[22]]
decoder:  [49406, 14875, 7517, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([23], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([22], device='cuda:0') tensor(3.4192e-09, device='cuda:0')
L1: [4669.675]	L2: [18.164366]	Linf: [0.5882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 760 pred_label: 760 pred_clean_logit 0.9886598587036133
prompt generate:  refrigerator  	labels:  [[760]]
decoder:  [49406, 36662, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([710], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([760], device='cuda:0') tensor(1.4589e-09, device='cuda:0')
L1: [2745.4663]	L2: [15.888119]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.4%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=47.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.9% (timestep 4)
Min contribution: 6.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 772 pred_label: 772 pred_clean_logit 0.7453737854957581
prompt generate:  safety pin  	labels:  [[772]]
decoder:  [49406, 3406, 5164, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([769], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([772], device='cuda:0') tensor(5.9095e-24, device='cuda:0')
L1: [10258.069]	L2: [44.72671]	Linf: [0.96862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=47.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.2% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 978 pred_label: 976 pred_clean_logit 0.37006035447120667
prompt generate:  seashore  	labels:  [[976]]
decoder:  [49406, 567, 31194, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([976], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([978], device='cuda:0') tensor(5.9025e-09, device='cuda:0')
L1: [6855.545]	L2: [30.136562]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 682 pred_label: 682 pred_clean_logit 0.9976577758789062
prompt generate:  obelisk  	labels:  [[682]]
decoder:  [49406, 78, 1308, 30171, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([437], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([682], device='cuda:0') tensor(1.9362e-17, device='cuda:0')
L1: [4576.2427]	L2: [20.506193]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 746 pred_label: 746 pred_clean_logit 0.998091995716095
prompt generate:  puck  	labels:  [[746]]
decoder:  [49406, 17550, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([795], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([746], device='cuda:0') tensor(8.3844e-10, device='cuda:0')
L1: [6537.7334]	L2: [33.234627]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 938 pred_label: 582 pred_clean_logit 0.15248779952526093
prompt generate:  cauliflower  	labels:  [[582]]
decoder:  [49406, 23802, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([410], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([938], device='cuda:0') tensor(1.0509e-25, device='cuda:0')
L1: [7059.0586]	L2: [30.923307]	Linf: [0.9137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 472 pred_label: 975 pred_clean_logit 0.017955441027879715
prompt generate:  canoe  	labels:  [[975]]
decoder:  [49406, 23503, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([863], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([472], device='cuda:0') tensor(3.2464e-22, device='cuda:0')
L1: [8495.09]	L2: [30.996395]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 864 pred_label: 864 pred_clean_logit 0.8859937191009521
prompt generate:  tow truck  	labels:  [[864]]
decoder:  [49406, 18653, 4629, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([675], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([864], device='cuda:0') tensor(3.8310e-14, device='cuda:0')
L1: [8136.976]	L2: [36.178474]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 765 pred_label: 765 pred_clean_logit 0.9990702271461487
prompt generate:  rocking chair  	labels:  [[765]]
decoder:  [49406, 7081, 4269, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([706], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([765], device='cuda:0') tensor(4.2880e-11, device='cuda:0')
L1: [6723.2207]	L2: [29.391733]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=22.4%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 754 pred_label: 528 pred_clean_logit 0.0006989212124608457
prompt generate:  radio  	labels:  [[528]]
decoder:  [49406, 2638, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([528], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([754], device='cuda:0') tensor(1.5247e-17, device='cuda:0')
L1: [9302.308]	L2: [42.002666]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 705 pred_label: 705 pred_clean_logit 0.9989870190620422
prompt generate:  passenger car  	labels:  [[705]]
decoder:  [49406, 12311, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([466], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([705], device='cuda:0') tensor(1.7034e-11, device='cuda:0')
L1: [9443.153]	L2: [37.124283]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=47.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.0% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 614 pred_label: 614 pred_clean_logit 0.9994292855262756
prompt generate:  kimono  	labels:  [[614]]
decoder:  [49406, 40024, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([703], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([614], device='cuda:0') tensor(9.9749e-24, device='cuda:0')
L1: [9477.436]	L2: [37.359238]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=57.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.6% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 309 pred_label: 309 pred_clean_logit 0.999890923500061
prompt generate:  bee  	labels:  [[309]]
decoder:  [49406, 5028, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([410], device='cuda:0') tensor(0.9551, device='cuda:0')
after_true: tensor([309], device='cuda:0') tensor(0.0004, device='cuda:0')
L1: [5133.8545]	L2: [21.493958]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 884 pred_label: 884 pred_clean_logit 0.6498848795890808
prompt generate:  vault  	labels:  [[884]]
decoder:  [49406, 15240, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([112], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([884], device='cuda:0') tensor(1.3622e-12, device='cuda:0')
L1: [9106.086]	L2: [32.383316]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=11.4%
Timestep  3: Avg Loss=0.000011, Std=0.000003, Contribution=25.1%
Timestep  4: Avg Loss=0.000025, Std=0.000006, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 1.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 471 pred_label: 471 pred_clean_logit 0.9998257756233215
prompt generate:  cannon  	labels:  [[471]]
decoder:  [49406, 15661, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([657], device='cuda:0') tensor(0.5122, device='cuda:0')
after_true: tensor([471], device='cuda:0') tensor(1.6601e-19, device='cuda:0')
L1: [7409.04]	L2: [33.22894]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=13.0%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.0%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 698 pred_label: 698 pred_clean_logit 0.5003770589828491
prompt generate:  palace  	labels:  [[698]]
decoder:  [49406, 6381, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([483], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([698], device='cuda:0') tensor(7.6541e-05, device='cuda:0')
L1: [8787.659]	L2: [40.722088]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.4%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=56.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.4% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 884 pred_label: 884 pred_clean_logit 0.9979724287986755
prompt generate:  vault  	labels:  [[884]]
decoder:  [49406, 15240, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([74], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([884], device='cuda:0') tensor(6.9348e-15, device='cuda:0')
L1: [12726.435]	L2: [44.130417]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=7.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=46.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.0% (timestep 4)
Min contribution: 7.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 972 pred_label: 500 pred_clean_logit 0.021556243300437927
prompt generate:  cliff  	labels:  [[500]]
decoder:  [49406, 10625, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([346], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([972], device='cuda:0') tensor(9.0322e-15, device='cuda:0')
L1: [8176.989]	L2: [28.316713]	Linf: [0.5803922]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=24.5%
Timestep  4: Avg Loss=0.000020, Std=0.000005, Contribution=59.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.1% (timestep 4)
Min contribution: 1.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 401 pred_label: 645 pred_clean_logit 0.000551500590518117
prompt generate:  accordion  	labels:  [[645]]
decoder:  [49406, 48760, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([645], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([401], device='cuda:0') tensor(3.3678e-26, device='cuda:0')
L1: [9683.473]	L2: [36.709362]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=45.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.5% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 970 pred_label: 876 pred_clean_logit 0.008157282136380672
prompt generate:  alp  	labels:  [[876]]
decoder:  [49406, 39342, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([876], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([970], device='cuda:0') tensor(2.1654e-23, device='cuda:0')
L1: [5883.1377]	L2: [22.967518]	Linf: [0.5647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 630 pred_label: 630 pred_clean_logit 0.8765501976013184
prompt generate:  Loafer  	labels:  [[630]]
decoder:  [49406, 26467, 528, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([589], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([630], device='cuda:0') tensor(1.3018e-18, device='cuda:0')
L1: [3279.1729]	L2: [15.7746]	Linf: [0.62352943]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 310 pred_label: 310 pred_clean_logit 0.9999932050704956
prompt generate:  ant  	labels:  [[310]]
decoder:  [49406, 773, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([70], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([310], device='cuda:0') tensor(9.1873e-17, device='cuda:0')
L1: [5948.255]	L2: [22.94822]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 12 pred_label: 12 pred_clean_logit 0.9999327659606934
prompt generate:  house finch  	labels:  [[12]]
decoder:  [49406, 1212, 18523, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([12], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([12], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [2076.949]	L2: [10.896977]	Linf: [0.46666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.5%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=20.3%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 538 pred_label: 884 pred_clean_logit 0.4329378008842468
prompt generate:  dome  	labels:  [[884]]
decoder:  [49406, 9827, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([884], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([538], device='cuda:0') tensor(7.5612e-13, device='cuda:0')
L1: [5443.464]	L2: [23.472862]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 538 pred_label: 538 pred_clean_logit 0.9985617995262146
prompt generate:  dome  	labels:  [[538]]
decoder:  [49406, 9827, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([832], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([538], device='cuda:0') tensor(6.2799e-12, device='cuda:0')
L1: [5972.4355]	L2: [26.150133]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=13.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=14.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=17.3%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=21.7%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=33.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 33.4% (timestep 4)
Min contribution: 13.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 38 pred_label: 38 pred_clean_logit 0.9079753160476685
prompt generate:  banded gecko  	labels:  [[38]]
decoder:  [49406, 37804, 38616, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([56], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([38], device='cuda:0') tensor(4.0199e-19, device='cuda:0')
L1: [7281.7954]	L2: [29.468218]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 667 pred_label: 764 pred_clean_logit 0.018050843849778175
prompt generate:  mortarboard  	labels:  [[764]]
decoder:  [49406, 657, 2002, 1972, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([614], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([667], device='cuda:0') tensor(3.4303e-18, device='cuda:0')
L1: [4667.812]	L2: [20.130703]	Linf: [0.62352943]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=58.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.7% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 340 pred_label: 340 pred_clean_logit 0.9999908208847046
prompt generate:  zebra  	labels:  [[340]]
decoder:  [49406, 22548, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([340], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([340], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [13850.506]	L2: [52.493793]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.8%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.5%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 605 pred_label: 620 pred_clean_logit 0.27445563673973083
prompt generate:  iPod  	labels:  [[620]]
decoder:  [49406, 17889, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([620], device='cuda:0') tensor(0.9991, device='cuda:0')
after_true: tensor([605], device='cuda:0') tensor(8.1725e-15, device='cuda:0')
L1: [4757.5615]	L2: [20.28388]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 547 pred_label: 547 pred_clean_logit 0.9515500068664551
prompt generate:  electric locomotive  	labels:  [[547]]
decoder:  [49406, 5031, 30439, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([494], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([547], device='cuda:0') tensor(2.4846e-32, device='cuda:0')
L1: [8903.593]	L2: [34.859226]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=55.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.8% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 652 pred_label: 652 pred_clean_logit 0.7433629035949707
prompt generate:  military uniform  	labels:  [[652]]
decoder:  [49406, 4323, 11075, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([645], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([652], device='cuda:0') tensor(8.2768e-18, device='cuda:0')
L1: [8914.753]	L2: [42.834305]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.2%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 937 pred_label: 937 pred_clean_logit 0.999998927116394
prompt generate:  broccoli  	labels:  [[937]]
decoder:  [49406, 19094, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([951], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([937], device='cuda:0') tensor(5.2772e-16, device='cuda:0')
L1: [7046.357]	L2: [28.237442]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 777 pred_label: 777 pred_clean_logit 0.4781397879123688
prompt generate:  scabbard  	labels:  [[777]]
decoder:  [49406, 31716, 17514, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([858], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([777], device='cuda:0') tensor(6.2895e-14, device='cuda:0')
L1: [4157.7407]	L2: [16.282578]	Linf: [0.5490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 665 pred_label: 665 pred_clean_logit 0.9947222471237183
prompt generate:  moped  	labels:  [[665]]
decoder:  [49406, 617, 2966, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([671], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([665], device='cuda:0') tensor(2.8000e-14, device='cuda:0')
L1: [11593.894]	L2: [42.542625]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 685 pred_label: 507 pred_clean_logit 0.40768879652023315
prompt generate:  odometer  	labels:  [[507]]
decoder:  [49406, 78, 8515, 652, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([507], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([685], device='cuda:0') tensor(1.3738e-09, device='cuda:0')
L1: [2499.8]	L2: [19.588924]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=27.4%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=44.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.4% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 511 pred_label: 511 pred_clean_logit 0.9958977103233337
prompt generate:  convertible  	labels:  [[511]]
decoder:  [49406, 19608, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([627], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([511], device='cuda:0') tensor(2.0271e-20, device='cuda:0')
L1: [8052.373]	L2: [32.517025]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 308 pred_label: 308 pred_clean_logit 0.8549548387527466
prompt generate:  fly  	labels:  [[308]]
decoder:  [49406, 3228, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([314], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([308], device='cuda:0') tensor(1.8648e-17, device='cuda:0')
L1: [4867.212]	L2: [18.941862]	Linf: [0.5686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 2 pred_label: 2 pred_clean_logit 0.9997571110725403
prompt generate:  great white shark  	labels:  [[2]]
decoder:  [49406, 830, 1579, 7980, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([801], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([2], device='cuda:0') tensor(4.0657e-13, device='cuda:0')
L1: [3916.7021]	L2: [14.120669]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=14.2%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=28.6%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 469 pred_label: 469 pred_clean_logit 0.9999295473098755
prompt generate:  caldron  	labels:  [[469]]
decoder:  [49406, 1198, 23360, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([541], device='cuda:0') tensor(0.9873, device='cuda:0')
after_true: tensor([469], device='cuda:0') tensor(6.6678e-16, device='cuda:0')
L1: [6823.8]	L2: [27.229053]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=12.9%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.0%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 717 pred_label: 717 pred_clean_logit 0.9998650550842285
prompt generate:  pickup  	labels:  [[717]]
decoder:  [49406, 15382, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([717], device='cuda:0') tensor(5.9644e-13, device='cuda:0')
L1: [7611.7026]	L2: [30.455126]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=11.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.4%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=41.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.8% (timestep 4)
Min contribution: 8.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 980 pred_label: 980 pred_clean_logit 0.9931753277778625
prompt generate:  volcano  	labels:  [[980]]
decoder:  [49406, 14581, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([994], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([980], device='cuda:0') tensor(1.5926e-18, device='cuda:0')
L1: [15627.476]	L2: [54.599213]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 251 pred_label: 251 pred_clean_logit 0.9991016387939453
prompt generate:  dalmatian  	labels:  [[251]]
decoder:  [49406, 44275, 550, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([293], device='cuda:0') tensor(0.9989, device='cuda:0')
after_true: tensor([251], device='cuda:0') tensor(8.2189e-10, device='cuda:0')
L1: [9195.596]	L2: [33.383755]	Linf: [0.62352943]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=26.0%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 738 pred_label: 738 pred_clean_logit 0.9969267249107361
prompt generate:  pot  	labels:  [[738]]
decoder:  [49406, 5168, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([949], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([738], device='cuda:0') tensor(1.5677e-20, device='cuda:0')
L1: [10100.819]	L2: [38.374477]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 829 pred_label: 874 pred_clean_logit 0.02417285367846489
prompt generate:  streetcar  	labels:  [[874]]
decoder:  [49406, 34268, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([874], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([829], device='cuda:0') tensor(1.6677e-16, device='cuda:0')
L1: [4758.879]	L2: [20.981201]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000018, Std=0.000005, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 557 pred_label: 557 pred_clean_logit 0.8405631184577942
prompt generate:  flagpole  	labels:  [[557]]
decoder:  [49406, 11536, 8170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([889], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([557], device='cuda:0') tensor(6.2394e-35, device='cuda:0')
L1: [8377.812]	L2: [39.091873]	Linf: [0.91764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=49.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.3% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 817 pred_label: 817 pred_clean_logit 0.5243144035339355
prompt generate:  sports car  	labels:  [[817]]
decoder:  [49406, 2054, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([436], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([817], device='cuda:0') tensor(4.2138e-14, device='cuda:0')
L1: [6924.726]	L2: [26.104935]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=2.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.7%
Timestep  3: Avg Loss=0.000008, Std=0.000004, Contribution=26.2%
Timestep  4: Avg Loss=0.000017, Std=0.000006, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 833 pred_label: 833 pred_clean_logit 0.9998900890350342
prompt generate:  submarine  	labels:  [[833]]
decoder:  [49406, 19968, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([718], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([833], device='cuda:0') tensor(4.6892e-17, device='cuda:0')
L1: [4648.0977]	L2: [20.086424]	Linf: [0.61176467]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.0%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=25.6%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 829 pred_label: 829 pred_clean_logit 0.9943954944610596
prompt generate:  streetcar  	labels:  [[829]]
decoder:  [49406, 34268, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([874], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([829], device='cuda:0') tensor(2.8497e-16, device='cuda:0')
L1: [9212.749]	L2: [35.17178]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 458 pred_label: 458 pred_clean_logit 0.9999243021011353
prompt generate:  brass  	labels:  [[458]]
decoder:  [49406, 11655, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([458], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([458], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [8135.1025]	L2: [32.973457]	Linf: [0.72156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=10.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=11.8%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.8%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=21.2%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=41.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.9% (timestep 4)
Min contribution: 10.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 979 pred_label: 979 pred_clean_logit 0.5543986558914185
prompt generate:  valley  	labels:  [[979]]
decoder:  [49406, 3136, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([978], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([979], device='cuda:0') tensor(1.0648e-13, device='cuda:0')
L1: [11731.0625]	L2: [44.22767]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=56.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.5% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 887 pred_label: 467 pred_clean_logit 0.4689154028892517
prompt generate:  vestment  	labels:  [[467]]
decoder:  [49406, 31657, 777, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([564], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([887], device='cuda:0') tensor(3.1904e-16, device='cuda:0')
L1: [9914.918]	L2: [36.615307]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=56.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.5% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 959 pred_label: 959 pred_clean_logit 0.9998939037322998
prompt generate:  carbonara  	labels:  [[959]]
decoder:  [49406, 14038, 3340, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([959], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([959], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [3859.9375]	L2: [13.768289]	Linf: [0.3882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.7%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 883 pred_label: 883 pred_clean_logit 0.9997400641441345
prompt generate:  vase  	labels:  [[883]]
decoder:  [49406, 20431, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([725], device='cuda:0') tensor(0.9931, device='cuda:0')
after_true: tensor([883], device='cuda:0') tensor(9.2706e-16, device='cuda:0')
L1: [6733.259]	L2: [30.673388]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 853 pred_label: 637 pred_clean_logit 0.0015737286303192377
prompt generate:  thatch  	labels:  [[637]]
decoder:  [49406, 6303, 634, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([637], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([853], device='cuda:0') tensor(1.1422e-21, device='cuda:0')
L1: [7957.486]	L2: [31.739876]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 309 pred_label: 309 pred_clean_logit 0.9987236857414246
prompt generate:  bee  	labels:  [[309]]
decoder:  [49406, 5028, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([310], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([309], device='cuda:0') tensor(1.9445e-29, device='cuda:0')
L1: [8928.509]	L2: [34.05654]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=13.4%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.7%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 892 pred_label: 892 pred_clean_logit 0.7424347996711731
prompt generate:  wall clock  	labels:  [[892]]
decoder:  [49406, 2569, 6716, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([409], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([892], device='cuda:0') tensor(2.0857e-15, device='cuda:0')
L1: [10296.921]	L2: [39.028736]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 519 pred_label: 519 pred_clean_logit 0.6149552464485168
prompt generate:  crate  	labels:  [[519]]
decoder:  [49406, 24756, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([542], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([519], device='cuda:0') tensor(2.6569e-28, device='cuda:0')
L1: [12012.746]	L2: [44.265488]	Linf: [0.92941177]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.3%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=48.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.3% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 475 pred_label: 475 pred_clean_logit 0.9999945163726807
prompt generate:  car mirror  	labels:  [[475]]
decoder:  [49406, 1615, 7220, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([475], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([475], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [3245.0674]	L2: [19.838457]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.3%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.4%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=56.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.5% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 562 pred_label: 562 pred_clean_logit 0.997365415096283
prompt generate:  fountain  	labels:  [[562]]
decoder:  [49406, 13405, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([819], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([562], device='cuda:0') tensor(1.6215e-16, device='cuda:0')
L1: [5529.4985]	L2: [26.163698]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 557 pred_label: 557 pred_clean_logit 0.9954534769058228
prompt generate:  flagpole  	labels:  [[557]]
decoder:  [49406, 11536, 8170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([842], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([557], device='cuda:0') tensor(8.3183e-23, device='cuda:0')
L1: [7696.2554]	L2: [32.03058]	Linf: [0.6509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=48.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.5% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 983 pred_label: 983 pred_clean_logit 0.9998177886009216
prompt generate:  scuba diver  	labels:  [[983]]
decoder:  [49406, 20559, 22094, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([701], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([983], device='cuda:0') tensor(1.7159e-13, device='cuda:0')
L1: [3360.9136]	L2: [15.793644]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=48.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.7% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 672 pred_label: 672 pred_clean_logit 0.2929824888706207
prompt generate:  mountain tent  	labels:  [[672]]
decoder:  [49406, 3965, 10782, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([432], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([672], device='cuda:0') tensor(6.4264e-25, device='cuda:0')
L1: [9211.792]	L2: [34.123455]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.5%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 437 pred_label: 437 pred_clean_logit 0.9999972581863403
prompt generate:  beacon  	labels:  [[437]]
decoder:  [49406, 18858, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([437], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([437], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5515.1494]	L2: [24.818583]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 129 pred_label: 129 pred_clean_logit 0.9479572176933289
prompt generate:  spoonbill  	labels:  [[129]]
decoder:  [49406, 27001, 2886, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([127], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([129], device='cuda:0') tensor(8.8478e-11, device='cuda:0')
L1: [2660.835]	L2: [11.723061]	Linf: [0.5882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=10.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=12.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.7%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.2%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=39.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 39.8% (timestep 4)
Min contribution: 10.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 928 pred_label: 928 pred_clean_logit 0.9999995231628418
prompt generate:  ice cream  	labels:  [[928]]
decoder:  [49406, 733, 3867, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([931], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([928], device='cuda:0') tensor(5.8736e-22, device='cuda:0')
L1: [8849.895]	L2: [36.465336]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 637 pred_label: 637 pred_clean_logit 0.9999969005584717
prompt generate:  mailbox  	labels:  [[637]]
decoder:  [49406, 31482, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([637], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([637], device='cuda:0') tensor(1., device='cuda:0')
L1: [6903.161]	L2: [26.612011]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 467 pred_label: 467 pred_clean_logit 0.9997115731239319
prompt generate:  butcher shop  	labels:  [[467]]
decoder:  [49406, 18732, 1557, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([991], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([467], device='cuda:0') tensor(2.0423e-13, device='cuda:0')
L1: [10435.643]	L2: [36.919533]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 708 pred_label: 708 pred_clean_logit 0.831640899181366
prompt generate:  pedestal  	labels:  [[708]]
decoder:  [49406, 12862, 5535, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([501], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([708], device='cuda:0') tensor(6.0872e-18, device='cuda:0')
L1: [12955.198]	L2: [46.769043]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 858 pred_label: 858 pred_clean_logit 0.9998800754547119
prompt generate:  tile roof  	labels:  [[858]]
decoder:  [49406, 8227, 6449, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([858], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([858], device='cuda:0') tensor(0.9997, device='cuda:0')
L1: [7887.619]	L2: [35.157562]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.5%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.9%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=48.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.3% (timestep 4)
Min contribution: 6.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 628 pred_label: 628 pred_clean_logit 0.9996746778488159
prompt generate:  liner  	labels:  [[628]]
decoder:  [49406, 11618, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([802], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([628], device='cuda:0') tensor(4.8496e-12, device='cuda:0')
L1: [6633.396]	L2: [28.59484]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 582 pred_label: 454 pred_clean_logit 8.045460708672181e-05
prompt generate:  grocery store  	labels:  [[454]]
decoder:  [49406, 13826, 2183, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([454], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([582], device='cuda:0') tensor(1.4781e-21, device='cuda:0')
L1: [9864.342]	L2: [39.48327]	Linf: [0.9137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 157 pred_label: 157 pred_clean_logit 0.999943733215332
prompt generate:  papillon  	labels:  [[157]]
decoder:  [49406, 1884, 20516, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([157], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([157], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7178.1377]	L2: [25.825047]	Linf: [0.61960787]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.6%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=25.2%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 51 pred_label: 71 pred_clean_logit 0.005267221014946699
prompt generate:  triceratops  	labels:  [[71]]
decoder:  [49406, 9511, 517, 527, 3054, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([679], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([51], device='cuda:0') tensor(6.3327e-18, device='cuda:0')
L1: [6570.9336]	L2: [30.522331]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 984 pred_label: 738 pred_clean_logit 0.042999766767024994
prompt generate:  rapeseed  	labels:  [[738]]
decoder:  [49406, 46099, 6488, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([193], device='cuda:0') tensor(0.9675, device='cuda:0')
after_true: tensor([984], device='cuda:0') tensor(6.7956e-16, device='cuda:0')
L1: [13362.572]	L2: [47.89755]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 104 pred_label: 104 pred_clean_logit 0.9999794960021973
prompt generate:  wallaby  	labels:  [[104]]
decoder:  [49406, 26007, 638, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([104], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([104], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [10622.129]	L2: [38.19165]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=26.7%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=49.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.3% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 441 pred_label: 441 pred_clean_logit 0.9975653886795044
prompt generate:  beer glass  	labels:  [[441]]
decoder:  [49406, 2544, 3313, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([960], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([441], device='cuda:0') tensor(6.8641e-13, device='cuda:0')
L1: [3943.9297]	L2: [15.546022]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 595 pred_label: 595 pred_clean_logit 0.4554327130317688
prompt generate:  harvester  	labels:  [[595]]
decoder:  [49406, 6405, 881, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([958], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([595], device='cuda:0') tensor(1.3395e-15, device='cuda:0')
L1: [4538.1104]	L2: [18.220942]	Linf: [0.52549016]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 946 pred_label: 946 pred_clean_logit 0.6491648554801941
prompt generate:  cardoon  	labels:  [[946]]
decoder:  [49406, 811, 36612, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([309], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([946], device='cuda:0') tensor(1.5661e-12, device='cuda:0')
L1: [5802.2314]	L2: [26.678997]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.2%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=59.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.8% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 521 pred_label: 521 pred_clean_logit 0.7522128224372864
prompt generate:  Crock Pot  	labels:  [[521]]
decoder:  [49406, 1192, 868, 5168, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([886], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([521], device='cuda:0') tensor(2.3641e-15, device='cuda:0')
L1: [9849.3955]	L2: [39.020973]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=43.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.4% (timestep 4)
Min contribution: 6.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 545 pred_label: 545 pred_clean_logit 0.9995294809341431
prompt generate:  electric fan  	labels:  [[545]]
decoder:  [49406, 5031, 2261, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([813], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([545], device='cuda:0') tensor(2.9889e-24, device='cuda:0')
L1: [5316.8984]	L2: [22.49616]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=24.4%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 946 pred_label: 946 pred_clean_logit 0.5040475726127625
prompt generate:  cardoon  	labels:  [[946]]
decoder:  [49406, 811, 36612, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([990], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([946], device='cuda:0') tensor(3.2081e-13, device='cuda:0')
L1: [12299.589]	L2: [44.204464]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=28.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=49.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.8% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 579 pred_label: 579 pred_clean_logit 0.9906195402145386
prompt generate:  grand piano  	labels:  [[579]]
decoder:  [49406, 2991, 7894, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([513], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([579], device='cuda:0') tensor(2.8089e-17, device='cuda:0')
L1: [4220.1846]	L2: [22.24914]	Linf: [0.93333334]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=27.0%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 863 pred_label: 863 pred_clean_logit 0.9999995231628418
prompt generate:  totem pole  	labels:  [[863]]
decoder:  [49406, 45376, 8170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([863], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([863], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6563.8003]	L2: [25.965158]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 10 pred_label: 10 pred_clean_logit 0.869558572769165
prompt generate:  brambling  	labels:  [[10]]
decoder:  [49406, 14815, 7097, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([12], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([10], device='cuda:0') tensor(2.9704e-11, device='cuda:0')
L1: [2946.1648]	L2: [12.79745]	Linf: [0.50196075]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 455 pred_label: 455 pred_clean_logit 0.9291567206382751
prompt generate:  bottlecap  	labels:  [[455]]
decoder:  [49406, 37306, 3938, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([737], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([455], device='cuda:0') tensor(6.8963e-08, device='cuda:0')
L1: [5071.274]	L2: [20.227112]	Linf: [0.69803923]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=9.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=11.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=16.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=39.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 39.5% (timestep 4)
Min contribution: 9.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 433 pred_label: 433 pred_clean_logit 0.9999960660934448
prompt generate:  bathing cap  	labels:  [[433]]
decoder:  [49406, 20144, 3938, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([433], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([433], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6204.4585]	L2: [24.945078]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.4%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.5%
Timestep  4: Avg Loss=0.000002, Std=0.000000, Contribution=43.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.8% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 455 pred_label: 539 pred_clean_logit 0.009060190990567207
prompt generate:  bottlecap  	labels:  [[539]]
decoder:  [49406, 37306, 3938, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([539], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([455], device='cuda:0') tensor(3.2708e-15, device='cuda:0')
L1: [12707.895]	L2: [43.539787]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 480 pred_label: 894 pred_clean_logit 0.03261096403002739
prompt generate:  cash machine  	labels:  [[894]]
decoder:  [49406, 5131, 4169, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([894], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([480], device='cuda:0') tensor(1.0776e-19, device='cuda:0')
L1: [4326.4077]	L2: [19.690378]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 912 pred_label: 912 pred_clean_logit 0.7802910804748535
prompt generate:  worm fence  	labels:  [[912]]
decoder:  [49406, 10945, 12679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([888], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([912], device='cuda:0') tensor(2.6203e-12, device='cuda:0')
L1: [5849.6357]	L2: [23.963968]	Linf: [0.5647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.1%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 908 pred_label: 908 pred_clean_logit 0.999836802482605
prompt generate:  wing  	labels:  [[908]]
decoder:  [49406, 1340, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([672], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([908], device='cuda:0') tensor(5.5569e-14, device='cuda:0')
L1: [3391.7256]	L2: [18.029493]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 348 pred_label: 348 pred_clean_logit 0.7650612592697144
prompt generate:  ram  	labels:  [[348]]
decoder:  [49406, 2007, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([169], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([348], device='cuda:0') tensor(6.9799e-23, device='cuda:0')
L1: [6221.3057]	L2: [22.341368]	Linf: [0.5568628]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=57.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.5% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 717 pred_label: 864 pred_clean_logit 0.006904053967446089
prompt generate:  pickup  	labels:  [[864]]
decoder:  [49406, 15382, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([864], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([717], device='cuda:0') tensor(4.1284e-16, device='cuda:0')
L1: [8931.013]	L2: [35.525307]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 470 pred_label: 572 pred_clean_logit 0.23213282227516174
prompt generate:  candle  	labels:  [[572]]
decoder:  [49406, 12674, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([519], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([470], device='cuda:0') tensor(5.6357e-17, device='cuda:0')
L1: [4692.083]	L2: [19.364176]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.9%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=58.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.2% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 874 pred_label: 829 pred_clean_logit 0.4045528769493103
prompt generate:  trolleybus  	labels:  [[829]]
decoder:  [49406, 10306, 2565, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([829], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([874], device='cuda:0') tensor(2.3795e-12, device='cuda:0')
L1: [7538.9883]	L2: [28.226545]	Linf: [0.6352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 884 pred_label: 884 pred_clean_logit 0.9595195055007935
prompt generate:  vault  	labels:  [[884]]
decoder:  [49406, 15240, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([663], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([884], device='cuda:0') tensor(2.4829e-13, device='cuda:0')
L1: [4983.5054]	L2: [20.228792]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 718 pred_label: 718 pred_clean_logit 0.9708712100982666
prompt generate:  pier  	labels:  [[718]]
decoder:  [49406, 11348, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([421], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([718], device='cuda:0') tensor(4.7623e-12, device='cuda:0')
L1: [6019.5176]	L2: [23.40597]	Linf: [0.5803921]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=25.4%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 964 pred_label: 964 pred_clean_logit 0.933420717716217
prompt generate:  potpie  	labels:  [[964]]
decoder:  [49406, 3547, 5319, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([923], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([964], device='cuda:0') tensor(1.3851e-10, device='cuda:0')
L1: [6487.3765]	L2: [27.800898]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 847 pred_label: 847 pred_clean_logit 0.9970357418060303
prompt generate:  tank  	labels:  [[847]]
decoder:  [49406, 6172, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([575], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([847], device='cuda:0') tensor(1.2940e-25, device='cuda:0')
L1: [10329.776]	L2: [37.826828]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=49.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.4% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 438 pred_label: 438 pred_clean_logit 0.8910071849822998
prompt generate:  beaker  	labels:  [[438]]
decoder:  [49406, 571, 3074, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([470], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([438], device='cuda:0') tensor(8.8337e-29, device='cuda:0')
L1: [3788.9175]	L2: [13.929319]	Linf: [0.5333333]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=22.3%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=59.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.8% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 981 pred_label: 981 pred_clean_logit 0.8941978812217712
prompt generate:  ballplayer  	labels:  [[981]]
decoder:  [49406, 3807, 2477, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([430], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([981], device='cuda:0') tensor(1.5834e-19, device='cuda:0')
L1: [12612.699]	L2: [47.217857]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 571 pred_label: 571 pred_clean_logit 0.9945797920227051
prompt generate:  gas pump  	labels:  [[571]]
decoder:  [49406, 2474, 9173, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([875], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([571], device='cuda:0') tensor(9.5867e-17, device='cuda:0')
L1: [5677.6704]	L2: [24.16749]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=2.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.1%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=24.3%
Timestep  4: Avg Loss=0.000016, Std=0.000006, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 792 pred_label: 792 pred_clean_logit 0.9997056126594543
prompt generate:  shovel  	labels:  [[792]]
decoder:  [49406, 31778, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([693], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([792], device='cuda:0') tensor(9.2459e-19, device='cuda:0')
L1: [7750.3096]	L2: [31.507961]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 874 pred_label: 874 pred_clean_logit 0.9790008664131165
prompt generate:  trolleybus  	labels:  [[874]]
decoder:  [49406, 10306, 2565, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([829], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([874], device='cuda:0') tensor(6.1580e-12, device='cuda:0')
L1: [10071.972]	L2: [41.494602]	Linf: [0.8666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=49.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.3% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 594 pred_label: 594 pred_clean_logit 0.8813446760177612
prompt generate:  harp  	labels:  [[594]]
decoder:  [49406, 27339, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([733], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([594], device='cuda:0') tensor(3.6451e-31, device='cuda:0')
L1: [8236.678]	L2: [36.09281]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 474 pred_label: 474 pred_clean_logit 0.9996787309646606
prompt generate:  cardigan  	labels:  [[474]]
decoder:  [49406, 30501, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([850], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([474], device='cuda:0') tensor(8.8081e-19, device='cuda:0')
L1: [4828.926]	L2: [18.120123]	Linf: [0.5686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 774 pred_label: 502 pred_clean_logit 0.05453459173440933
prompt generate:  sandal  	labels:  [[502]]
decoder:  [49406, 42185, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([808], device='cuda:0') tensor(0.9803, device='cuda:0')
after_true: tensor([774], device='cuda:0') tensor(1.0979e-10, device='cuda:0')
L1: [3499.8003]	L2: [20.746927]	Linf: [0.73725486]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=57.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.5% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 628 pred_label: 554 pred_clean_logit 0.035375095903873444
prompt generate:  liner  	labels:  [[554]]
decoder:  [49406, 11618, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([428], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([628], device='cuda:0') tensor(5.3363e-25, device='cuda:0')
L1: [5314.8037]	L2: [23.092682]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 671 pred_label: 671 pred_clean_logit 0.9966298937797546
prompt generate:  mountain bike  	labels:  [[671]]
decoder:  [49406, 3965, 3701, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([535], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([671], device='cuda:0') tensor(2.0413e-10, device='cuda:0')
L1: [9029.647]	L2: [36.978443]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 701 pred_label: 417 pred_clean_logit 0.04713284224271774
prompt generate:  parachute  	labels:  [[417]]
decoder:  [49406, 30122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([435], device='cuda:0') tensor(0.5065, device='cuda:0')
after_true: tensor([701], device='cuda:0') tensor(1.6370e-16, device='cuda:0')
L1: [3479.6467]	L2: [13.801174]	Linf: [0.6]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000018, Std=0.000004, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 78 pred_label: 78 pred_clean_logit 0.9999704360961914
prompt generate:  tick  	labels:  [[78]]
decoder:  [49406, 15617, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([943], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([78], device='cuda:0') tensor(1.4452e-22, device='cuda:0')
L1: [3945.7644]	L2: [20.552814]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=22.8%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 946 pred_label: 946 pred_clean_logit 0.9991173148155212
prompt generate:  cardoon  	labels:  [[946]]
decoder:  [49406, 811, 36612, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([11], device='cuda:0') tensor(0.9995, device='cuda:0')
after_true: tensor([946], device='cuda:0') tensor(8.7594e-09, device='cuda:0')
L1: [6599.3774]	L2: [24.873571]	Linf: [0.6862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 476 pred_label: 476 pred_clean_logit 0.9999852180480957
prompt generate:  carousel  	labels:  [[476]]
decoder:  [49406, 36665, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([476], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([476], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7234.3213]	L2: [28.916428]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.3%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.6%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=46.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.6% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 974 pred_label: 974 pred_clean_logit 0.9999861717224121
prompt generate:  geyser  	labels:  [[974]]
decoder:  [49406, 619, 33121, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([978], device='cuda:0') tensor(0.9987, device='cuda:0')
after_true: tensor([974], device='cuda:0') tensor(2.3861e-08, device='cuda:0')
L1: [2835.306]	L2: [11.384266]	Linf: [0.47058827]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.0%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=20.4%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=61.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 61.7% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 820 pred_label: 820 pred_clean_logit 0.9997772574424744
prompt generate:  steam locomotive  	labels:  [[820]]
decoder:  [49406, 6972, 30439, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([570], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([820], device='cuda:0') tensor(2.6003e-20, device='cuda:0')
L1: [11035.49]	L2: [46.11819]	Linf: [0.9647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 311 pred_label: 311 pred_clean_logit 0.43653836846351624
prompt generate:  grasshopper  	labels:  [[311]]
decoder:  [49406, 48894, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([312], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([311], device='cuda:0') tensor(1.0515e-19, device='cuda:0')
L1: [11335.35]	L2: [42.39718]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.2% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 963 pred_label: 963 pred_clean_logit 0.9992153644561768
prompt generate:  pizza  	labels:  [[963]]
decoder:  [49406, 4474, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([938], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([963], device='cuda:0') tensor(1.3906e-20, device='cuda:0')
L1: [9912.095]	L2: [35.61979]	Linf: [0.6509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.6%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 936 pred_label: 936 pred_clean_logit 0.9740093946456909
prompt generate:  head cabbage  	labels:  [[936]]
decoder:  [49406, 1375, 18407, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([938], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([936], device='cuda:0') tensor(1.5022e-20, device='cuda:0')
L1: [8699.199]	L2: [31.337713]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 634 pred_label: 988 pred_clean_logit 0.0007151016616262496
prompt generate:  lumbermill  	labels:  [[988]]
decoder:  [49406, 27421, 6637, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([907], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([634], device='cuda:0') tensor(3.0253e-18, device='cuda:0')
L1: [12262.847]	L2: [45.095993]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.8%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 427 pred_label: 427 pred_clean_logit 0.9977086782455444
prompt generate:  barrel  	labels:  [[427]]
decoder:  [49406, 11703, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([778], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([427], device='cuda:0') tensor(1.0661e-26, device='cuda:0')
L1: [7919.9062]	L2: [28.163708]	Linf: [0.5803922]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=42.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.8% (timestep 4)
Min contribution: 7.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 57 pred_label: 57 pred_clean_logit 0.9999655485153198
prompt generate:  garter snake  	labels:  [[57]]
decoder:  [49406, 48420, 8798, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([53], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([57], device='cuda:0') tensor(2.1323e-15, device='cuda:0')
L1: [9304.102]	L2: [36.821095]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 326 pred_label: 326 pred_clean_logit 0.9999710321426392
prompt generate:  lycaenid  	labels:  [[326]]
decoder:  [49406, 1251, 772, 524, 1014, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([322], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([326], device='cuda:0') tensor(5.7347e-09, device='cuda:0')
L1: [5074.894]	L2: [21.83233]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=57.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.0% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 344 pred_label: 341 pred_clean_logit 0.0008602612651884556
prompt generate:  hippopotamus  	labels:  [[341]]
decoder:  [49406, 28398, 45825, 718, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([348], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([344], device='cuda:0') tensor(1.8400e-23, device='cuda:0')
L1: [10012.554]	L2: [41.84763]	Linf: [0.93333334]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 963 pred_label: 963 pred_clean_logit 0.9999651908874512
prompt generate:  pizza  	labels:  [[963]]
decoder:  [49406, 4474, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([964], device='cuda:0') tensor(0.9212, device='cuda:0')
after_true: tensor([963], device='cuda:0') tensor(0.0735, device='cuda:0')
L1: [9885.479]	L2: [34.597057]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.6%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 825 pred_label: 509 pred_clean_logit 0.10708857327699661
prompt generate:  stone wall  	labels:  [[509]]
decoder:  [49406, 2441, 2569, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([509], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([825], device='cuda:0') tensor(4.8008e-20, device='cuda:0')
L1: [13243.031]	L2: [48.686012]	Linf: [0.99607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=13.3%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.5%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 606 pred_label: 606 pred_clean_logit 1.0
prompt generate:  iron  	labels:  [[606]]
decoder:  [49406, 5391, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([606], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([606], device='cuda:0') tensor(1., device='cuda:0')
L1: [2782.2083]	L2: [10.625026]	Linf: [0.48235297]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 765 pred_label: 765 pred_clean_logit 0.9987296462059021
prompt generate:  rocking chair  	labels:  [[765]]
decoder:  [49406, 7081, 4269, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([494], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([765], device='cuda:0') tensor(2.0821e-19, device='cuda:0')
L1: [7216.1025]	L2: [26.238026]	Linf: [0.69803923]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=47.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.6% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 659 pred_label: 659 pred_clean_logit 0.9954628348350525
prompt generate:  mixing bowl  	labels:  [[659]]
decoder:  [49406, 15588, 3814, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([828], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([659], device='cuda:0') tensor(3.7130e-32, device='cuda:0')
L1: [5009.322]	L2: [20.538519]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 478 pred_label: 478 pred_clean_logit 0.999727189540863
prompt generate:  carton  	labels:  [[478]]
decoder:  [49406, 41812, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([553], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([478], device='cuda:0') tensor(1.5544e-12, device='cuda:0')
L1: [3364.7688]	L2: [14.189969]	Linf: [0.5529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.5% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 688 pred_label: 688 pred_clean_logit 0.9979168772697449
prompt generate:  oscilloscope  	labels:  [[688]]
decoder:  [49406, 5092, 34153, 7979, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([848], device='cuda:0') tensor(0.9894, device='cuda:0')
after_true: tensor([688], device='cuda:0') tensor(9.1652e-14, device='cuda:0')
L1: [7710.6904]	L2: [29.861097]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=13.5%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=26.3%
Timestep  4: Avg Loss=0.000017, Std=0.000006, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 416 pred_label: 416 pred_clean_logit 0.9742431640625
prompt generate:  balance beam  	labels:  [[416]]
decoder:  [49406, 6827, 13663, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([702], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([416], device='cuda:0') tensor(1.0315e-15, device='cuda:0')
L1: [3480.7417]	L2: [13.000978]	Linf: [0.27058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 547 pred_label: 829 pred_clean_logit 0.21895265579223633
prompt generate:  electric locomotive  	labels:  [[829]]
decoder:  [49406, 5031, 30439, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([517], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([547], device='cuda:0') tensor(2.4566e-13, device='cuda:0')
L1: [6798.7646]	L2: [29.008184]	Linf: [0.7294117]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000010, Std=0.000002, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 708 pred_label: 708 pred_clean_logit 0.542822003364563
prompt generate:  pedestal  	labels:  [[708]]
decoder:  [49406, 12862, 5535, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([869], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([708], device='cuda:0') tensor(1.7731e-18, device='cuda:0')
L1: [4823.5186]	L2: [21.97413]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.7%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 557 pred_label: 557 pred_clean_logit 0.11254476755857468
prompt generate:  flagpole  	labels:  [[557]]
decoder:  [49406, 11536, 8170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([644], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([557], device='cuda:0') tensor(8.6915e-15, device='cuda:0')
L1: [9376.188]	L2: [37.284637]	Linf: [0.8156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 306 pred_label: 306 pred_clean_logit 0.999995231628418
prompt generate:  rhinoceros beetle  	labels:  [[306]]
decoder:  [49406, 41744, 1364, 1299, 16534, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([306], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([306], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [11986.534]	L2: [41.837948]	Linf: [0.5568627]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.2%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 993 pred_label: 85 pred_clean_logit 0.006713635288178921
prompt generate:  gyromitra  	labels:  [[85]]
decoder:  [49406, 2168, 532, 47703, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([136], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([993], device='cuda:0') tensor(9.5108e-20, device='cuda:0')
L1: [8696.25]	L2: [31.189552]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=27.1%
Timestep  4: Avg Loss=0.000019, Std=0.000005, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 933 pred_label: 933 pred_clean_logit 0.9009082317352295
prompt generate:  cheeseburger  	labels:  [[933]]
decoder:  [49406, 41200, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([928], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([933], device='cuda:0') tensor(4.7367e-24, device='cuda:0')
L1: [6867.318]	L2: [25.569445]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=57.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.2% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 547 pred_label: 705 pred_clean_logit 0.4370601773262024
prompt generate:  electric locomotive  	labels:  [[705]]
decoder:  [49406, 5031, 30439, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([829], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([547], device='cuda:0') tensor(3.9667e-13, device='cuda:0')
L1: [9456.687]	L2: [33.73098]	Linf: [0.654902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=58.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.0% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 989 pred_label: 580 pred_clean_logit 0.09420613199472427
prompt generate:  hip  	labels:  [[580]]
decoder:  [49406, 6584, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([580], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([989], device='cuda:0') tensor(6.6110e-13, device='cuda:0')
L1: [11829.3125]	L2: [39.357708]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 707 pred_label: 707 pred_clean_logit 0.9999905824661255
prompt generate:  pay-phone  	labels:  [[707]]
decoder:  [49406, 3345, 268, 1951, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([707], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([707], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [10384.055]	L2: [39.26555]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=49.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.8% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 819 pred_label: 819 pred_clean_logit 0.9754495024681091
prompt generate:  stage  	labels:  [[819]]
decoder:  [49406, 2170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([818], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([819], device='cuda:0') tensor(5.4646e-19, device='cuda:0')
L1: [4167.2515]	L2: [18.500763]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 764 pred_label: 764 pred_clean_logit 0.9997236132621765
prompt generate:  rifle  	labels:  [[764]]
decoder:  [49406, 15354, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([845], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([764], device='cuda:0') tensor(3.6564e-24, device='cuda:0')
L1: [10564.766]	L2: [37.338894]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 779 pred_label: 779 pred_clean_logit 0.9999974966049194
prompt generate:  school bus  	labels:  [[779]]
decoder:  [49406, 1228, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([779], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([779], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6141.3335]	L2: [26.608671]	Linf: [0.73725486]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=7.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.4%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=16.0%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=24.3%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=41.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.5% (timestep 4)
Min contribution: 7.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 682 pred_label: 682 pred_clean_logit 0.9999992847442627
prompt generate:  obelisk  	labels:  [[682]]
decoder:  [49406, 78, 1308, 30171, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([682], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([682], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6674.118]	L2: [27.666046]	Linf: [0.5960784]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000006, Std=0.000001, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 734 pred_label: 734 pred_clean_logit 0.9999998807907104
prompt generate:  police van  	labels:  [[734]]
decoder:  [49406, 2120, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5906.9253]	L2: [25.648535]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=9.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.8%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.6%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=22.1%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=43.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.4% (timestep 4)
Min contribution: 9.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 400 pred_label: 400 pred_clean_logit 0.6669585704803467
prompt generate:  academic gown  	labels:  [[400]]
decoder:  [49406, 7935, 13719, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([971], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([400], device='cuda:0') tensor(0., device='cuda:0')
L1: [11931.572]	L2: [44.79355]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=49.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.8% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 975 pred_label: 975 pred_clean_logit 0.9854990243911743
prompt generate:  lakeside  	labels:  [[975]]
decoder:  [49406, 30915, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([975], device='cuda:0') tensor(6.1561e-18, device='cuda:0')
L1: [8576.412]	L2: [35.509533]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.4%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 716 pred_label: 716 pred_clean_logit 0.9981945157051086
prompt generate:  picket fence  	labels:  [[716]]
decoder:  [49406, 33559, 12679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([660], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([716], device='cuda:0') tensor(6.6723e-13, device='cuda:0')
L1: [5754.2314]	L2: [22.292006]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=2.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=13.0%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=25.2%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 964 pred_label: 947 pred_clean_logit 0.0005876452778466046
prompt generate:  potpie  	labels:  [[947]]
decoder:  [49406, 3547, 5319, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([992], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([964], device='cuda:0') tensor(3.6937e-17, device='cuda:0')
L1: [7701.498]	L2: [30.146624]	Linf: [0.5686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 51 pred_label: 51 pred_clean_logit 0.9858158826828003
prompt generate:  triceratops  	labels:  [[51]]
decoder:  [49406, 9511, 517, 527, 3054, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([121], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([51], device='cuda:0') tensor(3.3351e-25, device='cuda:0')
L1: [6776.7285]	L2: [24.12795]	Linf: [0.43137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000017, Std=0.000004, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 654 pred_label: 654 pred_clean_logit 0.7588973641395569
prompt generate:  minibus  	labels:  [[654]]
decoder:  [49406, 1810, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([757], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([654], device='cuda:0') tensor(3.3312e-16, device='cuda:0')
L1: [5826.0205]	L2: [25.187027]	Linf: [0.8784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 718 pred_label: 718 pred_clean_logit 0.8809352517127991
prompt generate:  pier  	labels:  [[718]]
decoder:  [49406, 11348, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([888], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([718], device='cuda:0') tensor(5.6026e-12, device='cuda:0')
L1: [7562.7803]	L2: [36.609615]	Linf: [0.9372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 908 pred_label: 895 pred_clean_logit 0.2961992621421814
prompt generate:  wing  	labels:  [[895]]
decoder:  [49406, 1340, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([744], device='cuda:0') tensor(0.9446, device='cuda:0')
after_true: tensor([908], device='cuda:0') tensor(4.7410e-20, device='cuda:0')
L1: [3627.5571]	L2: [13.510942]	Linf: [0.58431375]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 132 pred_label: 132 pred_clean_logit 0.996842622756958
prompt generate:  American egret  	labels:  [[132]]
decoder:  [49406, 2151, 42002, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([134], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([132], device='cuda:0') tensor(3.1041e-08, device='cuda:0')
L1: [11281.647]	L2: [38.682747]	Linf: [0.61176467]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.0%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=48.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.2% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 557 pred_label: 21 pred_clean_logit 0.003174524288624525
prompt generate:  flagpole  	labels:  [[21]]
decoder:  [49406, 11536, 8170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([18], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([557], device='cuda:0') tensor(7.4406e-12, device='cuda:0')
L1: [2008.3141]	L2: [10.071953]	Linf: [0.5137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=15.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=46.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.3% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 407 pred_label: 734 pred_clean_logit 0.46636343002319336
prompt generate:  ambulance  	labels:  [[734]]
decoder:  [49406, 15555, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([734], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([407], device='cuda:0') tensor(3.3780e-17, device='cuda:0')
L1: [9098.173]	L2: [36.956482]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=10.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=43.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.5% (timestep 4)
Min contribution: 6.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 304 pred_label: 304 pred_clean_logit 0.8008992671966553
prompt generate:  leaf beetle  	labels:  [[304]]
decoder:  [49406, 7232, 16534, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([78], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([304], device='cuda:0') tensor(1.2345e-13, device='cuda:0')
L1: [3834.9058]	L2: [14.304287]	Linf: [0.5529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=22.7%
Timestep  4: Avg Loss=0.000014, Std=0.000003, Contribution=58.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.3% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 99 pred_label: 99 pred_clean_logit 0.9999939203262329
prompt generate:  goose  	labels:  [[99]]
decoder:  [49406, 13822, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([99], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([99], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [9665.868]	L2: [33.216175]	Linf: [0.58823526]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=54.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.5% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 640 pred_label: 640 pred_clean_logit 0.9696990847587585
prompt generate:  manhole cover  	labels:  [[640]]
decoder:  [49406, 723, 5341, 2202, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([891], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([640], device='cuda:0') tensor(1.3658e-10, device='cuda:0')
L1: [8128.031]	L2: [29.229252]	Linf: [0.60392153]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 854 pred_label: 854 pred_clean_logit 0.9992066025733948
prompt generate:  theater curtain  	labels:  [[854]]
decoder:  [49406, 6128, 17223, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([498], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([854], device='cuda:0') tensor(1.1816e-07, device='cuda:0')
L1: [7542.0273]	L2: [30.180294]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 933 pred_label: 933 pred_clean_logit 0.9998596906661987
prompt generate:  cheeseburger  	labels:  [[933]]
decoder:  [49406, 41200, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([931], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([933], device='cuda:0') tensor(1.6508e-14, device='cuda:0')
L1: [5678.228]	L2: [21.225172]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=11.9%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=25.4%
Timestep  4: Avg Loss=0.000012, Std=0.000006, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 979 pred_label: 979 pred_clean_logit 0.9906948804855347
prompt generate:  valley  	labels:  [[979]]
decoder:  [49406, 3136, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([14], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([979], device='cuda:0') tensor(4.4341e-28, device='cuda:0')
L1: [8703.82]	L2: [29.411602]	Linf: [0.54901963]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=60.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.0% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 440 pred_label: 440 pred_clean_logit 0.9918220639228821
prompt generate:  beer bottle  	labels:  [[440]]
decoder:  [49406, 2544, 5392, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([720], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([440], device='cuda:0') tensor(8.8794e-21, device='cuda:0')
L1: [4837.1836]	L2: [19.835564]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=12.9%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=24.3%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 436 pred_label: 654 pred_clean_logit 0.01740903966128826
prompt generate:  beach wagon  	labels:  [[654]]
decoder:  [49406, 2117, 13260, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([654], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([436], device='cuda:0') tensor(1.0108e-20, device='cuda:0')
L1: [7803.6006]	L2: [30.707048]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 489 pred_label: 489 pred_clean_logit 0.9999967813491821
prompt generate:  chainlink fence  	labels:  [[489]]
decoder:  [49406, 13898, 2468, 12679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([489], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([489], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3016.7964]	L2: [15.042745]	Linf: [0.71372545]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=10.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=12.3%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=16.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.7%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=39.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 39.2% (timestep 4)
Min contribution: 10.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 317 pred_label: 317 pred_clean_logit 0.9617642760276794
prompt generate:  leafhopper  	labels:  [[317]]
decoder:  [49406, 9377, 21748, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([316], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([317], device='cuda:0') tensor(1.5569e-14, device='cuda:0')
L1: [3947.671]	L2: [18.282347]	Linf: [0.92156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 887 pred_label: 887 pred_clean_logit 0.9733553528785706
prompt generate:  vestment  	labels:  [[887]]
decoder:  [49406, 31657, 777, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([617], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([887], device='cuda:0') tensor(4.5272e-24, device='cuda:0')
L1: [7515.7134]	L2: [31.362034]	Linf: [0.90588236]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 829 pred_label: 829 pred_clean_logit 0.6343441605567932
prompt generate:  streetcar  	labels:  [[829]]
decoder:  [49406, 34268, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([547], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([829], device='cuda:0') tensor(2.6997e-13, device='cuda:0')
L1: [7961.702]	L2: [35.632717]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=48.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.1% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 340 pred_label: 340 pred_clean_logit 0.9999840259552002
prompt generate:  zebra  	labels:  [[340]]
decoder:  [49406, 22548, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([340], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([340], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [10340.914]	L2: [37.489807]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.4%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 94 pred_label: 94 pred_clean_logit 0.9999806880950928
prompt generate:  hummingbird  	labels:  [[94]]
decoder:  [49406, 33072, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([94], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([94], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3714.8943]	L2: [16.403645]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.8%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=13.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.3%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=49.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.2% (timestep 4)
Min contribution: 6.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 887 pred_label: 887 pred_clean_logit 0.9998829364776611
prompt generate:  vestment  	labels:  [[887]]
decoder:  [49406, 31657, 777, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([981], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([887], device='cuda:0') tensor(2.5426e-14, device='cuda:0')
L1: [7593.9688]	L2: [31.891663]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000010, Std=0.000005, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 562 pred_label: 562 pred_clean_logit 0.9986673593521118
prompt generate:  fountain  	labels:  [[562]]
decoder:  [49406, 13405, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([521], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([562], device='cuda:0') tensor(4.2112e-28, device='cuda:0')
L1: [11191.768]	L2: [41.365013]	Linf: [0.6862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 817 pred_label: 817 pred_clean_logit 0.9962483048439026
prompt generate:  sports car  	labels:  [[817]]
decoder:  [49406, 2054, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([751], device='cuda:0') tensor(0.9990, device='cuda:0')
after_true: tensor([817], device='cuda:0') tensor(7.1669e-10, device='cuda:0')
L1: [6791.808]	L2: [32.473774]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=12.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=14.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=16.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.3%
Timestep  4: Avg Loss=0.000003, Std=0.000002, Contribution=34.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 34.5% (timestep 4)
Min contribution: 12.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 536 pred_label: 536 pred_clean_logit 0.9905998110771179
prompt generate:  dock  	labels:  [[536]]
decoder:  [49406, 8997, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([540], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([536], device='cuda:0') tensor(2.3536e-10, device='cuda:0')
L1: [6708.898]	L2: [28.710327]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 13 pred_label: 13 pred_clean_logit 0.9866503477096558
prompt generate:  junco  	labels:  [[13]]
decoder:  [49406, 1637, 1320, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([19], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([13], device='cuda:0') tensor(5.1640e-10, device='cuda:0')
L1: [4486.1646]	L2: [17.095366]	Linf: [0.5019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.7%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 580 pred_label: 580 pred_clean_logit 0.8455784916877747
prompt generate:  greenhouse  	labels:  [[580]]
decoder:  [49406, 20819, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([383], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([580], device='cuda:0') tensor(2.1415e-21, device='cuda:0')
L1: [12213.739]	L2: [42.663517]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.3%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=25.8%
Timestep  4: Avg Loss=0.000018, Std=0.000005, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 970 pred_label: 970 pred_clean_logit 0.993238091468811
prompt generate:  alp  	labels:  [[970]]
decoder:  [49406, 39342, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([143], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([970], device='cuda:0') tensor(1.8723e-15, device='cuda:0')
L1: [4396.4473]	L2: [19.065615]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=24.4%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=56.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.2% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 719 pred_label: 719 pred_clean_logit 0.999998927116394
prompt generate:  piggy bank  	labels:  [[719]]
decoder:  [49406, 28245, 2723, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([719], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([719], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [8544.475]	L2: [33.264805]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.8%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 320 pred_label: 320 pred_clean_logit 0.9400641322135925
prompt generate:  damselfly  	labels:  [[320]]
decoder:  [49406, 1880, 1000, 3228, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([319], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([320], device='cuda:0') tensor(2.8307e-12, device='cuda:0')
L1: [4188.6587]	L2: [17.640265]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.4%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 437 pred_label: 437 pred_clean_logit 0.9975895881652832
prompt generate:  beacon  	labels:  [[437]]
decoder:  [49406, 18858, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([460], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([437], device='cuda:0') tensor(1.2117e-11, device='cuda:0')
L1: [4241.1724]	L2: [19.533127]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=60.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.7% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 990 pred_label: 990 pred_clean_logit 0.9954395890235901
prompt generate:  buckeye  	labels:  [[990]]
decoder:  [49406, 34549, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([378], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([990], device='cuda:0') tensor(5.5091e-18, device='cuda:0')
L1: [11377.702]	L2: [39.90438]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=26.2%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 685 pred_label: 479 pred_clean_logit 0.0420665517449379
prompt generate:  odometer  	labels:  [[479]]
decoder:  [49406, 78, 8515, 652, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([778], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([685], device='cuda:0') tensor(3.2021e-29, device='cuda:0')
L1: [8939.866]	L2: [37.331013]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.7%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 805 pred_label: 805 pred_clean_logit 0.9944520592689514
prompt generate:  soccer ball  	labels:  [[805]]
decoder:  [49406, 4233, 1069, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([645], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([805], device='cuda:0') tensor(5.1391e-20, device='cuda:0')
L1: [8094.3613]	L2: [27.704529]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=27.3%
Timestep  4: Avg Loss=0.000010, Std=0.000002, Contribution=49.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.3% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 580 pred_label: 580 pred_clean_logit 0.9856347441673279
prompt generate:  greenhouse  	labels:  [[580]]
decoder:  [49406, 20819, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([738], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([580], device='cuda:0') tensor(2.2687e-13, device='cuda:0')
L1: [12265.643]	L2: [45.143803]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 717 pred_label: 609 pred_clean_logit 0.19778166711330414
prompt generate:  pickup  	labels:  [[609]]
decoder:  [49406, 15382, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([609], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([717], device='cuda:0') tensor(5.0318e-24, device='cuda:0')
L1: [8957.437]	L2: [35.41935]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.5%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=43.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.0% (timestep 4)
Min contribution: 6.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 591 pred_label: 591 pred_clean_logit 0.9376627206802368
prompt generate:  handkerchief  	labels:  [[591]]
decoder:  [49406, 1722, 2352, 3455, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([721], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([591], device='cuda:0') tensor(9.8129e-07, device='cuda:0')
L1: [7332.671]	L2: [33.859737]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000010, Std=0.000002, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 955 pred_label: 951 pred_clean_logit 0.095697320997715
prompt generate:  jackfruit  	labels:  [[951]]
decoder:  [49406, 2679, 5190, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([957], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([955], device='cuda:0') tensor(2.2415e-22, device='cuda:0')
L1: [15357.392]	L2: [57.536312]	Linf: [0.93333334]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=27.7%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 75 pred_label: 75 pred_clean_logit 0.8775942921638489
prompt generate:  black widow  	labels:  [[75]]
decoder:  [49406, 1449, 19949, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([72], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([75], device='cuda:0') tensor(1.1700e-17, device='cuda:0')
L1: [10548.891]	L2: [37.462563]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.1%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 832 pred_label: 832 pred_clean_logit 0.9999946355819702
prompt generate:  stupa  	labels:  [[832]]
decoder:  [49406, 858, 2217, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([832], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([832], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [8441.177]	L2: [33.67053]	Linf: [0.6666666]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.2%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=13.2%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.5%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 483 pred_label: 483 pred_clean_logit 0.5838974118232727
prompt generate:  castle  	labels:  [[483]]
decoder:  [49406, 3540, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([668], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([483], device='cuda:0') tensor(8.9409e-18, device='cuda:0')
L1: [10302.168]	L2: [42.78973]	Linf: [0.9137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 417 pred_label: 417 pred_clean_logit 0.9999140501022339
prompt generate:  balloon  	labels:  [[417]]
decoder:  [49406, 13634, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([476], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([417], device='cuda:0') tensor(1.2257e-07, device='cuda:0')
L1: [4945.5444]	L2: [22.293]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.4%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 779 pred_label: 779 pred_clean_logit 0.9893472194671631
prompt generate:  school bus  	labels:  [[779]]
decoder:  [49406, 1228, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([829], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([779], device='cuda:0') tensor(3.6551e-14, device='cuda:0')
L1: [11700.341]	L2: [41.29689]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=25.7%
Timestep  4: Avg Loss=0.000015, Std=0.000006, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 698 pred_label: 538 pred_clean_logit 0.00039286792161874473
prompt generate:  palace  	labels:  [[538]]
decoder:  [49406, 6381, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([538], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([698], device='cuda:0') tensor(1.0494e-16, device='cuda:0')
L1: [8641.243]	L2: [36.590446]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=48.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.5% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 531 pred_label: 531 pred_clean_logit 0.9999167919158936
prompt generate:  digital watch  	labels:  [[531]]
decoder:  [49406, 2794, 1239, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([487], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([531], device='cuda:0') tensor(2.7232e-13, device='cuda:0')
L1: [6501.027]	L2: [41.009094]	Linf: [0.99607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 703 pred_label: 612 pred_clean_logit 0.053224239498376846
prompt generate:  park bench  	labels:  [[612]]
decoder:  [49406, 1452, 8771, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([882], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([703], device='cuda:0') tensor(1.2198e-27, device='cuda:0')
L1: [9985.379]	L2: [37.305023]	Linf: [0.99215686]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 922 pred_label: 922 pred_clean_logit 0.9986246824264526
prompt generate:  menu  	labels:  [[922]]
decoder:  [49406, 6225, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([415], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([922], device='cuda:0') tensor(8.3859e-23, device='cuda:0')
L1: [8073.8433]	L2: [32.026093]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=46.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.1% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 321 pred_label: 321 pred_clean_logit 0.9999778270721436
prompt generate:  admiral  	labels:  [[321]]
decoder:  [49406, 21013, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([321], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([321], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [4321.263]	L2: [17.632284]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.2%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.4%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 312 pred_label: 312 pred_clean_logit 0.9134262800216675
prompt generate:  cricket  	labels:  [[312]]
decoder:  [49406, 5373, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([311], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([312], device='cuda:0') tensor(2.7482e-13, device='cuda:0')
L1: [7419.235]	L2: [31.614445]	Linf: [0.96862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 480 pred_label: 480 pred_clean_logit 0.9866933226585388
prompt generate:  cash machine  	labels:  [[480]]
decoder:  [49406, 5131, 4169, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([648], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([480], device='cuda:0') tensor(8.3622e-19, device='cuda:0')
L1: [7624.7686]	L2: [28.66966]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 324 pred_label: 323 pred_clean_logit 0.11940725892782211
prompt generate:  cabbage butterfly  	labels:  [[323]]
decoder:  [49406, 18407, 9738, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([620], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([324], device='cuda:0') tensor(9.4272e-27, device='cuda:0')
L1: [15428.172]	L2: [56.99623]	Linf: [0.90588236]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 667 pred_label: 819 pred_clean_logit 0.0022802159655839205
prompt generate:  mortarboard  	labels:  [[819]]
decoder:  [49406, 657, 2002, 1972, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([634], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([667], device='cuda:0') tensor(1.7933e-22, device='cuda:0')
L1: [7390.5483]	L2: [25.881857]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=28.4%
Timestep  4: Avg Loss=0.000015, Std=0.000003, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 603 pred_label: 603 pred_clean_logit 0.9999842643737793
prompt generate:  horse cart  	labels:  [[603]]
decoder:  [49406, 4558, 13065, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([603], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([603], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7500.1763]	L2: [30.387756]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.5%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=24.3%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 417 pred_label: 417 pred_clean_logit 0.9998421669006348
prompt generate:  balloon  	labels:  [[417]]
decoder:  [49406, 13634, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([821], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([417], device='cuda:0') tensor(9.0019e-15, device='cuda:0')
L1: [5884.9575]	L2: [25.174288]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 759 pred_label: 759 pred_clean_logit 0.9976866245269775
prompt generate:  reflex camera  	labels:  [[759]]
decoder:  [49406, 36050, 3934, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([570], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([759], device='cuda:0') tensor(2.4179e-12, device='cuda:0')
L1: [7008.6084]	L2: [32.66033]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=47.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.5% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 510 pred_label: 510 pred_clean_logit 0.9999995231628418
prompt generate:  container ship  	labels:  [[510]]
decoder:  [49406, 14913, 1158, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([510], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([510], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3855.251]	L2: [16.482862]	Linf: [0.52549016]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 695 pred_label: 788 pred_clean_logit 0.04416026175022125
prompt generate:  padlock  	labels:  [[788]]
decoder:  [49406, 3798, 4381, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([667], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([695], device='cuda:0') tensor(4.1712e-24, device='cuda:0')
L1: [5623.3843]	L2: [21.51781]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 525 pred_label: 525 pred_clean_logit 0.9209574460983276
prompt generate:  dam  	labels:  [[525]]
decoder:  [49406, 4926, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([839], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([525], device='cuda:0') tensor(1.4083e-18, device='cuda:0')
L1: [5880.6396]	L2: [22.70453]	Linf: [0.62352943]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=58.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.6% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 308 pred_label: 308 pred_clean_logit 0.9999884366989136
prompt generate:  fly  	labels:  [[308]]
decoder:  [49406, 3228, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([309], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([308], device='cuda:0') tensor(3.9676e-17, device='cuda:0')
L1: [8901.812]	L2: [30.796097]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=12.2%
Timestep  3: Avg Loss=0.000010, Std=0.000003, Contribution=27.2%
Timestep  4: Avg Loss=0.000020, Std=0.000006, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 1.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 142 pred_label: 142 pred_clean_logit 0.9990037083625793
prompt generate:  dowitcher  	labels:  [[142]]
decoder:  [49406, 639, 33684, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([129], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([142], device='cuda:0') tensor(2.6899e-08, device='cuda:0')
L1: [5981.953]	L2: [21.43097]	Linf: [0.60392153]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000007, Std=0.000004, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 897 pred_label: 897 pred_clean_logit 0.999981164932251
prompt generate:  washer  	labels:  [[897]]
decoder:  [49406, 24085, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([577], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([897], device='cuda:0') tensor(1.1327e-19, device='cuda:0')
L1: [7106.9287]	L2: [27.814415]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000004, Std=0.000003, Contribution=45.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.8% (timestep 4)
Min contribution: 6.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 498 pred_label: 498 pred_clean_logit 0.6273851990699768
prompt generate:  cinema  	labels:  [[498]]
decoder:  [49406, 6443, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([687], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([498], device='cuda:0') tensor(8.3243e-18, device='cuda:0')
L1: [5090.7573]	L2: [22.811163]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=25.5%
Timestep  4: Avg Loss=0.000018, Std=0.000006, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 888 pred_label: 888 pred_clean_logit 0.9999767541885376
prompt generate:  viaduct  	labels:  [[888]]
decoder:  [49406, 39113, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([888], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([888], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [8488.023]	L2: [32.517113]	Linf: [0.6823529]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.0%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 303 pred_label: 303 pred_clean_logit 0.998991072177887
prompt generate:  long-horned beetle  	labels:  [[303]]
decoder:  [49406, 1538, 268, 34526, 16534, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([461], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([303], device='cuda:0') tensor(3.6211e-23, device='cuda:0')
L1: [8001.154]	L2: [37.648434]	Linf: [0.8666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.0% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 649 pred_label: 649 pred_clean_logit 0.9986827969551086
prompt generate:  megalith  	labels:  [[649]]
decoder:  [49406, 37650, 1757, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([818], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([649], device='cuda:0') tensor(4.4529e-17, device='cuda:0')
L1: [2441.996]	L2: [11.226015]	Linf: [0.5019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.0%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=58.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.3% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 406 pred_label: 917 pred_clean_logit 0.32614874839782715
prompt generate:  altar  	labels:  [[917]]
decoder:  [49406, 16385, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([894], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([406], device='cuda:0') tensor(6.7218e-21, device='cuda:0')
L1: [9293.251]	L2: [35.8602]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 841 pred_label: 841 pred_clean_logit 0.9999035596847534
prompt generate:  sweatshirt  	labels:  [[841]]
decoder:  [49406, 22442, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([451], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([841], device='cuda:0') tensor(1.6442e-18, device='cuda:0')
L1: [4478.2783]	L2: [18.872543]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000002, Std=0.000002, Contribution=21.6%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 6.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 37 pred_label: 37 pred_clean_logit 0.9998351335525513
prompt generate:  box turtle  	labels:  [[37]]
decoder:  [49406, 2063, 10912, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([36], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([37], device='cuda:0') tensor(1.5346e-08, device='cuda:0')
L1: [10529.243]	L2: [38.46404]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.9%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 320 pred_label: 320 pred_clean_logit 0.9949002861976624
prompt generate:  damselfly  	labels:  [[320]]
decoder:  [49406, 1880, 1000, 3228, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([319], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([320], device='cuda:0') tensor(3.4853e-09, device='cuda:0')
L1: [2589.8594]	L2: [10.674189]	Linf: [0.35686278]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.6% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 580 pred_label: 124 pred_clean_logit 4.8821607379068155e-06
prompt generate:  greenhouse  	labels:  [[124]]
decoder:  [49406, 20819, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([124], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([580], device='cuda:0') tensor(8.8294e-31, device='cuda:0')
L1: [12061.452]	L2: [43.596546]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 950 pred_label: 950 pred_clean_logit 0.8942831158638
prompt generate:  orange  	labels:  [[950]]
decoder:  [49406, 4287, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([928], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([950], device='cuda:0') tensor(2.5891e-31, device='cuda:0')
L1: [5386.9683]	L2: [24.269989]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 821 pred_label: 821 pred_clean_logit 0.3734146058559418
prompt generate:  steel arch bridge  	labels:  [[821]]
decoder:  [49406, 4726, 8557, 2465, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([456], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([821], device='cuda:0') tensor(2.8656e-08, device='cuda:0')
L1: [2535.4077]	L2: [9.812957]	Linf: [0.41568628]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000006, Std=0.000001, Contribution=57.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.0% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 656 pred_label: 656 pred_clean_logit 0.8833780288696289
prompt generate:  minivan  	labels:  [[656]]
decoder:  [49406, 1810, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([656], device='cuda:0') tensor(6.2876e-14, device='cuda:0')
L1: [5343.3413]	L2: [26.133245]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 665 pred_label: 665 pred_clean_logit 0.9894722104072571
prompt generate:  moped  	labels:  [[665]]
decoder:  [49406, 617, 2966, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([518], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([665], device='cuda:0') tensor(4.4245e-19, device='cuda:0')
L1: [10027.46]	L2: [41.654175]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 805 pred_label: 805 pred_clean_logit 0.9999960660934448
prompt generate:  soccer ball  	labels:  [[805]]
decoder:  [49406, 4233, 1069, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([805], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([805], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [8081.859]	L2: [32.38921]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.1%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.2%
Timestep  4: Avg Loss=0.000002, Std=0.000000, Contribution=46.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.2% (timestep 4)
Min contribution: 6.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 467 pred_label: 467 pred_clean_logit 0.9988794922828674
prompt generate:  butcher shop  	labels:  [[467]]
decoder:  [49406, 18732, 1557, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([942], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([467], device='cuda:0') tensor(1.5791e-24, device='cuda:0')
L1: [5727.385]	L2: [21.683832]	Linf: [0.49411768]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=60.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.0% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 949 pred_label: 949 pred_clean_logit 0.994217038154602
prompt generate:  strawberry  	labels:  [[949]]
decoder:  [49406, 10233, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([928], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([949], device='cuda:0') tensor(2.9861e-16, device='cuda:0')
L1: [4050.3342]	L2: [19.239231]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=20.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=58.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.7% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 471 pred_label: 612 pred_clean_logit 0.00010604959970805794
prompt generate:  cannon  	labels:  [[612]]
decoder:  [49406, 15661, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([431], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([471], device='cuda:0') tensor(3.5203e-22, device='cuda:0')
L1: [8179.0117]	L2: [32.119606]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.6%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=24.4%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 16 pred_label: 16 pred_clean_logit 0.9999977350234985
prompt generate:  bulbul  	labels:  [[16]]
decoder:  [49406, 2572, 10200, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([16], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([16], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2507.4197]	L2: [10.636116]	Linf: [0.37647063]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.6%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=11.7%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=20.6%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 646 pred_label: 646 pred_clean_logit 0.9987748265266418
prompt generate:  maze  	labels:  [[646]]
decoder:  [49406, 21988, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([888], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([646], device='cuda:0') tensor(4.9793e-17, device='cuda:0')
L1: [11868.64]	L2: [41.94769]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=57.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.5% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 985 pred_label: 985 pred_clean_logit 0.9987509250640869
prompt generate:  daisy  	labels:  [[985]]
decoder:  [49406, 12865, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([539], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([985], device='cuda:0') tensor(5.9891e-12, device='cuda:0')
L1: [12683.407]	L2: [43.045227]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 949 pred_label: 949 pred_clean_logit 0.9995511174201965
prompt generate:  strawberry  	labels:  [[949]]
decoder:  [49406, 10233, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([949], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([949], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5172.9253]	L2: [19.129105]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=59.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.0% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 917 pred_label: 917 pred_clean_logit 0.9918225407600403
prompt generate:  comic book  	labels:  [[917]]
decoder:  [49406, 4962, 1116, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([446], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([917], device='cuda:0') tensor(1.6243e-14, device='cuda:0')
L1: [11770.092]	L2: [50.271843]	Linf: [0.96862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=14.2%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.0%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 866 pred_label: 866 pred_clean_logit 0.9821944832801819
prompt generate:  tractor  	labels:  [[866]]
decoder:  [49406, 14607, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([803], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([866], device='cuda:0') tensor(2.4174e-13, device='cuda:0')
L1: [10894.518]	L2: [42.613575]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 703 pred_label: 703 pred_clean_logit 0.9994285702705383
prompt generate:  park bench  	labels:  [[703]]
decoder:  [49406, 1452, 8771, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([706], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([703], device='cuda:0') tensor(1.2919e-17, device='cuda:0')
L1: [10510.752]	L2: [37.00277]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=56.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.6% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 874 pred_label: 874 pred_clean_logit 0.9998093247413635
prompt generate:  trolleybus  	labels:  [[874]]
decoder:  [49406, 10306, 2565, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([705], device='cuda:0') tensor(0.9896, device='cuda:0')
after_true: tensor([874], device='cuda:0') tensor(1.1070e-05, device='cuda:0')
L1: [7423.7183]	L2: [30.005825]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=47.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.9% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 144 pred_label: 144 pred_clean_logit 0.999904990196228
prompt generate:  pelican  	labels:  [[144]]
decoder:  [49406, 34131, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([146], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([144], device='cuda:0') tensor(2.0461e-19, device='cuda:0')
L1: [7481.9565]	L2: [28.431288]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 930 pred_label: 930 pred_clean_logit 0.9984903335571289
prompt generate:  French loaf  	labels:  [[930]]
decoder:  [49406, 3461, 18273, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([994], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([930], device='cuda:0') tensor(3.6383e-14, device='cuda:0')
L1: [5751.6353]	L2: [21.795113]	Linf: [0.48627454]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.1%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=58.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.9% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 825 pred_label: 825 pred_clean_logit 0.6059644818305969
prompt generate:  stone wall  	labels:  [[825]]
decoder:  [49406, 2441, 2569, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([150], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([825], device='cuda:0') tensor(1.8476e-20, device='cuda:0')
L1: [11815.134]	L2: [40.173985]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 663 pred_label: 663 pred_clean_logit 0.8703387975692749
prompt generate:  monastery  	labels:  [[663]]
decoder:  [49406, 21850, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([497], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([663], device='cuda:0') tensor(1.5538e-11, device='cuda:0')
L1: [9479.121]	L2: [35.24301]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.5%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=27.2%
Timestep  4: Avg Loss=0.000018, Std=0.000006, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 858 pred_label: 858 pred_clean_logit 0.8173926472663879
prompt generate:  tile roof  	labels:  [[858]]
decoder:  [49406, 8227, 6449, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([428], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([858], device='cuda:0') tensor(1.9703e-30, device='cuda:0')
L1: [7019.126]	L2: [28.641161]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 489 pred_label: 489 pred_clean_logit 0.9981354475021362
prompt generate:  chainlink fence  	labels:  [[489]]
decoder:  [49406, 13898, 2468, 12679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([177], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([489], device='cuda:0') tensor(5.8032e-21, device='cuda:0')
L1: [12677.56]	L2: [44.10629]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 616 pred_label: 60 pred_clean_logit 0.00011148564954055473
prompt generate:  knot  	labels:  [[60]]
decoder:  [49406, 18412, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([120], device='cuda:0') tensor(0.9201, device='cuda:0')
after_true: tensor([616], device='cuda:0') tensor(2.6929e-06, device='cuda:0')
L1: [8485.784]	L2: [34.716183]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=24.7%
Timestep  4: Avg Loss=0.000010, Std=0.000002, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 820 pred_label: 866 pred_clean_logit 0.026318661868572235
prompt generate:  steam locomotive  	labels:  [[866]]
decoder:  [49406, 6972, 30439, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([471], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([820], device='cuda:0') tensor(7.6371e-14, device='cuda:0')
L1: [6024.9175]	L2: [23.840548]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 319 pred_label: 319 pred_clean_logit 0.9999967813491821
prompt generate:  dragonfly  	labels:  [[319]]
decoder:  [49406, 32824, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([308], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([319], device='cuda:0') tensor(3.4842e-16, device='cuda:0')
L1: [3412.9338]	L2: [21.307878]	Linf: [0.8666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 843 pred_label: 395 pred_clean_logit 0.05707969143986702
prompt generate:  swing  	labels:  [[395]]
decoder:  [49406, 7429, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([395], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([843], device='cuda:0') tensor(5.2884e-22, device='cuda:0')
L1: [6729.8823]	L2: [24.020008]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 547 pred_label: 547 pred_clean_logit 0.9977954626083374
prompt generate:  electric locomotive  	labels:  [[547]]
decoder:  [49406, 5031, 30439, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([705], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([547], device='cuda:0') tensor(5.0615e-09, device='cuda:0')
L1: [8609.447]	L2: [36.34735]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 437 pred_label: 437 pred_clean_logit 0.7933676242828369
prompt generate:  beacon  	labels:  [[437]]
decoder:  [49406, 18858, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([863], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([437], device='cuda:0') tensor(1.8811e-20, device='cuda:0')
L1: [2815.0466]	L2: [11.569022]	Linf: [0.42745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000017, Std=0.000004, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 668 pred_label: 668 pred_clean_logit 0.39873000979423523
prompt generate:  mosque  	labels:  [[668]]
decoder:  [49406, 12694, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([480], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([668], device='cuda:0') tensor(3.5518e-13, device='cuda:0')
L1: [4346.6196]	L2: [21.700708]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=8.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.6%
Timestep  4: Avg Loss=0.000003, Std=0.000002, Contribution=44.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.6% (timestep 4)
Min contribution: 8.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 521 pred_label: 521 pred_clean_logit 0.9999974966049194
prompt generate:  Crock Pot  	labels:  [[521]]
decoder:  [49406, 1192, 868, 5168, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([886], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([521], device='cuda:0') tensor(3.2294e-16, device='cuda:0')
L1: [7503.5024]	L2: [34.45946]	Linf: [0.8980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000002, Std=0.000002, Contribution=22.4%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=45.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.4% (timestep 4)
Min contribution: 7.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 652 pred_label: 737 pred_clean_logit 0.034694746136665344
prompt generate:  military uniform  	labels:  [[737]]
decoder:  [49406, 4323, 11075, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([737], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([652], device='cuda:0') tensor(1.6984e-19, device='cuda:0')
L1: [9574.96]	L2: [37.52581]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 646 pred_label: 646 pred_clean_logit 0.9999991655349731
prompt generate:  maze  	labels:  [[646]]
decoder:  [49406, 21988, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([816], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([646], device='cuda:0') tensor(7.0840e-22, device='cuda:0')
L1: [12424.206]	L2: [45.9312]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=58.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.5% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 882 pred_label: 882 pred_clean_logit 0.9999986886978149
prompt generate:  vacuum  	labels:  [[882]]
decoder:  [49406, 18420, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([665], device='cuda:0') tensor(0.9909, device='cuda:0')
after_true: tensor([882], device='cuda:0') tensor(8.0036e-14, device='cuda:0')
L1: [5951.7734]	L2: [24.336645]	Linf: [0.5882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.1%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 402 pred_label: 402 pred_clean_logit 0.9656118154525757
prompt generate:  acoustic guitar  	labels:  [[402]]
decoder:  [49406, 10616, 5084, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([835], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([402], device='cuda:0') tensor(9.2350e-14, device='cuda:0')
L1: [4964.781]	L2: [20.499851]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 890 pred_label: 890 pred_clean_logit 0.5446279048919678
prompt generate:  volleyball  	labels:  [[890]]
decoder:  [49406, 7458, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([430], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([890], device='cuda:0') tensor(1.4176e-11, device='cuda:0')
L1: [5173.1333]	L2: [22.426912]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000010, Std=0.000002, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 749 pred_label: 749 pred_clean_logit 0.9794368147850037
prompt generate:  quill  	labels:  [[749]]
decoder:  [49406, 48951, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([456], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([749], device='cuda:0') tensor(2.1171e-17, device='cuda:0')
L1: [4233.1846]	L2: [16.960566]	Linf: [0.43137252]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=21.7%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=59.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.8% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 825 pred_label: 865 pred_clean_logit 0.049231547862291336
prompt generate:  stone wall  	labels:  [[865]]
decoder:  [49406, 2441, 2569, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([406], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([825], device='cuda:0') tensor(3.0027e-20, device='cuda:0')
L1: [14492.946]	L2: [51.31369]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 817 pred_label: 817 pred_clean_logit 0.9993270635604858
prompt generate:  sports car  	labels:  [[817]]
decoder:  [49406, 2054, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([511], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([817], device='cuda:0') tensor(7.9930e-12, device='cuda:0')
L1: [6276.726]	L2: [29.301336]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=49.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.6% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 471 pred_label: 471 pred_clean_logit 0.9999980926513672
prompt generate:  cannon  	labels:  [[471]]
decoder:  [49406, 15661, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([471], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([471], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7695.4746]	L2: [28.694302]	Linf: [0.64705884]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.6%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=44.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.7% (timestep 4)
Min contribution: 6.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 675 pred_label: 675 pred_clean_logit 0.999854326248169
prompt generate:  moving van  	labels:  [[675]]
decoder:  [49406, 3584, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([407], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([675], device='cuda:0') tensor(1.4976e-14, device='cuda:0')
L1: [6560.996]	L2: [30.88624]	Linf: [0.8980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000006, Std=0.000004, Contribution=43.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.0% (timestep 4)
Min contribution: 8.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 733 pred_label: 733 pred_clean_logit 0.9493274092674255
prompt generate:  pole  	labels:  [[733]]
decoder:  [49406, 8170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([818], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([733], device='cuda:0') tensor(1.5499e-17, device='cuda:0')
L1: [6122.059]	L2: [23.89052]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.3%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=56.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.9% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 858 pred_label: 673 pred_clean_logit 0.021228397265076637
prompt generate:  tile roof  	labels:  [[673]]
decoder:  [49406, 8227, 6449, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([508], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([858], device='cuda:0') tensor(3.9070e-14, device='cuda:0')
L1: [7687.42]	L2: [37.60981]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=48.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.2% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 322 pred_label: 322 pred_clean_logit 0.9996637105941772
prompt generate:  ringlet  	labels:  [[322]]
decoder:  [49406, 8318, 1094, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([326], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([322], device='cuda:0') tensor(3.6877e-10, device='cuda:0')
L1: [5941.5337]	L2: [22.564741]	Linf: [0.6]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000007, Std=0.000004, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 912 pred_label: 637 pred_clean_logit 0.2590751051902771
prompt generate:  worm fence  	labels:  [[637]]
decoder:  [49406, 10945, 12679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([447], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([912], device='cuda:0') tensor(1.0689e-24, device='cuda:0')
L1: [7461.6836]	L2: [27.400854]	Linf: [0.6823529]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 933 pred_label: 938 pred_clean_logit 0.02602308616042137
prompt generate:  cheeseburger  	labels:  [[938]]
decoder:  [49406, 41200, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([928], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([933], device='cuda:0') tensor(2.4490e-26, device='cuda:0')
L1: [7331.5894]	L2: [29.003302]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=25.3%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 302 pred_label: 302 pred_clean_logit 0.9998722076416016
prompt generate:  ground beetle  	labels:  [[302]]
decoder:  [49406, 2461, 16534, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([307], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([302], device='cuda:0') tensor(4.3733e-10, device='cuda:0')
L1: [7290.13]	L2: [26.099407]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=59.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.2% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 768 pred_label: 880 pred_clean_logit 0.02052236720919609
prompt generate:  rugby ball  	labels:  [[880]]
decoder:  [49406, 4964, 1069, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([880], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([768], device='cuda:0') tensor(4.1777e-22, device='cuda:0')
L1: [6643.4424]	L2: [31.39314]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 766 pred_label: 509 pred_clean_logit 0.04484105482697487
prompt generate:  rotisserie  	labels:  [[509]]
decoder:  [49406, 532, 28155, 7005, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([938], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([766], device='cuda:0') tensor(2.5385e-31, device='cuda:0')
L1: [10329.419]	L2: [38.10459]	Linf: [0.8745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=24.6%
Timestep  4: Avg Loss=0.000022, Std=0.000005, Contribution=57.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.2% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 442 pred_label: 442 pred_clean_logit 0.9955072402954102
prompt generate:  bell cote  	labels:  [[442]]
decoder:  [49406, 3718, 20751, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([663], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([442], device='cuda:0') tensor(5.0656e-14, device='cuda:0')
L1: [6788.6787]	L2: [31.580563]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 911 pred_label: 911 pred_clean_logit 0.8368636965751648
prompt generate:  wool  	labels:  [[911]]
decoder:  [49406, 13283, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([463], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([911], device='cuda:0') tensor(5.8626e-21, device='cuda:0')
L1: [6598.9536]	L2: [27.590164]	Linf: [0.6666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.6%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=16.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=45.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.9% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 974 pred_label: 974 pred_clean_logit 0.999921441078186
prompt generate:  geyser  	labels:  [[974]]
decoder:  [49406, 619, 33121, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([974], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([974], device='cuda:0') tensor(0.9997, device='cuda:0')
L1: [2848.2588]	L2: [13.890314]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.2%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=11.6%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.7%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 511 pred_label: 511 pred_clean_logit 0.9997277855873108
prompt generate:  convertible  	labels:  [[511]]
decoder:  [49406, 19608, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([751], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([511], device='cuda:0') tensor(1.8304e-20, device='cuda:0')
L1: [8265.772]	L2: [36.084976]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 640 pred_label: 640 pred_clean_logit 0.8791964054107666
prompt generate:  manhole cover  	labels:  [[640]]
decoder:  [49406, 723, 5341, 2202, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([835], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([640], device='cuda:0') tensor(1.5942e-12, device='cuda:0')
L1: [9902.632]	L2: [36.673874]	Linf: [0.6980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 582 pred_label: 582 pred_clean_logit 0.9563261270523071
prompt generate:  grocery store  	labels:  [[582]]
decoder:  [49406, 13826, 2183, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([582], device='cuda:0') tensor(1.7358e-25, device='cuda:0')
L1: [12053.083]	L2: [46.076935]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.6% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 661 pred_label: 661 pred_clean_logit 0.9990150928497314
prompt generate:  Model T  	labels:  [[661]]
decoder:  [49406, 2863, 339, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([609], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([661], device='cuda:0') tensor(6.3581e-23, device='cuda:0')
L1: [8267.227]	L2: [40.890797]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.6%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=43.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.3% (timestep 4)
Min contribution: 8.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 259 pred_label: 259 pred_clean_logit 0.9997252821922302
prompt generate:  Pomeranian  	labels:  [[259]]
decoder:  [49406, 35156, 9945, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([263], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([259], device='cuda:0') tensor(1.2312e-13, device='cuda:0')
L1: [4102.698]	L2: [14.252264]	Linf: [0.34901962]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=13.1%
Timestep  3: Avg Loss=0.000005, Std=0.000003, Contribution=24.0%
Timestep  4: Avg Loss=0.000010, Std=0.000005, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 99 pred_label: 99 pred_clean_logit 0.8606724143028259
prompt generate:  goose  	labels:  [[99]]
decoder:  [49406, 13822, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([97], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([99], device='cuda:0') tensor(1.0314e-15, device='cuda:0')
L1: [15174.799]	L2: [51.629257]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 323 pred_label: 324 pred_clean_logit 0.08941610157489777
prompt generate:  monarch  	labels:  [[324]]
decoder:  [49406, 22619, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([862], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([323], device='cuda:0') tensor(1.5980e-33, device='cuda:0')
L1: [6426.734]	L2: [26.194607]	Linf: [0.8745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 497 pred_label: 497 pred_clean_logit 0.5860657095909119
prompt generate:  church  	labels:  [[497]]
decoder:  [49406, 2735, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([800], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([497], device='cuda:0') tensor(3.6750e-21, device='cuda:0')
L1: [18145.973]	L2: [69.70316]	Linf: [0.9137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=46.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.1% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 980 pred_label: 90 pred_clean_logit 0.000943479361012578
prompt generate:  volcano  	labels:  [[90]]
decoder:  [49406, 14581, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([1], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([980], device='cuda:0') tensor(8.6578e-20, device='cuda:0')
L1: [7717.502]	L2: [29.50258]	Linf: [0.92941177]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 8 pred_label: 8 pred_clean_logit 0.3761666417121887
prompt generate:  hen  	labels:  [[8]]
decoder:  [49406, 8047, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([87], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([8], device='cuda:0') tensor(4.1611e-16, device='cuda:0')
L1: [8720.219]	L2: [30.669844]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000018, Std=0.000004, Contribution=55.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.7% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 919 pred_label: 919 pred_clean_logit 0.9999768733978271
prompt generate:  street sign  	labels:  [[919]]
decoder:  [49406, 2012, 2292, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([919], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([919], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [9259.333]	L2: [32.223866]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000006, Std=0.000001, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 762 pred_label: 498 pred_clean_logit 0.37901830673217773
prompt generate:  restaurant  	labels:  [[498]]
decoder:  [49406, 4489, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([498], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([762], device='cuda:0') tensor(1.9077e-21, device='cuda:0')
L1: [7255.2466]	L2: [30.51845]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 454 pred_label: 454 pred_clean_logit 0.9992154836654663
prompt generate:  bookshop  	labels:  [[454]]
decoder:  [49406, 24705, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([799], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([454], device='cuda:0') tensor(6.6815e-15, device='cuda:0')
L1: [7207.965]	L2: [28.349094]	Linf: [0.6666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=25.2%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=56.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.9% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 430 pred_label: 430 pred_clean_logit 0.9999947547912598
prompt generate:  basketball  	labels:  [[430]]
decoder:  [49406, 3835, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([430], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([430], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [4940.185]	L2: [20.786543]	Linf: [0.57254905]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.6%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=24.6%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=49.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.2% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 100 pred_label: 100 pred_clean_logit 0.9999767541885376
prompt generate:  black swan  	labels:  [[100]]
decoder:  [49406, 1449, 12530, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([100], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([100], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [3465.9568]	L2: [15.347659]	Linf: [0.5294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.3%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.5%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 120 pred_label: 120 pred_clean_logit 0.1733296513557434
prompt generate:  fiddler crab  	labels:  [[120]]
decoder:  [49406, 25218, 1803, 11574, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([81], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([120], device='cuda:0') tensor(8.6602e-16, device='cuda:0')
L1: [6457.1924]	L2: [23.950022]	Linf: [0.4627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 737 pred_label: 898 pred_clean_logit 0.08793287724256516
prompt generate:  pop bottle  	labels:  [[898]]
decoder:  [49406, 2852, 5392, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([898], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([737], device='cuda:0') tensor(1.0992e-18, device='cuda:0')
L1: [8429.493]	L2: [35.44635]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=9.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=12.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=16.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=38.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 38.9% (timestep 4)
Min contribution: 9.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 404 pred_label: 404 pred_clean_logit 0.9830785393714905
prompt generate:  airliner  	labels:  [[404]]
decoder:  [49406, 1281, 11618, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([908], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([404], device='cuda:0') tensor(1.0835e-07, device='cuda:0')
L1: [2604.1646]	L2: [14.2220745]	Linf: [0.5372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.1%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 455 pred_label: 893 pred_clean_logit 0.007980951108038425
prompt generate:  bottlecap  	labels:  [[893]]
decoder:  [49406, 37306, 3938, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([893], device='cuda:0') tensor(0.9027, device='cuda:0')
after_true: tensor([455], device='cuda:0') tensor(3.7200e-15, device='cuda:0')
L1: [10576.784]	L2: [35.554775]	Linf: [0.5490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.6%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=21.1%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 879 pred_label: 879 pred_clean_logit 0.9999449253082275
prompt generate:  umbrella  	labels:  [[879]]
decoder:  [49406, 17143, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([229], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([879], device='cuda:0') tensor(1.1291e-13, device='cuda:0')
L1: [8918.744]	L2: [39.319416]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 399 pred_label: 610 pred_clean_logit 0.05135873332619667
prompt generate:  abaya  	labels:  [[610]]
decoder:  [49406, 596, 5917, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([610], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([399], device='cuda:0') tensor(1.6059e-13, device='cuda:0')
L1: [3933.196]	L2: [24.681412]	Linf: [0.9137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.1%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 640 pred_label: 401 pred_clean_logit 5.917044632042234e-09
prompt generate:  manhole cover  	labels:  [[401]]
decoder:  [49406, 723, 5341, 2202, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([401], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([640], device='cuda:0') tensor(6.1772e-24, device='cuda:0')
L1: [9567.258]	L2: [37.827602]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 4.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 829 pred_label: 829 pred_clean_logit 0.9969789981842041
prompt generate:  streetcar  	labels:  [[829]]
decoder:  [49406, 34268, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([475], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([829], device='cuda:0') tensor(5.7228e-17, device='cuda:0')
L1: [10201.965]	L2: [38.546745]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.4% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 890 pred_label: 890 pred_clean_logit 0.9999881982803345
prompt generate:  volleyball  	labels:  [[890]]
decoder:  [49406, 7458, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([890], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([890], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [12753.78]	L2: [43.906136]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.6%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 975 pred_label: 975 pred_clean_logit 0.9954250454902649
prompt generate:  lakeside  	labels:  [[975]]
decoder:  [49406, 30915, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([979], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([975], device='cuda:0') tensor(1.0745e-09, device='cuda:0')
L1: [8758.525]	L2: [34.447487]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.4%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=55.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.1% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 975 pred_label: 703 pred_clean_logit 0.07209376990795135
prompt generate:  lakeside  	labels:  [[703]]
decoder:  [49406, 30915, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([703], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([975], device='cuda:0') tensor(3.5802e-18, device='cuda:0')
L1: [12494.862]	L2: [45.40372]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 980 pred_label: 980 pred_clean_logit 0.9988920092582703
prompt generate:  volcano  	labels:  [[980]]
decoder:  [49406, 14581, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([862], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([980], device='cuda:0') tensor(3.2213e-18, device='cuda:0')
L1: [1477.463]	L2: [8.846002]	Linf: [0.5058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=20.7%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=59.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.1% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 130 pred_label: 130 pred_clean_logit 0.8761715888977051
prompt generate:  flamingo  	labels:  [[130]]
decoder:  [49406, 30323, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([128], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([130], device='cuda:0') tensor(1.0405e-17, device='cuda:0')
L1: [6196.498]	L2: [23.854717]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000018, Std=0.000004, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 535 pred_label: 535 pred_clean_logit 0.929451584815979
prompt generate:  disk brake  	labels:  [[535]]
decoder:  [49406, 17970, 14937, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([328], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([535], device='cuda:0') tensor(2.4286e-16, device='cuda:0')
L1: [5360.561]	L2: [31.126822]	Linf: [0.9882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 142 pred_label: 140 pred_clean_logit 0.06124962493777275
prompt generate:  dowitcher  	labels:  [[140]]
decoder:  [49406, 639, 33684, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([140], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([142], device='cuda:0') tensor(5.7633e-16, device='cuda:0')
L1: [8147.42]	L2: [31.25511]	Linf: [0.6745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 344 pred_label: 344 pred_clean_logit 0.6640994548797607
prompt generate:  hippopotamus  	labels:  [[344]]
decoder:  [49406, 28398, 45825, 718, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([611], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([344], device='cuda:0') tensor(1.3028e-22, device='cuda:0')
L1: [9285.901]	L2: [34.718464]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000017, Std=0.000004, Contribution=56.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.9% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 807 pred_label: 807 pred_clean_logit 0.8774661421775818
prompt generate:  solar dish  	labels:  [[807]]
decoder:  [49406, 5199, 4531, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([706], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([807], device='cuda:0') tensor(2.4473e-19, device='cuda:0')
L1: [9813.406]	L2: [38.88986]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=50.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.4% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 325 pred_label: 325 pred_clean_logit 0.9998631477355957
prompt generate:  sulphur butterfly  	labels:  [[325]]
decoder:  [49406, 47659, 9738, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([324], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([325], device='cuda:0') tensor(1.2162e-11, device='cuda:0')
L1: [6801.5645]	L2: [23.363764]	Linf: [0.5686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=49.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.8% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 661 pred_label: 661 pred_clean_logit 0.9996899366378784
prompt generate:  Model T  	labels:  [[661]]
decoder:  [49406, 2863, 339, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([803], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([661], device='cuda:0') tensor(3.1398e-14, device='cuda:0')
L1: [5997.098]	L2: [24.87236]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 479 pred_label: 479 pred_clean_logit 0.9985999464988708
prompt generate:  car wheel  	labels:  [[479]]
decoder:  [49406, 1615, 6744, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([518], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([479], device='cuda:0') tensor(8.9358e-13, device='cuda:0')
L1: [4882.906]	L2: [22.502436]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=48.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.9% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 479 pred_label: 479 pred_clean_logit 0.9418065547943115
prompt generate:  car wheel  	labels:  [[479]]
decoder:  [49406, 1615, 6744, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([535], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([479], device='cuda:0') tensor(1.5122e-08, device='cuda:0')
L1: [5454.624]	L2: [21.816887]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 5.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 738 pred_label: 738 pred_clean_logit 0.9772093296051025
prompt generate:  pot  	labels:  [[738]]
decoder:  [49406, 5168, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([883], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([738], device='cuda:0') tensor(2.8809e-13, device='cuda:0')
L1: [8836.125]	L2: [39.419315]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 805 pred_label: 805 pred_clean_logit 0.9195852279663086
prompt generate:  soccer ball  	labels:  [[805]]
decoder:  [49406, 4233, 1069, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([890], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([805], device='cuda:0') tensor(3.6771e-09, device='cuda:0')
L1: [7231.953]	L2: [27.679794]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 828 pred_label: 828 pred_clean_logit 0.4456053078174591
prompt generate:  strainer  	labels:  [[828]]
decoder:  [49406, 1894, 5155, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([677], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([828], device='cuda:0') tensor(7.4150e-18, device='cuda:0')
L1: [14342.409]	L2: [50.93439]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=27.7%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=45.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.6% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 597 pred_label: 570 pred_clean_logit 6.954539912840119e-06
prompt generate:  holster  	labels:  [[570]]
decoder:  [49406, 1187, 881, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([891], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([597], device='cuda:0') tensor(5.5208e-24, device='cuda:0')
L1: [8156.588]	L2: [32.35348]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 425 pred_label: 425 pred_clean_logit 0.9997956156730652
prompt generate:  barn  	labels:  [[425]]
decoder:  [49406, 10942, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([853], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([425], device='cuda:0') tensor(1.7923e-12, device='cuda:0')
L1: [10472.8125]	L2: [36.742954]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 946 pred_label: 127 pred_clean_logit 0.01594463177025318
prompt generate:  cardoon  	labels:  [[127]]
decoder:  [49406, 811, 36612, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([328], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([946], device='cuda:0') tensor(7.4101e-17, device='cuda:0')
L1: [4220.232]	L2: [23.485909]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.2%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 628 pred_label: 814 pred_clean_logit 0.13112179934978485
prompt generate:  liner  	labels:  [[814]]
decoder:  [49406, 11618, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([814], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([628], device='cuda:0') tensor(5.0682e-18, device='cuda:0')
L1: [5718.1807]	L2: [23.331284]	Linf: [0.6]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 759 pred_label: 759 pred_clean_logit 0.999818742275238
prompt generate:  reflex camera  	labels:  [[759]]
decoder:  [49406, 36050, 3934, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([759], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([759], device='cuda:0') tensor(0.9997, device='cuda:0')
L1: [5169.028]	L2: [28.33644]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=9.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.2%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=23.0%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=46.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.9% (timestep 4)
Min contribution: 6.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 532 pred_label: 526 pred_clean_logit 0.18519890308380127
prompt generate:  dining table  	labels:  [[526]]
decoder:  [49406, 8658, 2175, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([526], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([532], device='cuda:0') tensor(5.0788e-16, device='cuda:0')
L1: [5915.1533]	L2: [26.633215]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=8.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=15.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=40.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 40.8% (timestep 4)
Min contribution: 8.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 865 pred_label: 865 pred_clean_logit 0.9838108420372009
prompt generate:  toyshop  	labels:  [[865]]
decoder:  [49406, 14387, 1557, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([398], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([865], device='cuda:0') tensor(1.6939e-32, device='cuda:0')
L1: [10504.303]	L2: [37.966072]	Linf: [0.81960785]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=13.6%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=27.0%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 468 pred_label: 468 pred_clean_logit 0.9999492168426514
prompt generate:  cab  	labels:  [[468]]
decoder:  [49406, 11912, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([511], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([468], device='cuda:0') tensor(3.7957e-16, device='cuda:0')
L1: [10641.091]	L2: [43.811295]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=15.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=45.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.7% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 895 pred_label: 895 pred_clean_logit 0.9335981607437134
prompt generate:  warplane  	labels:  [[895]]
decoder:  [49406, 984, 5363, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([403], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([895], device='cuda:0') tensor(1.7610e-12, device='cuda:0')
L1: [5140.6826]	L2: [22.843227]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.1% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 309 pred_label: 309 pred_clean_logit 0.992643415927887
prompt generate:  bee  	labels:  [[309]]
decoder:  [49406, 5028, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([308], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([309], device='cuda:0') tensor(1.4877e-14, device='cuda:0')
L1: [4569.436]	L2: [18.767534]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 656 pred_label: 656 pred_clean_logit 0.9963498115539551
prompt generate:  minivan  	labels:  [[656]]
decoder:  [49406, 1810, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([656], device='cuda:0') tensor(3.3309e-15, device='cuda:0')
L1: [6129.451]	L2: [25.173353]	Linf: [0.8784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=9.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=45.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.2% (timestep 4)
Min contribution: 6.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 581 pred_label: 581 pred_clean_logit 0.949817955493927
prompt generate:  grille  	labels:  [[581]]
decoder:  [49406, 34748, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([581], device='cuda:0') tensor(8.0396e-16, device='cuda:0')
L1: [8422.977]	L2: [31.623835]	Linf: [0.6352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 468 pred_label: 468 pred_clean_logit 0.8685001134872437
prompt generate:  cab  	labels:  [[468]]
decoder:  [49406, 11912, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([675], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([468], device='cuda:0') tensor(2.6399e-17, device='cuda:0')
L1: [7449.945]	L2: [30.13087]	Linf: [0.6823529]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=48.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.8% (timestep 4)
Min contribution: 6.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 239 pred_label: 239 pred_clean_logit 0.9729154109954834
prompt generate:  Bernese mountain dog  	labels:  [[239]]
decoder:  [49406, 867, 32220, 3965, 1929, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([240], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([239], device='cuda:0') tensor(4.5857e-13, device='cuda:0')
L1: [9496.017]	L2: [38.05846]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 565 pred_label: 565 pred_clean_logit 0.9999598264694214
prompt generate:  freight car  	labels:  [[565]]
decoder:  [49406, 17023, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([565], device='cuda:0') tensor(0.9996, device='cuda:0')
after_true: tensor([565], device='cuda:0') tensor(0.9996, device='cuda:0')
L1: [9885.091]	L2: [40.05657]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=49.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.1% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 692 pred_label: 692 pred_clean_logit 0.9999041557312012
prompt generate:  packet  	labels:  [[692]]
decoder:  [49406, 25022, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([637], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([692], device='cuda:0') tensor(6.3482e-19, device='cuda:0')
L1: [6777.9497]	L2: [27.13822]	Linf: [0.63529414]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=49.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.8% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 895 pred_label: 895 pred_clean_logit 0.4657135605812073
prompt generate:  warplane  	labels:  [[895]]
decoder:  [49406, 984, 5363, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([847], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([895], device='cuda:0') tensor(3.7238e-12, device='cuda:0')
L1: [3075.7136]	L2: [13.347914]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000010, Std=0.000002, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 597 pred_label: 597 pred_clean_logit 0.9978390336036682
prompt generate:  holster  	labels:  [[597]]
decoder:  [49406, 1187, 881, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([763], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([597], device='cuda:0') tensor(2.6498e-14, device='cuda:0')
L1: [5244.6704]	L2: [19.66925]	Linf: [0.5529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 858 pred_label: 858 pred_clean_logit 0.5744660496711731
prompt generate:  tile roof  	labels:  [[858]]
decoder:  [49406, 8227, 6449, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([537], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([858], device='cuda:0') tensor(5.4756e-16, device='cuda:0')
L1: [8802.969]	L2: [35.143753]	Linf: [0.6666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 632 pred_label: 632 pred_clean_logit 0.9871234893798828
prompt generate:  loudspeaker  	labels:  [[632]]
decoder:  [49406, 22884, 4914, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([485], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([632], device='cuda:0') tensor(2.6733e-12, device='cuda:0')
L1: [3056.0356]	L2: [18.593197]	Linf: [0.9529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 967 pred_label: 967 pred_clean_logit 0.5066849589347839
prompt generate:  espresso  	labels:  [[967]]
decoder:  [49406, 17098, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([535], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([967], device='cuda:0') tensor(2.3600e-18, device='cuda:0')
L1: [6583.9653]	L2: [25.76251]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 504 pred_label: 504 pred_clean_logit 0.9984444975852966
prompt generate:  coffee mug  	labels:  [[504]]
decoder:  [49406, 2453, 9722, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([725], device='cuda:0') tensor(0.9697, device='cuda:0')
after_true: tensor([504], device='cuda:0') tensor(3.6588e-09, device='cuda:0')
L1: [6388.9326]	L2: [31.77129]	Linf: [0.94509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=43.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.4% (timestep 4)
Min contribution: 7.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 751 pred_label: 919 pred_clean_logit 0.19371037185192108
prompt generate:  racer  	labels:  [[919]]
decoder:  [49406, 16798, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([919], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([751], device='cuda:0') tensor(3.6654e-16, device='cuda:0')
L1: [6890.557]	L2: [25.450941]	Linf: [0.5764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=45.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.7% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 912 pred_label: 449 pred_clean_logit 0.19565816223621368
prompt generate:  worm fence  	labels:  [[449]]
decoder:  [49406, 10945, 12679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([912], device='cuda:0') tensor(8.9673e-16, device='cuda:0')
L1: [7934.1177]	L2: [32.183388]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 383 pred_label: 383 pred_clean_logit 0.9419788718223572
prompt generate:  Madagascar cat  	labels:  [[383]]
decoder:  [49406, 25744, 2368, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([382], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([383], device='cuda:0') tensor(4.1330e-13, device='cuda:0')
L1: [8063.043]	L2: [31.29343]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=49.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.9% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 317 pred_label: 317 pred_clean_logit 0.7596774697303772
prompt generate:  leafhopper  	labels:  [[317]]
decoder:  [49406, 9377, 21748, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([311], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([317], device='cuda:0') tensor(1.4513e-16, device='cuda:0')
L1: [4338.3774]	L2: [22.030367]	Linf: [0.90588236]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 39 pred_label: 39 pred_clean_logit 0.9999864101409912
prompt generate:  common iguana  	labels:  [[39]]
decoder:  [49406, 4176, 21279, 1388, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([39], device='cuda:0') tensor(0.9977, device='cuda:0')
after_true: tensor([39], device='cuda:0') tensor(0.9977, device='cuda:0')
L1: [10433.498]	L2: [39.522903]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.7%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 544 pred_label: 544 pred_clean_logit 0.9999791383743286
prompt generate:  Dutch oven  	labels:  [[544]]
decoder:  [49406, 7991, 12579, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([567], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([544], device='cuda:0') tensor(1.4936e-16, device='cuda:0')
L1: [8731.584]	L2: [33.79106]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.7%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=53.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.2% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 580 pred_label: 580 pred_clean_logit 0.9999487400054932
prompt generate:  greenhouse  	labels:  [[580]]
decoder:  [49406, 20819, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([971], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([580], device='cuda:0') tensor(9.6353e-42, device='cuda:0')
L1: [14778.828]	L2: [53.359684]	Linf: [0.9411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 989 pred_label: 990 pred_clean_logit 0.007981041446328163
prompt generate:  hip  	labels:  [[990]]
decoder:  [49406, 6584, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([990], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([989], device='cuda:0') tensor(1.2539e-19, device='cuda:0')
L1: [10096.459]	L2: [36.363647]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.9%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 703 pred_label: 462 pred_clean_logit 0.1739487648010254
prompt generate:  park bench  	labels:  [[462]]
decoder:  [49406, 1452, 8771, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([696], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([703], device='cuda:0') tensor(5.9223e-22, device='cuda:0')
L1: [11388.466]	L2: [46.900574]	Linf: [0.98039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 984 pred_label: 984 pred_clean_logit 0.999592125415802
prompt generate:  rapeseed  	labels:  [[984]]
decoder:  [49406, 46099, 6488, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([986], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([984], device='cuda:0') tensor(3.2035e-21, device='cuda:0')
L1: [8713.628]	L2: [34.092278]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 844 pred_label: 844 pred_clean_logit 0.9991459846496582
prompt generate:  switch  	labels:  [[844]]
decoder:  [49406, 5893, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([662], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([844], device='cuda:0') tensor(1.7919e-12, device='cuda:0')
L1: [2642.7686]	L2: [11.489022]	Linf: [0.5058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 483 pred_label: 483 pred_clean_logit 0.9906256198883057
prompt generate:  castle  	labels:  [[483]]
decoder:  [49406, 3540, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([497], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([483], device='cuda:0') tensor(1.5072e-16, device='cuda:0')
L1: [6586.208]	L2: [26.767624]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=59.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.3% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 701 pred_label: 701 pred_clean_logit 0.8624321818351746
prompt generate:  parachute  	labels:  [[701]]
decoder:  [49406, 30122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([427], device='cuda:0') tensor(0.9967, device='cuda:0')
after_true: tensor([701], device='cuda:0') tensor(1.1756e-09, device='cuda:0')
L1: [4477.977]	L2: [19.26673]	Linf: [0.73725486]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=44.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.2% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 672 pred_label: 672 pred_clean_logit 0.9999772310256958
prompt generate:  mountain tent  	labels:  [[672]]
decoder:  [49406, 3965, 10782, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([672], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([672], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [4657.008]	L2: [20.840273]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.3%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.5%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 874 pred_label: 829 pred_clean_logit 0.05442212149500847
prompt generate:  trolleybus  	labels:  [[829]]
decoder:  [49406, 10306, 2565, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([829], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([874], device='cuda:0') tensor(7.2767e-12, device='cuda:0')
L1: [8698.676]	L2: [37.238514]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=45.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.8% (timestep 4)
Min contribution: 6.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 3 pred_label: 4 pred_clean_logit 0.08248787373304367
prompt generate:  tiger shark  	labels:  [[4]]
decoder:  [49406, 6531, 7980, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([4], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([3], device='cuda:0') tensor(6.8064e-15, device='cuda:0')
L1: [7628.6074]	L2: [29.01603]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=57.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.6% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 511 pred_label: 511 pred_clean_logit 0.9999850988388062
prompt generate:  convertible  	labels:  [[511]]
decoder:  [49406, 19608, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([511], device='cuda:0') tensor(1.4310e-16, device='cuda:0')
L1: [8526.722]	L2: [34.369762]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=7.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=15.7%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=41.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.8% (timestep 4)
Min contribution: 7.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 913 pred_label: 491 pred_clean_logit 2.8335009119473398e-05
prompt generate:  wreck  	labels:  [[491]]
decoder:  [49406, 15017, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([499], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([913], device='cuda:0') tensor(4.1642e-21, device='cuda:0')
L1: [6972.103]	L2: [27.357128]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=57.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.2% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 619 pred_label: 619 pred_clean_logit 0.8915828466415405
prompt generate:  lampshade  	labels:  [[619]]
decoder:  [49406, 26700, 10097, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([613], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([619], device='cuda:0') tensor(4.0156e-11, device='cuda:0')
L1: [2507.5964]	L2: [13.779336]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=47.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.7% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 751 pred_label: 573 pred_clean_logit 0.1608414649963379
prompt generate:  racer  	labels:  [[573]]
decoder:  [49406, 16798, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([573], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([751], device='cuda:0') tensor(2.7714e-09, device='cuda:0')
L1: [3332.365]	L2: [15.445311]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=26.1%
Timestep  4: Avg Loss=0.000006, Std=0.000001, Contribution=46.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.8% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 630 pred_label: 630 pred_clean_logit 0.6744464039802551
prompt generate:  Loafer  	labels:  [[630]]
decoder:  [49406, 26467, 528, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([875], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([630], device='cuda:0') tensor(3.1841e-14, device='cuda:0')
L1: [3775.8667]	L2: [14.146982]	Linf: [0.54901963]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000019, Std=0.000005, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 975 pred_label: 975 pred_clean_logit 0.9990842342376709
prompt generate:  lakeside  	labels:  [[975]]
decoder:  [49406, 30915, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([975], device='cuda:0') tensor(1.4600e-14, device='cuda:0')
L1: [6661.5063]	L2: [28.367266]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000007, Std=0.000004, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 759 pred_label: 759 pred_clean_logit 0.9999436140060425
prompt generate:  reflex camera  	labels:  [[759]]
decoder:  [49406, 36050, 3934, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([759], device='cuda:0') tensor(0.9996, device='cuda:0')
after_true: tensor([759], device='cuda:0') tensor(0.9996, device='cuda:0')
L1: [3350.392]	L2: [16.129738]	Linf: [0.517647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=8.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.2%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.0%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=41.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.9% (timestep 4)
Min contribution: 8.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 933 pred_label: 923 pred_clean_logit 0.03223897144198418
prompt generate:  cheeseburger  	labels:  [[923]]
decoder:  [49406, 41200, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([923], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([933], device='cuda:0') tensor(4.1837e-15, device='cuda:0')
L1: [4978.357]	L2: [20.442656]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 624 pred_label: 454 pred_clean_logit 0.02858715131878853
prompt generate:  library  	labels:  [[454]]
decoder:  [49406, 3519, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([454], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([624], device='cuda:0') tensor(1.6287e-17, device='cuda:0')
L1: [10672.274]	L2: [43.224228]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 981 pred_label: 981 pred_clean_logit 0.6076955199241638
prompt generate:  ballplayer  	labels:  [[981]]
decoder:  [49406, 3807, 2477, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([807], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([981], device='cuda:0') tensor(3.3872e-25, device='cuda:0')
L1: [15384.641]	L2: [56.593967]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=26.4%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 472 pred_label: 576 pred_clean_logit 0.010729354806244373
prompt generate:  canoe  	labels:  [[576]]
decoder:  [49406, 23503, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([576], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([472], device='cuda:0') tensor(7.3827e-16, device='cuda:0')
L1: [8522.852]	L2: [32.555977]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 776 pred_label: 776 pred_clean_logit 0.9999891519546509
prompt generate:  sax  	labels:  [[776]]
decoder:  [49406, 23766, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([513], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([776], device='cuda:0') tensor(1.7718e-18, device='cuda:0')
L1: [7639.6826]	L2: [33.444008]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=47.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.3% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 406 pred_label: 687 pred_clean_logit 0.2847307324409485
prompt generate:  altar  	labels:  [[687]]
decoder:  [49406, 16385, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([687], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([406], device='cuda:0') tensor(6.0294e-23, device='cuda:0')
L1: [13902.251]	L2: [50.1904]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=49.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.2% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 991 pred_label: 991 pred_clean_logit 0.9999947547912598
prompt generate:  coral fungus  	labels:  [[991]]
decoder:  [49406, 12054, 30677, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([991], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([991], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7918.605]	L2: [28.84381]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 518 pred_label: 518 pred_clean_logit 0.9996885061264038
prompt generate:  crash helmet  	labels:  [[518]]
decoder:  [49406, 5033, 11122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([770], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([518], device='cuda:0') tensor(9.1749e-14, device='cuda:0')
L1: [4976.345]	L2: [28.436827]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=55.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.5% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 351 pred_label: 351 pred_clean_logit 0.9997051358222961
prompt generate:  hartebeest  	labels:  [[351]]
decoder:  [49406, 915, 600, 571, 1509, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([353], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([351], device='cuda:0') tensor(1.4923e-14, device='cuda:0')
L1: [8577.012]	L2: [30.772032]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 489 pred_label: 489 pred_clean_logit 0.727194607257843
prompt generate:  chainlink fence  	labels:  [[489]]
decoder:  [49406, 13898, 2468, 12679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([23], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([489], device='cuda:0') tensor(3.1789e-26, device='cuda:0')
L1: [14074.288]	L2: [48.79243]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=50.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.8% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 888 pred_label: 888 pred_clean_logit 0.999993085861206
prompt generate:  viaduct  	labels:  [[888]]
decoder:  [49406, 39113, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([668], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([888], device='cuda:0') tensor(2.2359e-10, device='cuda:0')
L1: [10472.734]	L2: [40.014645]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.9%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=13.3%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=22.5%
Timestep  4: Avg Loss=0.000002, Std=0.000002, Contribution=48.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.8% (timestep 4)
Min contribution: 6.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 866 pred_label: 866 pred_clean_logit 0.9998069405555725
prompt generate:  tractor  	labels:  [[866]]
decoder:  [49406, 14607, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([586], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([866], device='cuda:0') tensor(3.1573e-13, device='cuda:0')
L1: [8209.859]	L2: [34.876545]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=46.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.0% (timestep 4)
Min contribution: 7.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 517 pred_label: 517 pred_clean_logit 0.9999904632568359
prompt generate:  crane  	labels:  [[517]]
decoder:  [49406, 14626, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([517], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([517], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5804.2]	L2: [26.760588]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.8%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.7%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.4%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 672 pred_label: 672 pred_clean_logit 0.9977861642837524
prompt generate:  mountain tent  	labels:  [[672]]
decoder:  [49406, 3965, 10782, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([672], device='cuda:0') tensor(3.4761e-27, device='cuda:0')
L1: [9699.432]	L2: [40.189304]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 971 pred_label: 513 pred_clean_logit 0.24814783036708832
prompt generate:  bubble  	labels:  [[513]]
decoder:  [49406, 10799, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([558], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([971], device='cuda:0') tensor(9.4836e-27, device='cuda:0')
L1: [7523.545]	L2: [30.999956]	Linf: [0.74509805]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 971 pred_label: 971 pred_clean_logit 0.8202390074729919
prompt generate:  bubble  	labels:  [[971]]
decoder:  [49406, 10799, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([107], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([971], device='cuda:0') tensor(7.4500e-09, device='cuda:0')
L1: [2753.8984]	L2: [10.049592]	Linf: [0.4117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.6%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=60.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.7% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 671 pred_label: 671 pred_clean_logit 0.9939019680023193
prompt generate:  mountain bike  	labels:  [[671]]
decoder:  [49406, 3965, 3701, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([444], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([671], device='cuda:0') tensor(1.3236e-16, device='cuda:0')
L1: [11418.274]	L2: [43.488377]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 734 pred_label: 734 pred_clean_logit 0.999962329864502
prompt generate:  police van  	labels:  [[734]]
decoder:  [49406, 2120, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([407], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([734], device='cuda:0') tensor(5.4258e-25, device='cuda:0')
L1: [8620.527]	L2: [33.715576]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=47.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.9% (timestep 4)
Min contribution: 5.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 347 pred_label: 347 pred_clean_logit 0.9969480633735657
prompt generate:  bison  	labels:  [[347]]
decoder:  [49406, 19741, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([410], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([347], device='cuda:0') tensor(3.9896e-20, device='cuda:0')
L1: [7124.2354]	L2: [27.262987]	Linf: [0.5921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000014, Std=0.000003, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 1.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 920 pred_label: 920 pred_clean_logit 0.9514056444168091
prompt generate:  traffic light  	labels:  [[920]]
decoder:  [49406, 3399, 1395, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([718], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([920], device='cuda:0') tensor(1.1525e-19, device='cuda:0')
L1: [7991.2666]	L2: [34.38871]	Linf: [0.9372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=54.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.8% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 442 pred_label: 442 pred_clean_logit 0.9993017911911011
prompt generate:  bell cote  	labels:  [[442]]
decoder:  [49406, 3718, 20751, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([497], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([442], device='cuda:0') tensor(1.2107e-09, device='cuda:0')
L1: [9957.757]	L2: [34.388863]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.1%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=59.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.1% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 922 pred_label: 922 pred_clean_logit 0.9718108177185059
prompt generate:  menu  	labels:  [[922]]
decoder:  [49406, 6225, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([446], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([922], device='cuda:0') tensor(1.6742e-11, device='cuda:0')
L1: [3231.0781]	L2: [13.953459]	Linf: [0.38039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=44.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.7% (timestep 4)
Min contribution: 6.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 832 pred_label: 697 pred_clean_logit 0.0002474179782439023
prompt generate:  stupa  	labels:  [[697]]
decoder:  [49406, 858, 2217, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([697], device='cuda:0') tensor(0.9855, device='cuda:0')
after_true: tensor([832], device='cuda:0') tensor(7.5597e-07, device='cuda:0')
L1: [3128.886]	L2: [9.523658]	Linf: [0.43137252]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.4%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=22.9%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 144 pred_label: 144 pred_clean_logit 0.9999468326568604
prompt generate:  pelican  	labels:  [[144]]
decoder:  [49406, 34131, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([144], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([144], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [3743.7493]	L2: [13.390589]	Linf: [0.26666668]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.4%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.6%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 779 pred_label: 779 pred_clean_logit 0.9999977350234985
prompt generate:  school bus  	labels:  [[779]]
decoder:  [49406, 1228, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([779], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([779], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3758.2627]	L2: [14.510597]	Linf: [0.5490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000006, Std=0.000001, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 458 pred_label: 458 pred_clean_logit 0.999879002571106
prompt generate:  brass  	labels:  [[458]]
decoder:  [49406, 11655, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([458], device='cuda:0') tensor(0.9955, device='cuda:0')
after_true: tensor([458], device='cuda:0') tensor(0.9955, device='cuda:0')
L1: [6373.6777]	L2: [24.12239]	Linf: [0.427451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.5%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=47.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.8% (timestep 4)
Min contribution: 6.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 94 pred_label: 94 pred_clean_logit 0.997789740562439
prompt generate:  hummingbird  	labels:  [[94]]
decoder:  [49406, 33072, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([88], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([94], device='cuda:0') tensor(4.4482e-21, device='cuda:0')
L1: [7213.7764]	L2: [27.118248]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 717 pred_label: 717 pred_clean_logit 0.9781484603881836
prompt generate:  pickup  	labels:  [[717]]
decoder:  [49406, 15382, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([717], device='cuda:0') tensor(3.9189e-14, device='cuda:0')
L1: [7890.6636]	L2: [34.828323]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.1%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=47.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.6% (timestep 4)
Min contribution: 6.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 814 pred_label: 814 pred_clean_logit 0.9971610307693481
prompt generate:  speedboat  	labels:  [[814]]
decoder:  [49406, 6860, 4440, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([554], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([814], device='cuda:0') tensor(2.5963e-17, device='cuda:0')
L1: [9304.875]	L2: [36.87296]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=47.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.1% (timestep 4)
Min contribution: 6.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 985 pred_label: 985 pred_clean_logit 0.9999823570251465
prompt generate:  daisy  	labels:  [[985]]
decoder:  [49406, 12865, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([985], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([985], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2590.5767]	L2: [17.465055]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=9.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=11.7%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=16.6%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=21.7%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=40.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 40.3% (timestep 4)
Min contribution: 9.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 978 pred_label: 978 pred_clean_logit 0.709079921245575
prompt generate:  seashore  	labels:  [[978]]
decoder:  [49406, 567, 31194, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([314], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([978], device='cuda:0') tensor(4.7156e-23, device='cuda:0')
L1: [4338.694]	L2: [17.770092]	Linf: [0.5137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.3%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000019, Std=0.000005, Contribution=60.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.2% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 904 pred_label: 557 pred_clean_logit 0.038751810789108276
prompt generate:  window screen  	labels:  [[557]]
decoder:  [49406, 4879, 3750, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([557], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([904], device='cuda:0') tensor(2.8415e-24, device='cuda:0')
L1: [7826.753]	L2: [29.519674]	Linf: [0.62352943]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=44.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.5% (timestep 4)
Min contribution: 7.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 280 pred_label: 280 pred_clean_logit 0.9999494552612305
prompt generate:  grey fox  	labels:  [[280]]
decoder:  [49406, 5046, 3240, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([269], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([280], device='cuda:0') tensor(3.7256e-11, device='cuda:0')
L1: [12031.757]	L2: [45.444756]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=27.8%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 318 pred_label: 318 pred_clean_logit 0.9999991655349731
prompt generate:  lacewing  	labels:  [[318]]
decoder:  [49406, 30012, 1340, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([318], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([318], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3824.647]	L2: [20.105545]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.9%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 887 pred_label: 887 pred_clean_logit 0.898779571056366
prompt generate:  vestment  	labels:  [[887]]
decoder:  [49406, 31657, 777, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([617], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([887], device='cuda:0') tensor(5.5592e-23, device='cuda:0')
L1: [10960.491]	L2: [41.48372]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 347 pred_label: 347 pred_clean_logit 0.9998729228973389
prompt generate:  bison  	labels:  [[347]]
decoder:  [49406, 19741, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([348], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([347], device='cuda:0') tensor(2.1106e-21, device='cuda:0')
L1: [7833.595]	L2: [27.150639]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 346 pred_label: 346 pred_clean_logit 0.9961179494857788
prompt generate:  water buffalo  	labels:  [[346]]
decoder:  [49406, 1573, 8054, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([345], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([346], device='cuda:0') tensor(5.0297e-12, device='cuda:0')
L1: [6701.53]	L2: [27.31242]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 671 pred_label: 671 pred_clean_logit 0.9737207293510437
prompt generate:  mountain bike  	labels:  [[671]]
decoder:  [49406, 3965, 3701, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([444], device='cuda:0') tensor(0.9998, device='cuda:0')
after_true: tensor([671], device='cuda:0') tensor(4.0178e-08, device='cuda:0')
L1: [8444.988]	L2: [34.258694]	Linf: [0.96862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.9%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=47.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.9% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 668 pred_label: 668 pred_clean_logit 0.999828577041626
prompt generate:  mosque  	labels:  [[668]]
decoder:  [49406, 12694, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([900], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([668], device='cuda:0') tensor(3.5743e-09, device='cuda:0')
L1: [4899.0234]	L2: [25.702717]	Linf: [0.72156864]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=9.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=20.5%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=61.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 61.7% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 403 pred_label: 403 pred_clean_logit 0.999995231628418
prompt generate:  aircraft carrier  	labels:  [[403]]
decoder:  [49406, 7706, 12308, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([403], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([403], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5190.0703]	L2: [20.625692]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=5.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 322 pred_label: 322 pred_clean_logit 0.9743485450744629
prompt generate:  ringlet  	labels:  [[322]]
decoder:  [49406, 8318, 1094, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([325], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([322], device='cuda:0') tensor(1.3751e-12, device='cuda:0')
L1: [7279.365]	L2: [27.868933]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 734 pred_label: 734 pred_clean_logit 0.9410495758056641
prompt generate:  police van  	labels:  [[734]]
decoder:  [49406, 2120, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([407], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([734], device='cuda:0') tensor(5.0143e-16, device='cuda:0')
L1: [8541.627]	L2: [34.499477]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 962 pred_label: 962 pred_clean_logit 0.996957540512085
prompt generate:  meat loaf  	labels:  [[962]]
decoder:  [49406, 6480, 18273, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([941], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([962], device='cuda:0') tensor(6.8942e-18, device='cuda:0')
L1: [8293.334]	L2: [34.46109]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 675 pred_label: 675 pred_clean_logit 0.9348326921463013
prompt generate:  moving van  	labels:  [[675]]
decoder:  [49406, 3584, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([757], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([675], device='cuda:0') tensor(2.9669e-21, device='cuda:0')
L1: [8172.2866]	L2: [31.693699]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=46.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.4% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 468 pred_label: 468 pred_clean_logit 0.9999631643295288
prompt generate:  cab  	labels:  [[468]]
decoder:  [49406, 11912, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([561], device='cuda:0') tensor(0.9959, device='cuda:0')
after_true: tensor([468], device='cuda:0') tensor(0.0001, device='cuda:0')
L1: [6840.6123]	L2: [28.18866]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=9.2%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=45.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.4% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 295 pred_label: 295 pred_clean_logit 0.9456811547279358
prompt generate:  American black bear  	labels:  [[295]]
decoder:  [49406, 2151, 1449, 4298, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([386], device='cuda:0') tensor(0.9838, device='cuda:0')
after_true: tensor([295], device='cuda:0') tensor(1.9633e-11, device='cuda:0')
L1: [6610.117]	L2: [25.589958]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=11.5%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=24.7%
Timestep  4: Avg Loss=0.000020, Std=0.000006, Contribution=56.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.5% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 670 pred_label: 670 pred_clean_logit 0.7837015986442566
prompt generate:  motor scooter  	labels:  [[670]]
decoder:  [49406, 7659, 14199, 652, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([238], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([670], device='cuda:0') tensor(1.6266e-19, device='cuda:0')
L1: [8121.1177]	L2: [31.136772]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000016, Std=0.000004, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 13 pred_label: 13 pred_clean_logit 0.5057878494262695
prompt generate:  junco  	labels:  [[13]]
decoder:  [49406, 1637, 1320, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([18], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([13], device='cuda:0') tensor(1.3083e-09, device='cuda:0')
L1: [3969.408]	L2: [15.071157]	Linf: [0.59607846]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=58.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.0% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 546 pred_label: 546 pred_clean_logit 0.9996010661125183
prompt generate:  electric guitar  	labels:  [[546]]
decoder:  [49406, 5031, 5084, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([714], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([546], device='cuda:0') tensor(5.9409e-25, device='cuda:0')
L1: [7700.1064]	L2: [41.46806]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=45.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.8% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 737 pred_label: 737 pred_clean_logit 0.8590848445892334
prompt generate:  pop bottle  	labels:  [[737]]
decoder:  [49406, 2852, 5392, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([898], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([737], device='cuda:0') tensor(9.6206e-17, device='cuda:0')
L1: [7710.8555]	L2: [33.548676]	Linf: [0.8980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.1% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 457 pred_label: 857 pred_clean_logit 0.041365161538124084
prompt generate:  bow tie  	labels:  [[857]]
decoder:  [49406, 4040, 3422, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([667], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([457], device='cuda:0') tensor(4.0581e-32, device='cuda:0')
L1: [6388.15]	L2: [24.190859]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.2%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=24.1%
Timestep  4: Avg Loss=0.000019, Std=0.000005, Contribution=59.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.4% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 403 pred_label: 403 pred_clean_logit 0.9994307160377502
prompt generate:  aircraft carrier  	labels:  [[403]]
decoder:  [49406, 7706, 12308, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([510], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([403], device='cuda:0') tensor(7.4199e-25, device='cuda:0')
L1: [11378.264]	L2: [43.641052]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 112 pred_label: 112 pred_clean_logit 0.9578545093536377
prompt generate:  conch  	labels:  [[112]]
decoder:  [49406, 616, 634, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([117], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([112], device='cuda:0') tensor(6.5927e-18, device='cuda:0')
L1: [3545.8667]	L2: [14.399679]	Linf: [0.41176474]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 985 pred_label: 985 pred_clean_logit 0.9999762773513794
prompt generate:  daisy  	labels:  [[985]]
decoder:  [49406, 12865, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([985], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([985], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [4054.3765]	L2: [17.080309]	Linf: [0.5568628]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.2%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.1%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 762 pred_label: 579 pred_clean_logit 0.006326517555862665
prompt generate:  restaurant  	labels:  [[579]]
decoder:  [49406, 4489, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([579], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([762], device='cuda:0') tensor(2.5081e-28, device='cuda:0')
L1: [7500.954]	L2: [30.298023]	Linf: [0.8509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 908 pred_label: 475 pred_clean_logit 0.002313826931640506
prompt generate:  wing  	labels:  [[475]]
decoder:  [49406, 1340, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([475], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([908], device='cuda:0') tensor(3.6567e-14, device='cuda:0')
L1: [3277.6943]	L2: [13.181348]	Linf: [0.35686275]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=54.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.7% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 582 pred_label: 582 pred_clean_logit 0.9592928290367126
prompt generate:  grocery store  	labels:  [[582]]
decoder:  [49406, 13826, 2183, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([998], device='cuda:0') tensor(0.9991, device='cuda:0')
after_true: tensor([582], device='cuda:0') tensor(6.5735e-27, device='cuda:0')
L1: [6708.039]	L2: [25.253252]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 705 pred_label: 705 pred_clean_logit 0.9999663829803467
prompt generate:  passenger car  	labels:  [[705]]
decoder:  [49406, 12311, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([547], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([705], device='cuda:0') tensor(1.7479e-07, device='cuda:0')
L1: [5866.51]	L2: [23.08617]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 565 pred_label: 569 pred_clean_logit 0.13694915175437927
prompt generate:  freight car  	labels:  [[569]]
decoder:  [49406, 17023, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([569], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([565], device='cuda:0') tensor(2.8082e-18, device='cuda:0')
L1: [6061.412]	L2: [27.235794]	Linf: [0.65098035]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000014, Std=0.000005, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 486 pred_label: 486 pred_clean_logit 0.9999998807907104
prompt generate:  cello  	labels:  [[486]]
decoder:  [49406, 23013, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([486], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([486], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6031.0938]	L2: [24.59208]	Linf: [0.6862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.1%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.0%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=23.4%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=46.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.6% (timestep 4)
Min contribution: 6.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 829 pred_label: 829 pred_clean_logit 0.9996174573898315
prompt generate:  streetcar  	labels:  [[829]]
decoder:  [49406, 34268, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([449], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([829], device='cuda:0') tensor(4.0159e-17, device='cuda:0')
L1: [8417.671]	L2: [31.368454]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 961 pred_label: 961 pred_clean_logit 0.9980412721633911
prompt generate:  dough  	labels:  [[961]]
decoder:  [49406, 14983, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([941], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([961], device='cuda:0') tensor(5.7703e-15, device='cuda:0')
L1: [3628.0903]	L2: [13.185264]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.1%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=57.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.5% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 471 pred_label: 471 pred_clean_logit 0.8840309977531433
prompt generate:  cannon  	labels:  [[471]]
decoder:  [49406, 15661, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([169], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([471], device='cuda:0') tensor(6.4988e-24, device='cuda:0')
L1: [12095.231]	L2: [49.240776]	Linf: [0.972549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.6% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 695 pred_label: 666 pred_clean_logit 0.059538621455430984
prompt generate:  padlock  	labels:  [[666]]
decoder:  [49406, 3798, 4381, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([666], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([695], device='cuda:0') tensor(6.0097e-32, device='cuda:0')
L1: [4716.]	L2: [17.450357]	Linf: [0.41960782]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000009, Std=0.000002, Contribution=25.2%
Timestep  4: Avg Loss=0.000020, Std=0.000004, Contribution=56.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.6% (timestep 4)
Min contribution: 1.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 436 pred_label: 468 pred_clean_logit 0.06702050566673279
prompt generate:  beach wagon  	labels:  [[468]]
decoder:  [49406, 2117, 13260, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([436], device='cuda:0') tensor(5.6475e-21, device='cuda:0')
L1: [9996.871]	L2: [37.342133]	Linf: [0.67058825]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=45.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.9% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 874 pred_label: 874 pred_clean_logit 0.9488427639007568
prompt generate:  trolleybus  	labels:  [[874]]
decoder:  [49406, 10306, 2565, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([874], device='cuda:0') tensor(5.1653e-15, device='cuda:0')
L1: [8411.8]	L2: [31.610117]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 883 pred_label: 883 pred_clean_logit 0.8913714289665222
prompt generate:  vase  	labels:  [[883]]
decoder:  [49406, 20431, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([646], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([883], device='cuda:0') tensor(1.6535e-21, device='cuda:0')
L1: [9247.432]	L2: [35.847546]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=46.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.0% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 705 pred_label: 705 pred_clean_logit 0.9998832941055298
prompt generate:  passenger car  	labels:  [[705]]
decoder:  [49406, 12311, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([782], device='cuda:0') tensor(0.9312, device='cuda:0')
after_true: tensor([705], device='cuda:0') tensor(4.3372e-17, device='cuda:0')
L1: [4834.2476]	L2: [19.665245]	Linf: [0.5960784]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.8%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.1%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=57.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.0% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 347 pred_label: 347 pred_clean_logit 0.998635470867157
prompt generate:  bison  	labels:  [[347]]
decoder:  [49406, 19741, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([350], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([347], device='cuda:0') tensor(1.0381e-19, device='cuda:0')
L1: [5471.282]	L2: [25.450573]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=22.0%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 746 pred_label: 746 pred_clean_logit 0.9955872297286987
prompt generate:  puck  	labels:  [[746]]
decoder:  [49406, 17550, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([981], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([746], device='cuda:0') tensor(3.4050e-12, device='cuda:0')
L1: [7170.506]	L2: [33.284817]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=51.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.1% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 974 pred_label: 974 pred_clean_logit 0.9945226907730103
prompt generate:  geyser  	labels:  [[974]]
decoder:  [49406, 619, 33121, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([978], device='cuda:0') tensor(0.9990, device='cuda:0')
after_true: tensor([974], device='cuda:0') tensor(7.5056e-10, device='cuda:0')
L1: [5799.1807]	L2: [21.669275]	Linf: [0.46274513]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=10.9%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=24.5%
Timestep  4: Avg Loss=0.000020, Std=0.000007, Contribution=58.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.7% (timestep 4)
Min contribution: 1.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 555 pred_label: 980 pred_clean_logit 0.03263266757130623
prompt generate:  fire engine  	labels:  [[980]]
decoder:  [49406, 1769, 5857, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([974], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([555], device='cuda:0') tensor(2.2822e-13, device='cuda:0')
L1: [2794.6274]	L2: [15.2536955]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=57.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.8% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 634 pred_label: 442 pred_clean_logit 0.0865166038274765
prompt generate:  lumbermill  	labels:  [[442]]
decoder:  [49406, 27421, 6637, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([749], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([634], device='cuda:0') tensor(3.0268e-22, device='cuda:0')
L1: [6781.7417]	L2: [24.817465]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=2.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000018, Std=0.000005, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 319 pred_label: 326 pred_clean_logit 0.00010647234739735723
prompt generate:  dragonfly  	labels:  [[326]]
decoder:  [49406, 32824, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([326], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([319], device='cuda:0') tensor(2.5887e-12, device='cuda:0')
L1: [4755.4517]	L2: [24.384033]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.2%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 560 pred_label: 560 pred_clean_logit 0.9276569485664368
prompt generate:  football helmet  	labels:  [[560]]
decoder:  [49406, 1882, 11122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([615], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([560], device='cuda:0') tensor(1.8598e-20, device='cuda:0')
L1: [10632.324]	L2: [40.555397]	Linf: [0.89411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 3.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 762 pred_label: 498 pred_clean_logit 0.10269875079393387
prompt generate:  restaurant  	labels:  [[498]]
decoder:  [49406, 4489, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([498], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([762], device='cuda:0') tensor(2.7512e-19, device='cuda:0')
L1: [7068.267]	L2: [29.799541]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 559 pred_label: 559 pred_clean_logit 0.9963317513465881
prompt generate:  folding chair  	labels:  [[559]]
decoder:  [49406, 15464, 4269, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([526], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([559], device='cuda:0') tensor(6.9672e-18, device='cuda:0')
L1: [6199.189]	L2: [25.693556]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 573 pred_label: 573 pred_clean_logit 0.9909663200378418
prompt generate:  go-kart  	labels:  [[573]]
decoder:  [49406, 861, 268, 21310, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([621], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([573], device='cuda:0') tensor(3.3049e-15, device='cuda:0')
L1: [6457.16]	L2: [26.972134]	Linf: [0.79607844]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=56.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 980 pred_label: 980 pred_clean_logit 0.999994158744812
prompt generate:  volcano  	labels:  [[980]]
decoder:  [49406, 14581, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([6], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([980], device='cuda:0') tensor(2.7593e-17, device='cuda:0')
L1: [4689.0938]	L2: [21.89326]	Linf: [0.62745094]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.3%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=25.7%
Timestep  4: Avg Loss=0.000018, Std=0.000005, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 661 pred_label: 661 pred_clean_logit 0.9999945163726807
prompt generate:  Model T  	labels:  [[661]]
decoder:  [49406, 2863, 339, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([661], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([661], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [12220.729]	L2: [52.099773]	Linf: [0.9882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=9.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=11.3%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=15.5%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=22.8%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=41.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.0% (timestep 4)
Min contribution: 9.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 922 pred_label: 922 pred_clean_logit 0.9987751841545105
prompt generate:  menu  	labels:  [[922]]
decoder:  [49406, 6225, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([742], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([922], device='cuda:0') tensor(8.0107e-14, device='cuda:0')
L1: [4384.1216]	L2: [22.295324]	Linf: [0.6980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=47.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.6% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 923 pred_label: 923 pred_clean_logit 0.9961571097373962
prompt generate:  plate  	labels:  [[923]]
decoder:  [49406, 5135, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([809], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([923], device='cuda:0') tensor(2.3632e-15, device='cuda:0')
L1: [5065.019]	L2: [24.439222]	Linf: [0.6901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 661 pred_label: 661 pred_clean_logit 0.9999872446060181
prompt generate:  Model T  	labels:  [[661]]
decoder:  [49406, 2863, 339, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([661], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([661], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7144.8003]	L2: [30.105234]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.4%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=47.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.4% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 535 pred_label: 535 pred_clean_logit 0.9997857213020325
prompt generate:  disk brake  	labels:  [[535]]
decoder:  [49406, 17970, 14937, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([535], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([535], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [5858.342]	L2: [24.41014]	Linf: [0.7764706]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=15.3%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.4%
Timestep  4: Avg Loss=0.000002, Std=0.000000, Contribution=43.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.8% (timestep 4)
Min contribution: 6.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 70 pred_label: 70 pred_clean_logit 0.999925971031189
prompt generate:  harvestman  	labels:  [[70]]
decoder:  [49406, 44495, 786, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([70], device='cuda:0') tensor(0.9991, device='cuda:0')
after_true: tensor([70], device='cuda:0') tensor(0.9991, device='cuda:0')
L1: [1661.7217]	L2: [5.6979256]	Linf: [0.3647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000006, Std=0.000001, Contribution=58.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.0% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 897 pred_label: 612 pred_clean_logit 0.005177819635719061
prompt generate:  washer  	labels:  [[612]]
decoder:  [49406, 24085, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([880], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([897], device='cuda:0') tensor(1.8904e-23, device='cuda:0')
L1: [7280.1963]	L2: [29.686861]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.8%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 540 pred_label: 517 pred_clean_logit 0.3675798177719116
prompt generate:  drilling platform  	labels:  [[517]]
decoder:  [49406, 18634, 5549, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([517], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([540], device='cuda:0') tensor(1.2700e-10, device='cuda:0')
L1: [10022.188]	L2: [42.56636]	Linf: [0.85490197]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=25.9%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 789 pred_label: 789 pred_clean_logit 0.9951889514923096
prompt generate:  shoji  	labels:  [[789]]
decoder:  [49406, 719, 2697, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([804], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([789], device='cuda:0') tensor(3.9984e-20, device='cuda:0')
L1: [5502.0396]	L2: [24.505632]	Linf: [0.6862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=9.8%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=14.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=44.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.5% (timestep 4)
Min contribution: 7.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 791 pred_label: 791 pred_clean_logit 0.6156538128852844
prompt generate:  shopping cart  	labels:  [[791]]
decoder:  [49406, 4266, 13065, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([751], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([791], device='cuda:0') tensor(1.1486e-16, device='cuda:0')
L1: [11382.329]	L2: [42.359272]	Linf: [0.8784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.5%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=51.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.5% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 915 pred_label: 915 pred_clean_logit 0.9999884366989136
prompt generate:  yurt  	labels:  [[915]]
decoder:  [49406, 88, 24309, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([672], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([915], device='cuda:0') tensor(1.2168e-09, device='cuda:0')
L1: [11936.316]	L2: [49.002037]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 707 pred_label: 707 pred_clean_logit 0.999886155128479
prompt generate:  pay-phone  	labels:  [[707]]
decoder:  [49406, 3345, 268, 1951, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([707], device='cuda:0') tensor(0.9931, device='cuda:0')
after_true: tensor([707], device='cuda:0') tensor(0.9931, device='cuda:0')
L1: [8617.023]	L2: [32.421494]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.2%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=24.3%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=47.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.0% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 668 pred_label: 668 pred_clean_logit 0.9999886751174927
prompt generate:  mosque  	labels:  [[668]]
decoder:  [49406, 12694, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([668], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([668], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3335.4429]	L2: [15.040655]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.2%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=48.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.2% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 430 pred_label: 890 pred_clean_logit 0.06805001944303513
prompt generate:  basketball  	labels:  [[890]]
decoder:  [49406, 3835, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([202], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([430], device='cuda:0') tensor(4.5333e-29, device='cuda:0')
L1: [8556.852]	L2: [33.09928]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.5%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=49.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.3% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 497 pred_label: 497 pred_clean_logit 0.8120702505111694
prompt generate:  church  	labels:  [[497]]
decoder:  [49406, 2735, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([483], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([497], device='cuda:0') tensor(2.5580e-18, device='cuda:0')
L1: [7872.447]	L2: [31.78493]	Linf: [0.83137256]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.5%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 324 pred_label: 324 pred_clean_logit 0.8054978251457214
prompt generate:  cabbage butterfly  	labels:  [[324]]
decoder:  [49406, 18407, 9738, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([720], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([324], device='cuda:0') tensor(7.7122e-20, device='cuda:0')
L1: [3600.812]	L2: [15.193917]	Linf: [0.5294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=55.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.7% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 518 pred_label: 518 pred_clean_logit 0.9998608827590942
prompt generate:  crash helmet  	labels:  [[518]]
decoder:  [49406, 5033, 11122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([573], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([518], device='cuda:0') tensor(1.7068e-14, device='cuda:0')
L1: [9265.935]	L2: [41.3171]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=49.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.2% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 296 pred_label: 296 pred_clean_logit 0.9957441687583923
prompt generate:  ice bear  	labels:  [[296]]
decoder:  [49406, 733, 4298, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([178], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([296], device='cuda:0') tensor(1.2789e-21, device='cuda:0')
L1: [4977.8433]	L2: [18.100235]	Linf: [0.5137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 821 pred_label: 821 pred_clean_logit 0.9999947547912598
prompt generate:  steel arch bridge  	labels:  [[821]]
decoder:  [49406, 4726, 8557, 2465, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([821], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([821], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [9910.1875]	L2: [37.985542]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.3%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=12.8%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.3%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 299 pred_label: 299 pred_clean_logit 0.9992008805274963
prompt generate:  meerkat  	labels:  [[299]]
decoder:  [49406, 26714, 9341, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([82], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([299], device='cuda:0') tensor(6.3265e-16, device='cuda:0')
L1: [10051.404]	L2: [37.738132]	Linf: [0.58431375]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.1%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=55.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.7% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 328 pred_label: 328 pred_clean_logit 0.992151141166687
prompt generate:  sea urchin  	labels:  [[328]]
decoder:  [49406, 2102, 565, 8979, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([973], device='cuda:0') tensor(0.9817, device='cuda:0')
after_true: tensor([328], device='cuda:0') tensor(1.7290e-08, device='cuda:0')
L1: [12887.656]	L2: [46.11254]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.8%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.4%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=27.3%
Timestep  4: Avg Loss=0.000017, Std=0.000006, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 1.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 160 pred_label: 160 pred_clean_logit 0.9999719858169556
prompt generate:  Afghan hound  	labels:  [[160]]
decoder:  [49406, 15919, 13561, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([226], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([160], device='cuda:0') tensor(3.0041e-23, device='cuda:0')
L1: [9773.303]	L2: [36.28507]	Linf: [0.8156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 555 pred_label: 555 pred_clean_logit 0.7941935062408447
prompt generate:  fire engine  	labels:  [[555]]
decoder:  [49406, 1769, 5857, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([819], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([555], device='cuda:0') tensor(1.1951e-21, device='cuda:0')
L1: [9817.184]	L2: [45.42629]	Linf: [0.9254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.8%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 947 pred_label: 120 pred_clean_logit 0.0017091662157326937
prompt generate:  mushroom  	labels:  [[120]]
decoder:  [49406, 13011, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([470], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([947], device='cuda:0') tensor(1.5698e-38, device='cuda:0')
L1: [6402.3965]	L2: [25.056425]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=3.8%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=10.5%
Timestep  3: Avg Loss=0.000011, Std=0.000003, Contribution=24.6%
Timestep  4: Avg Loss=0.000026, Std=0.000007, Contribution=59.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.8% (timestep 4)
Min contribution: 1.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 985 pred_label: 985 pred_clean_logit 0.4746347963809967
prompt generate:  daisy  	labels:  [[985]]
decoder:  [49406, 12865, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([944], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([985], device='cuda:0') tensor(1.7820e-16, device='cuda:0')
L1: [3459.4004]	L2: [13.868831]	Linf: [0.56470585]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 646 pred_label: 900 pred_clean_logit 2.8906220904900692e-05
prompt generate:  maze  	labels:  [[900]]
decoder:  [49406, 21988, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([900], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([646], device='cuda:0') tensor(1.4405e-18, device='cuda:0')
L1: [12682.662]	L2: [46.280766]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=49.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.6% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 617 pred_label: 617 pred_clean_logit 0.3574599325656891
prompt generate:  lab coat  	labels:  [[617]]
decoder:  [49406, 4352, 7356, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([808], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([617], device='cuda:0') tensor(1.7254e-35, device='cuda:0')
L1: [4793.4077]	L2: [19.18637]	Linf: [0.5254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=47.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.8% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 853 pred_label: 853 pred_clean_logit 0.9250163435935974
prompt generate:  thatch  	labels:  [[853]]
decoder:  [49406, 6303, 634, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([634], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([853], device='cuda:0') tensor(1.6264e-20, device='cuda:0')
L1: [9661.275]	L2: [42.702354]	Linf: [0.9490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=57.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.5% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 807 pred_label: 580 pred_clean_logit 0.0013632482150569558
prompt generate:  solar dish  	labels:  [[580]]
decoder:  [49406, 5199, 4531, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([593], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([807], device='cuda:0') tensor(3.7074e-12, device='cuda:0')
L1: [10295.927]	L2: [35.38831]	Linf: [0.68235296]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.1%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=59.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.1% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 976 pred_label: 976 pred_clean_logit 0.9852349758148193
prompt generate:  promontory  	labels:  [[976]]
decoder:  [49406, 644, 749, 4214, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([972], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([976], device='cuda:0') tensor(9.4540e-15, device='cuda:0')
L1: [5424.706]	L2: [21.44848]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.7%
Timestep  4: Avg Loss=0.000008, Std=0.000004, Contribution=55.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.3% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 430 pred_label: 430 pred_clean_logit 0.9999945163726807
prompt generate:  basketball  	labels:  [[430]]
decoder:  [49406, 3835, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([890], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([430], device='cuda:0') tensor(2.2346e-18, device='cuda:0')
L1: [9075.455]	L2: [33.93642]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=52.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.6% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 832 pred_label: 832 pred_clean_logit 0.9999932050704956
prompt generate:  stupa  	labels:  [[832]]
decoder:  [49406, 858, 2217, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([832], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([832], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [11730.524]	L2: [45.70652]	Linf: [0.8156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.8%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=24.2%
Timestep  4: Avg Loss=0.000005, Std=0.000001, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 895 pred_label: 895 pred_clean_logit 0.9994791150093079
prompt generate:  warplane  	labels:  [[895]]
decoder:  [49406, 984, 5363, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([908], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([895], device='cuda:0') tensor(1.1543e-10, device='cuda:0')
L1: [5580.7295]	L2: [21.259953]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 985 pred_label: 985 pred_clean_logit 0.9993522763252258
prompt generate:  daisy  	labels:  [[985]]
decoder:  [49406, 12865, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([720], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([985], device='cuda:0') tensor(1.3829e-08, device='cuda:0')
L1: [8783.394]	L2: [32.82737]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.9%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=26.8%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=48.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.4% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 94 pred_label: 94 pred_clean_logit 0.999981164932251
prompt generate:  hummingbird  	labels:  [[94]]
decoder:  [49406, 33072, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([94], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([94], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2333.216]	L2: [10.278072]	Linf: [0.39215687]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=10.3%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=18.2%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=61.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 61.3% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 763 pred_label: 763 pred_clean_logit 0.9999538660049438
prompt generate:  revolver  	labels:  [[763]]
decoder:  [49406, 38747, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([764], device='cuda:0') tensor(0.9926, device='cuda:0')
after_true: tensor([763], device='cuda:0') tensor(4.0150e-12, device='cuda:0')
L1: [5777.0977]	L2: [24.511185]	Linf: [0.6313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=55.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.9% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 885 pred_label: 584 pred_clean_logit 0.14043118059635162
prompt generate:  velvet  	labels:  [[584]]
decoder:  [49406, 11063, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([117], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([885], device='cuda:0') tensor(5.4557e-22, device='cuda:0')
L1: [4994.255]	L2: [18.506132]	Linf: [0.5333333]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 873 pred_label: 873 pred_clean_logit 0.9374637007713318
prompt generate:  triumphal arch  	labels:  [[873]]
decoder:  [49406, 14782, 1037, 8708, 8557, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([497], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([873], device='cuda:0') tensor(4.0836e-17, device='cuda:0')
L1: [12517.941]	L2: [46.38153]	Linf: [0.8784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 562 pred_label: 562 pred_clean_logit 0.9293389916419983
prompt generate:  fountain  	labels:  [[562]]
decoder:  [49406, 13405, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([509], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([562], device='cuda:0') tensor(3.6965e-20, device='cuda:0')
L1: [6164.1846]	L2: [25.862514]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.9%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000017, Std=0.000004, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 1.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 472 pred_label: 472 pred_clean_logit 0.9694178104400635
prompt generate:  canoe  	labels:  [[472]]
decoder:  [49406, 23503, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([977], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([472], device='cuda:0') tensor(4.5027e-12, device='cuda:0')
L1: [5389.4155]	L2: [20.943483]	Linf: [0.8392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.1%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 665 pred_label: 665 pred_clean_logit 0.9990094900131226
prompt generate:  moped  	labels:  [[665]]
decoder:  [49406, 617, 2966, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([661], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([665], device='cuda:0') tensor(1.6697e-13, device='cuda:0')
L1: [11277.329]	L2: [43.183174]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=26.4%
Timestep  4: Avg Loss=0.000003, Std=0.000002, Contribution=46.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.2% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 322 pred_label: 322 pred_clean_logit 0.9980406165122986
prompt generate:  ringlet  	labels:  [[322]]
decoder:  [49406, 8318, 1094, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([324], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([322], device='cuda:0') tensor(2.5344e-17, device='cuda:0')
L1: [6154.4043]	L2: [23.949526]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.2%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 441 pred_label: 441 pred_clean_logit 0.9939520955085754
prompt generate:  beer glass  	labels:  [[441]]
decoder:  [49406, 2544, 3313, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([967], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([441], device='cuda:0') tensor(2.5756e-16, device='cuda:0')
L1: [3886.6982]	L2: [15.2933655]	Linf: [0.5411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000010, Std=0.000005, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 437 pred_label: 437 pred_clean_logit 0.9997530579566956
prompt generate:  beacon  	labels:  [[437]]
decoder:  [49406, 18858, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([437], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([437], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [5447.086]	L2: [26.973219]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=16.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=28.3%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=43.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.2% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 320 pred_label: 320 pred_clean_logit 0.953711211681366
prompt generate:  damselfly  	labels:  [[320]]
decoder:  [49406, 1880, 1000, 3228, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([319], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([320], device='cuda:0') tensor(1.0208e-11, device='cuda:0')
L1: [10804.506]	L2: [39.12852]	Linf: [0.8862745]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 900 pred_label: 900 pred_clean_logit 0.9809850454330444
prompt generate:  water tower  	labels:  [[900]]
decoder:  [49406, 1573, 4730, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([417], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([900], device='cuda:0') tensor(2.2943e-23, device='cuda:0')
L1: [13248.454]	L2: [47.482178]	Linf: [0.85882354]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=55.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.0% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 517 pred_label: 517 pred_clean_logit 0.9952227473258972
prompt generate:  crane  	labels:  [[517]]
decoder:  [49406, 14626, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([755], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([517], device='cuda:0') tensor(6.7896e-16, device='cuda:0')
L1: [5934.8003]	L2: [23.221762]	Linf: [0.6117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 403 pred_label: 403 pred_clean_logit 0.9999406337738037
prompt generate:  aircraft carrier  	labels:  [[403]]
decoder:  [49406, 7706, 12308, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([408], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([403], device='cuda:0') tensor(3.1711e-15, device='cuda:0')
L1: [6201.208]	L2: [30.126291]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=55.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.2% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 814 pred_label: 814 pred_clean_logit 0.9940263032913208
prompt generate:  speedboat  	labels:  [[814]]
decoder:  [49406, 6860, 4440, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([693], device='cuda:0') tensor(0.9994, device='cuda:0')
after_true: tensor([814], device='cuda:0') tensor(5.0526e-11, device='cuda:0')
L1: [6354.992]	L2: [23.146687]	Linf: [0.6]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=22.0%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=57.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.9% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 877 pred_label: 877 pred_clean_logit 0.9685974717140198
prompt generate:  turnstile  	labels:  [[877]]
decoder:  [49406, 5522, 522, 989, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([877], device='cuda:0') tensor(1.5579e-21, device='cuda:0')
L1: [8526.383]	L2: [35.6993]	Linf: [0.9098039]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.7%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=50.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.2% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 21 pred_label: 21 pred_clean_logit 0.9975916147232056
prompt generate:  kite  	labels:  [[21]]
decoder:  [49406, 19867, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([91], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([21], device='cuda:0') tensor(5.1028e-13, device='cuda:0')
L1: [5460.7065]	L2: [22.830404]	Linf: [0.5647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.7%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=57.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.4% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 489 pred_label: 489 pred_clean_logit 0.9811133146286011
prompt generate:  chainlink fence  	labels:  [[489]]
decoder:  [49406, 13898, 2468, 12679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([897], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([489], device='cuda:0') tensor(1.0527e-17, device='cuda:0')
L1: [9725.172]	L2: [39.783436]	Linf: [0.88235295]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=53.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.9% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 751 pred_label: 751 pred_clean_logit 0.9981127977371216
prompt generate:  racer  	labels:  [[751]]
decoder:  [49406, 16798, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([817], device='cuda:0') tensor(0.9987, device='cuda:0')
after_true: tensor([751], device='cuda:0') tensor(4.5670e-08, device='cuda:0')
L1: [6180.381]	L2: [27.773602]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=44.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.7% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 654 pred_label: 654 pred_clean_logit 0.9651688933372498
prompt generate:  minibus  	labels:  [[654]]
decoder:  [49406, 1810, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([762], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([654], device='cuda:0') tensor(1.1416e-17, device='cuda:0')
L1: [6584.478]	L2: [30.401281]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.5%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 311 pred_label: 311 pred_clean_logit 0.6046202778816223
prompt generate:  grasshopper  	labels:  [[311]]
decoder:  [49406, 48894, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([319], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([311], device='cuda:0') tensor(1.3466e-26, device='cuda:0')
L1: [9744.753]	L2: [36.498375]	Linf: [0.6666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000007, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 628 pred_label: 628 pred_clean_logit 0.8001478314399719
prompt generate:  liner  	labels:  [[628]]
decoder:  [49406, 11618, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([536], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([628], device='cuda:0') tensor(2.6665e-11, device='cuda:0')
L1: [5580.737]	L2: [25.248518]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 978 pred_label: 978 pred_clean_logit 0.7111579775810242
prompt generate:  seashore  	labels:  [[978]]
decoder:  [49406, 567, 31194, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([766], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([978], device='cuda:0') tensor(1.0627e-26, device='cuda:0')
L1: [6290.3687]	L2: [24.39315]	Linf: [0.98039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.3%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.7%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=25.2%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 640 pred_label: 918 pred_clean_logit 1.1143414667458273e-05
prompt generate:  manhole cover  	labels:  [[918]]
decoder:  [49406, 723, 5341, 2202, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([918], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([640], device='cuda:0') tensor(1.1246e-33, device='cuda:0')
L1: [11673.162]	L2: [41.455143]	Linf: [0.78431374]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=24.2%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 5.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 39 pred_label: 39 pred_clean_logit 0.9969245791435242
prompt generate:  common iguana  	labels:  [[39]]
decoder:  [49406, 4176, 21279, 1388, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([46], device='cuda:0') tensor(0.8729, device='cuda:0')
after_true: tensor([39], device='cuda:0') tensor(1.0632e-09, device='cuda:0')
L1: [9462.191]	L2: [37.992676]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.0%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.1% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 776 pred_label: 776 pred_clean_logit 0.9999942779541016
prompt generate:  sax  	labels:  [[776]]
decoder:  [49406, 23766, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([785], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([776], device='cuda:0') tensor(1.0013e-31, device='cuda:0')
L1: [9160.809]	L2: [34.4557]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.4%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.4%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=12.7%
Timestep  3: Avg Loss=0.000011, Std=0.000003, Contribution=27.9%
Timestep  4: Avg Loss=0.000022, Std=0.000005, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 1.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 734 pred_label: 734 pred_clean_logit 0.9999997615814209
prompt generate:  police van  	labels:  [[734]]
decoder:  [49406, 2120, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [5862.929]	L2: [25.387234]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=11.5%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=12.9%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=15.9%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=21.9%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=37.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 37.8% (timestep 4)
Min contribution: 11.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 133 pred_label: 133 pred_clean_logit 0.9845970273017883
prompt generate:  bittern  	labels:  [[133]]
decoder:  [49406, 3010, 12959, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([142], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([133], device='cuda:0') tensor(2.4543e-12, device='cuda:0')
L1: [10263.443]	L2: [37.94926]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=52.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.7% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 787 pred_label: 652 pred_clean_logit 0.017077308148145676
prompt generate:  shield  	labels:  [[652]]
decoder:  [49406, 8670, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([124], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([787], device='cuda:0') tensor(2.9515e-32, device='cuda:0')
L1: [7387.5186]	L2: [30.594103]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.5%
Timestep  2: Avg Loss=0.000005, Std=0.000001, Contribution=11.9%
Timestep  3: Avg Loss=0.000011, Std=0.000003, Contribution=26.7%
Timestep  4: Avg Loss=0.000022, Std=0.000005, Contribution=55.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.4% (timestep 4)
Min contribution: 1.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 821 pred_label: 821 pred_clean_logit 0.994049072265625
prompt generate:  steel arch bridge  	labels:  [[821]]
decoder:  [49406, 4726, 8557, 2465, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([649], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([821], device='cuda:0') tensor(1.2408e-10, device='cuda:0')
L1: [4493.4746]	L2: [21.179918]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 637 pred_label: 637 pred_clean_logit 0.9998125433921814
prompt generate:  mailbox  	labels:  [[637]]
decoder:  [49406, 31482, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([412], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([637], device='cuda:0') tensor(3.3279e-15, device='cuda:0')
L1: [6148.2827]	L2: [25.406057]	Linf: [0.6509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.7%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=58.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.6% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 448 pred_label: 824 pred_clean_logit 0.0001273123052669689
prompt generate:  birdhouse  	labels:  [[824]]
decoder:  [49406, 6908, 1212, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([824], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([448], device='cuda:0') tensor(1.1705e-18, device='cuda:0')
L1: [14128.627]	L2: [52.950897]	Linf: [0.70980394]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.4%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 654 pred_label: 654 pred_clean_logit 0.9853373169898987
prompt generate:  minibus  	labels:  [[654]]
decoder:  [49406, 1810, 2840, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([436], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([654], device='cuda:0') tensor(9.1202e-13, device='cuda:0')
L1: [6759.2866]	L2: [27.09175]	Linf: [0.6666667]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=8.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.5%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=48.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.7% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 406 pred_label: 406 pred_clean_logit 0.6810405850410461
prompt generate:  altar  	labels:  [[406]]
decoder:  [49406, 16385, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([698], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([406], device='cuda:0') tensor(3.6873e-23, device='cuda:0')
L1: [8123.483]	L2: [32.531986]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=3.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.2%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=12.8%
Timestep  3: Avg Loss=0.000006, Std=0.000003, Contribution=25.4%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 646 pred_label: 787 pred_clean_logit 0.024152187630534172
prompt generate:  maze  	labels:  [[787]]
decoder:  [49406, 21988, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([292], device='cuda:0') tensor(0.9848, device='cuda:0')
after_true: tensor([646], device='cuda:0') tensor(2.2356e-07, device='cuda:0')
L1: [16742.61]	L2: [72.23097]	Linf: [0.99215686]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=9.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=11.4%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=16.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=37.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 37.7% (timestep 4)
Min contribution: 9.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 555 pred_label: 555 pred_clean_logit 0.9999758005142212
prompt generate:  fire engine  	labels:  [[555]]
decoder:  [49406, 1769, 5857, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([555], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([555], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [10193.129]	L2: [37.358025]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 391 pred_label: 391 pred_clean_logit 0.8128942251205444
prompt generate:  coho  	labels:  [[391]]
decoder:  [49406, 622, 2971, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([394], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([391], device='cuda:0') tensor(1.5326e-23, device='cuda:0')
L1: [8893.416]	L2: [32.474415]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=54.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.1% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 436 pred_label: 436 pred_clean_logit 0.9764544367790222
prompt generate:  beach wagon  	labels:  [[436]]
decoder:  [49406, 2117, 13260, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([468], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([436], device='cuda:0') tensor(1.0159e-19, device='cuda:0')
L1: [8819.608]	L2: [35.872925]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=49.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.2% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 117 pred_label: 117 pred_clean_logit 0.9999998807907104
prompt generate:  chambered nautilus  	labels:  [[117]]
decoder:  [49406, 1290, 9193, 5955, 6124, 718, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([117], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([117], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3616.8276]	L2: [14.762902]	Linf: [0.45490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.4%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 734 pred_label: 734 pred_clean_logit 0.9999934434890747
prompt generate:  police van  	labels:  [[734]]
decoder:  [49406, 2120, 2451, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([734], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6516.612]	L2: [27.189787]	Linf: [0.627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.3%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=14.3%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=24.3%
Timestep  4: Avg Loss=0.000002, Std=0.000000, Contribution=45.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.5% (timestep 4)
Min contribution: 6.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 980 pred_label: 980 pred_clean_logit 0.9990191459655762
prompt generate:  volcano  	labels:  [[980]]
decoder:  [49406, 14581, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([107], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([980], device='cuda:0') tensor(3.2075e-17, device='cuda:0')
L1: [2960.608]	L2: [10.411628]	Linf: [0.22352943]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=3.1%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=9.7%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=24.0%
Timestep  4: Avg Loss=0.000023, Std=0.000005, Contribution=62.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 62.0% (timestep 4)
Min contribution: 1.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 304 pred_label: 303 pred_clean_logit 0.0005008276784792542
prompt generate:  leaf beetle  	labels:  [[303]]
decoder:  [49406, 7232, 16534, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([312], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([304], device='cuda:0') tensor(2.4730e-19, device='cuda:0')
L1: [6136.302]	L2: [25.469803]	Linf: [0.58823526]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.8%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=52.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.4% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 628 pred_label: 628 pred_clean_logit 0.9998992681503296
prompt generate:  liner  	labels:  [[628]]
decoder:  [49406, 11618, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([727], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([628], device='cuda:0') tensor(1.8452e-11, device='cuda:0')
L1: [5506.93]	L2: [27.419167]	Linf: [0.73725486]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=8.7%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=10.8%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.9%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=22.6%
Timestep  4: Avg Loss=0.000001, Std=0.000001, Contribution=43.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.0% (timestep 4)
Min contribution: 8.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 518 pred_label: 518 pred_clean_logit 0.9734570980072021
prompt generate:  crash helmet  	labels:  [[518]]
decoder:  [49406, 5033, 11122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([450], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([518], device='cuda:0') tensor(1.4071e-21, device='cuda:0')
L1: [8960.835]	L2: [42.015965]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.3%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.3% (timestep 4)
Min contribution: 3.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 609 pred_label: 656 pred_clean_logit 0.40826019644737244
prompt generate:  jeep  	labels:  [[656]]
decoder:  [49406, 11286, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([656], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([609], device='cuda:0') tensor(1.5285e-16, device='cuda:0')
L1: [7400.9414]	L2: [28.952417]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 741 pred_label: 741 pred_clean_logit 0.9856632351875305
prompt generate:  prayer rug  	labels:  [[741]]
decoder:  [49406, 6583, 19220, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([735], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([741], device='cuda:0') tensor(8.7402e-20, device='cuda:0')
L1: [17597.13]	L2: [61.161]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.2%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=27.9%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 562 pred_label: 562 pred_clean_logit 0.9986346364021301
prompt generate:  fountain  	labels:  [[562]]
decoder:  [49406, 13405, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([694], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([562], device='cuda:0') tensor(2.0136e-19, device='cuda:0')
L1: [5751.208]	L2: [28.517056]	Linf: [0.87058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 733 pred_label: 733 pred_clean_logit 0.20303800702095032
prompt generate:  pole  	labels:  [[733]]
decoder:  [49406, 8170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([723], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([733], device='cuda:0') tensor(7.4882e-22, device='cuda:0')
L1: [4636.054]	L2: [21.153568]	Linf: [0.6823529]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000010, Std=0.000004, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 442 pred_label: 442 pred_clean_logit 0.9974483251571655
prompt generate:  bell cote  	labels:  [[442]]
decoder:  [49406, 3718, 20751, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([698], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([442], device='cuda:0') tensor(2.5076e-12, device='cuda:0')
L1: [5443.577]	L2: [23.73596]	Linf: [0.6588235]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.6%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.0%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 6.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 692 pred_label: 692 pred_clean_logit 0.9882363677024841
prompt generate:  packet  	labels:  [[692]]
decoder:  [49406, 25022, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([917], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([692], device='cuda:0') tensor(1.6601e-12, device='cuda:0')
L1: [13035.698]	L2: [54.281536]	Linf: [0.9529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=15.9%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=26.8%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=45.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.0% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 310 pred_label: 310 pred_clean_logit 0.9999145269393921
prompt generate:  ant  	labels:  [[310]]
decoder:  [49406, 773, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([310], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([310], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6904.3496]	L2: [25.222134]	Linf: [0.517647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000013, Std=0.000003, Contribution=51.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.8% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 751 pred_label: 751 pred_clean_logit 0.9999052286148071
prompt generate:  racer  	labels:  [[751]]
decoder:  [49406, 16798, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([479], device='cuda:0') tensor(0.9994, device='cuda:0')
after_true: tensor([751], device='cuda:0') tensor(1.0972e-08, device='cuda:0')
L1: [8508.537]	L2: [34.98388]	Linf: [0.92941177]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.3%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=46.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.4% (timestep 4)
Min contribution: 6.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 819 pred_label: 819 pred_clean_logit 0.9895803332328796
prompt generate:  stage  	labels:  [[819]]
decoder:  [49406, 2170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([573], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([819], device='cuda:0') tensor(1.8581e-18, device='cuda:0')
L1: [8995.02]	L2: [37.131744]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 535 pred_label: 686 pred_clean_logit 0.3546925187110901
prompt generate:  disk brake  	labels:  [[686]]
decoder:  [49406, 17970, 14937, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([686], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([535], device='cuda:0') tensor(6.4266e-15, device='cuda:0')
L1: [5588.8857]	L2: [22.157925]	Linf: [0.7490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=26.1%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=45.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.9% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 546 pred_label: 546 pred_clean_logit 0.8895503878593445
prompt generate:  electric guitar  	labels:  [[546]]
decoder:  [49406, 5031, 5084, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([740], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([546], device='cuda:0') tensor(3.1171e-19, device='cuda:0')
L1: [7979.8315]	L2: [36.319828]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.2%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=50.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.6% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 708 pred_label: 708 pred_clean_logit 0.9999223947525024
prompt generate:  pedestal  	labels:  [[708]]
decoder:  [49406, 12862, 5535, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([863], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([708], device='cuda:0') tensor(2.1791e-18, device='cuda:0')
L1: [4009.7253]	L2: [16.281076]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000007, Std=0.000004, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 4.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 366 pred_label: 366 pred_clean_logit 0.9886857271194458
prompt generate:  gorilla  	labels:  [[366]]
decoder:  [49406, 21994, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([367], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([366], device='cuda:0') tensor(5.6033e-23, device='cuda:0')
L1: [9624.016]	L2: [33.245903]	Linf: [0.7137255]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.1%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 886 pred_label: 886 pred_clean_logit 0.9999984502792358
prompt generate:  vending machine  	labels:  [[886]]
decoder:  [49406, 29202, 4169, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([860], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([886], device='cuda:0') tensor(2.7594e-13, device='cuda:0')
L1: [9764.89]	L2: [38.805935]	Linf: [0.7294118]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.1%
Timestep  4: Avg Loss=0.000005, Std=0.000003, Contribution=52.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.2% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 705 pred_label: 705 pred_clean_logit 0.9961183071136475
prompt generate:  passenger car  	labels:  [[705]]
decoder:  [49406, 12311, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([466], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([705], device='cuda:0') tensor(1.2093e-16, device='cuda:0')
L1: [13644.432]	L2: [48.485573]	Linf: [0.75686276]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.3%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=60.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.0% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 671 pred_label: 671 pred_clean_logit 0.9998377561569214
prompt generate:  mountain bike  	labels:  [[671]]
decoder:  [49406, 3965, 3701, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([518], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([671], device='cuda:0') tensor(4.1679e-17, device='cuda:0')
L1: [7006.5693]	L2: [27.56457]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=45.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.9% (timestep 4)
Min contribution: 5.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 887 pred_label: 887 pred_clean_logit 0.9996987581253052
prompt generate:  vestment  	labels:  [[887]]
decoder:  [49406, 31657, 777, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([443], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([887], device='cuda:0') tensor(7.9707e-20, device='cuda:0')
L1: [7571.377]	L2: [29.399431]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=49.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.2% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 300 pred_label: 70 pred_clean_logit 0.1907949000597
prompt generate:  tiger beetle  	labels:  [[70]]
decoder:  [49406, 6531, 16534, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([310], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([300], device='cuda:0') tensor(4.9109e-12, device='cuda:0')
L1: [8337.616]	L2: [30.531359]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.0%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.8%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.2%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=53.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.8% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 603 pred_label: 603 pred_clean_logit 0.9999991655349731
prompt generate:  horse cart  	labels:  [[603]]
decoder:  [49406, 4558, 13065, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([690], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([603], device='cuda:0') tensor(2.0019e-18, device='cuda:0')
L1: [10593.353]	L2: [43.998013]	Linf: [0.77254903]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 131 pred_label: 131 pred_clean_logit 0.3142428398132324
prompt generate:  little blue heron  	labels:  [[131]]
decoder:  [49406, 1274, 1746, 22593, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([261], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([131], device='cuda:0') tensor(4.7560e-15, device='cuda:0')
L1: [7144.5767]	L2: [25.234274]	Linf: [0.7372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.9%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 2.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 304 pred_label: 304 pred_clean_logit 0.8225816488265991
prompt generate:  leaf beetle  	labels:  [[304]]
decoder:  [49406, 7232, 16534, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([306], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([304], device='cuda:0') tensor(2.6948e-13, device='cuda:0')
L1: [5195.49]	L2: [21.88386]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=52.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.9% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 323 pred_label: 323 pred_clean_logit 0.9999974966049194
prompt generate:  monarch  	labels:  [[323]]
decoder:  [49406, 22619, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([323], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([323], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [6796.047]	L2: [26.164259]	Linf: [0.5803922]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=54.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.3% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 525 pred_label: 525 pred_clean_logit 0.99998939037323
prompt generate:  dam  	labels:  [[525]]
decoder:  [49406, 4926, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([460], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([525], device='cuda:0') tensor(3.8626e-11, device='cuda:0')
L1: [7252.3027]	L2: [27.126457]	Linf: [0.6]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.3%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 458 pred_label: 704 pred_clean_logit 0.3650017976760864
prompt generate:  brass  	labels:  [[704]]
decoder:  [49406, 11655, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([704], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([458], device='cuda:0') tensor(1.5961e-13, device='cuda:0')
L1: [6171.694]	L2: [23.797085]	Linf: [0.65098035]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.6%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=47.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.3% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 972 pred_label: 972 pred_clean_logit 0.9769257307052612
prompt generate:  cliff  	labels:  [[972]]
decoder:  [49406, 10625, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([500], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([972], device='cuda:0') tensor(1.5523e-16, device='cuda:0')
L1: [10617.642]	L2: [38.472176]	Linf: [0.7607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 590 pred_label: 688 pred_clean_logit 0.4825833737850189
prompt generate:  hand-held computer  	labels:  [[688]]
decoder:  [49406, 2463, 268, 4042, 11639, 652, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([688], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([590], device='cuda:0') tensor(9.0121e-11, device='cuda:0')
L1: [6496.5415]	L2: [30.146976]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=9.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=11.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.8%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=43.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.7% (timestep 4)
Min contribution: 9.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 716 pred_label: 716 pred_clean_logit 0.9999209642410278
prompt generate:  picket fence  	labels:  [[716]]
decoder:  [49406, 33559, 12679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([716], device='cuda:0') tensor(0.9995, device='cuda:0')
after_true: tensor([716], device='cuda:0') tensor(0.9995, device='cuda:0')
L1: [7549.585]	L2: [29.665815]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=8.6%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.6%
Timestep  3: Avg Loss=0.000002, Std=0.000000, Contribution=24.3%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=47.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.7% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 751 pred_label: 751 pred_clean_logit 0.9991602897644043
prompt generate:  racer  	labels:  [[751]]
decoder:  [49406, 16798, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([817], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([751], device='cuda:0') tensor(1.8266e-12, device='cuda:0')
L1: [9683.317]	L2: [38.39624]	Linf: [0.8745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=26.5%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=45.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 45.2% (timestep 4)
Min contribution: 4.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 819 pred_label: 819 pred_clean_logit 0.9988442659378052
prompt generate:  stage  	labels:  [[819]]
decoder:  [49406, 2170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([583], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([819], device='cuda:0') tensor(0., device='cuda:0')
L1: [9057.773]	L2: [38.821938]	Linf: [0.8980392]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.3%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 888 pred_label: 888 pred_clean_logit 0.9998248219490051
prompt generate:  viaduct  	labels:  [[888]]
decoder:  [49406, 39113, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([888], device='cuda:0') tensor(0.9997, device='cuda:0')
after_true: tensor([888], device='cuda:0') tensor(0.9997, device='cuda:0')
L1: [2988.161]	L2: [15.667891]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.8%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 630 pred_label: 630 pred_clean_logit 0.9998432397842407
prompt generate:  Loafer  	labels:  [[630]]
decoder:  [49406, 26467, 528, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([502], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([630], device='cuda:0') tensor(3.1311e-15, device='cuda:0')
L1: [4988.5137]	L2: [23.362217]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.4%
Timestep  2: Avg Loss=0.000002, Std=0.000002, Contribution=13.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.9%
Timestep  4: Avg Loss=0.000009, Std=0.000004, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 5.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 335 pred_label: 278 pred_clean_logit 0.02432514727115631
prompt generate:  fox squirrel  	labels:  [[278]]
decoder:  [49406, 3240, 14004, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([278], device='cuda:0') tensor(0.9986, device='cuda:0')
after_true: tensor([335], device='cuda:0') tensor(3.4014e-14, device='cuda:0')
L1: [6424.181]	L2: [23.878887]	Linf: [0.54509807]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=22.9%
Timestep  4: Avg Loss=0.000011, Std=0.000004, Contribution=58.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 58.7% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 830 pred_label: 830 pred_clean_logit 0.7907664775848389
prompt generate:  stretcher  	labels:  [[830]]
decoder:  [49406, 12265, 3466, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([713], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([830], device='cuda:0') tensor(1.9513e-17, device='cuda:0')
L1: [5859.1255]	L2: [22.522072]	Linf: [0.6117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.7%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=52.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.5% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 608 pred_label: 608 pred_clean_logit 0.9996782541275024
prompt generate:  jean  	labels:  [[608]]
decoder:  [49406, 6473, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([655], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([608], device='cuda:0') tensor(1.0492e-15, device='cuda:0')
L1: [8422.474]	L2: [32.98786]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=9.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=11.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=15.3%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=22.4%
Timestep  4: Avg Loss=0.000003, Std=0.000002, Contribution=41.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.4% (timestep 4)
Min contribution: 9.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 403 pred_label: 403 pred_clean_logit 0.9999994039535522
prompt generate:  aircraft carrier  	labels:  [[403]]
decoder:  [49406, 7706, 12308, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([403], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([403], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [2543.659]	L2: [11.660739]	Linf: [0.54117644]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.7%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.4%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=53.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.4% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 610 pred_label: 610 pred_clean_logit 0.9966341853141785
prompt generate:  jersey  	labels:  [[610]]
decoder:  [49406, 4471, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([487], device='cuda:0') tensor(0.9891, device='cuda:0')
after_true: tensor([610], device='cuda:0') tensor(2.8378e-07, device='cuda:0')
L1: [5495.707]	L2: [28.983149]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=21.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 5.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 780 pred_label: 780 pred_clean_logit 0.9901171326637268
prompt generate:  schooner  	labels:  [[780]]
decoder:  [49406, 2493, 6071, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([724], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([780], device='cuda:0') tensor(1.1127e-05, device='cuda:0')
L1: [4260.126]	L2: [17.039692]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=21.0%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=54.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.6% (timestep 4)
Min contribution: 5.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 563 pred_label: 563 pred_clean_logit 0.9953293800354004
prompt generate:  fountain pen  	labels:  [[563]]
decoder:  [49406, 13405, 5356, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([767], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([563], device='cuda:0') tensor(1.7152e-13, device='cuda:0')
L1: [3925.7378]	L2: [19.618639]	Linf: [0.98039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.1%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 4.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 668 pred_label: 668 pred_clean_logit 0.4104863107204437
prompt generate:  mosque  	labels:  [[668]]
decoder:  [49406, 12694, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([615], device='cuda:0') tensor(0.9936, device='cuda:0')
after_true: tensor([668], device='cuda:0') tensor(7.2626e-07, device='cuda:0')
L1: [2165.7021]	L2: [9.974336]	Linf: [0.45490196]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=11.1%
Timestep  3: Avg Loss=0.000001, Std=0.000001, Contribution=19.1%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 737 pred_label: 737 pred_clean_logit 0.9992697834968567
prompt generate:  pop bottle  	labels:  [[737]]
decoder:  [49406, 2852, 5392, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([907], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([737], device='cuda:0') tensor(4.6290e-17, device='cuda:0')
L1: [11416.515]	L2: [47.89556]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=47.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.4% (timestep 4)
Min contribution: 6.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 867 pred_label: 867 pred_clean_logit 0.9986116886138916
prompt generate:  trailer truck  	labels:  [[867]]
decoder:  [49406, 4700, 4629, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([675], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([867], device='cuda:0') tensor(4.0007e-16, device='cuda:0')
L1: [5920.086]	L2: [25.685612]	Linf: [0.8235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=25.0%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=47.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 47.3% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 119 pred_label: 124 pred_clean_logit 0.007156321778893471
prompt generate:  rock crab  	labels:  [[124]]
decoder:  [49406, 2172, 11574, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([124], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([119], device='cuda:0') tensor(5.3442e-18, device='cuda:0')
L1: [3188.1182]	L2: [12.981861]	Linf: [0.36078432]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=24.9%
Timestep  4: Avg Loss=0.000016, Std=0.000006, Contribution=57.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.7% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 560 pred_label: 768 pred_clean_logit 0.38815703988075256
prompt generate:  football helmet  	labels:  [[768]]
decoder:  [49406, 1882, 11122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([768], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([560], device='cuda:0') tensor(1.1844e-13, device='cuda:0')
L1: [7942.5684]	L2: [30.158472]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=14.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=27.4%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=48.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.5% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 284 pred_label: 192 pred_clean_logit 0.00040394303505308926
prompt generate:  Siamese cat  	labels:  [[192]]
decoder:  [49406, 43161, 2368, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([202], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([284], device='cuda:0') tensor(6.4162e-22, device='cuda:0')
L1: [6444.3027]	L2: [24.741072]	Linf: [0.5921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=24.3%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=53.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.5% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 847 pred_label: 847 pred_clean_logit 0.933610200881958
prompt generate:  tank  	labels:  [[847]]
decoder:  [49406, 6172, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([871], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([847], device='cuda:0') tensor(9.8485e-16, device='cuda:0')
L1: [5429.208]	L2: [20.362211]	Linf: [0.60392153]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=2.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=13.7%
Timestep  3: Avg Loss=0.000009, Std=0.000003, Contribution=26.8%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 979 pred_label: 979 pred_clean_logit 0.9816715121269226
prompt generate:  valley  	labels:  [[979]]
decoder:  [49406, 3136, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([970], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([979], device='cuda:0') tensor(8.2074e-13, device='cuda:0')
L1: [9585.467]	L2: [34.539494]	Linf: [0.6156863]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.5%
Timestep  4: Avg Loss=0.000009, Std=0.000002, Contribution=56.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.6% (timestep 4)
Min contribution: 2.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 817 pred_label: 817 pred_clean_logit 0.979716956615448
prompt generate:  sports car  	labels:  [[817]]
decoder:  [49406, 2054, 1615, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([511], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([817], device='cuda:0') tensor(2.6740e-13, device='cuda:0')
L1: [9643.895]	L2: [39.94236]	Linf: [0.92941177]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.8%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 781 pred_label: 781 pred_clean_logit 0.9054251909255981
prompt generate:  scoreboard  	labels:  [[781]]
decoder:  [49406, 30104, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([668], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([781], device='cuda:0') tensor(2.1771e-17, device='cuda:0')
L1: [6632.675]	L2: [31.992393]	Linf: [1.]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.0%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.6%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=26.3%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=50.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.5% (timestep 4)
Min contribution: 2.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 498 pred_label: 498 pred_clean_logit 0.9939370155334473
prompt generate:  cinema  	labels:  [[498]]
decoder:  [49406, 6443, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([458], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([498], device='cuda:0') tensor(9.1058e-16, device='cuda:0')
L1: [9049.921]	L2: [35.431606]	Linf: [0.69411767]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.6%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.0%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=43.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.6% (timestep 4)
Min contribution: 7.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 879 pred_label: 501 pred_clean_logit 0.022626031190156937
prompt generate:  umbrella  	labels:  [[501]]
decoder:  [49406, 17143, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([501], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([879], device='cuda:0') tensor(2.6025e-14, device='cuda:0')
L1: [3355.9097]	L2: [21.21007]	Linf: [0.76862746]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 3.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 963 pred_label: 963 pred_clean_logit 0.5682843327522278
prompt generate:  pizza  	labels:  [[963]]
decoder:  [49406, 4474, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([618], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([963], device='cuda:0') tensor(2.0069e-27, device='cuda:0')
L1: [12081.318]	L2: [46.312794]	Linf: [0.80784315]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=55.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.6% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 981 pred_label: 981 pred_clean_logit 0.8783146739006042
prompt generate:  ballplayer  	labels:  [[981]]
decoder:  [49406, 3807, 2477, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([611], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([981], device='cuda:0') tensor(8.1438e-22, device='cuda:0')
L1: [6114.3887]	L2: [23.317003]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=6.0%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000014, Std=0.000004, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 539 pred_label: 738 pred_clean_logit 0.0005212902324274182
prompt generate:  doormat  	labels:  [[738]]
decoder:  [49406, 7188, 9063, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([738], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([539], device='cuda:0') tensor(6.2493e-15, device='cuda:0')
L1: [6121.9097]	L2: [25.71354]	Linf: [0.6784314]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=8.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=48.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.0% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 497 pred_label: 497 pred_clean_logit 0.9679251909255981
prompt generate:  church  	labels:  [[497]]
decoder:  [49406, 2735, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([538], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([497], device='cuda:0') tensor(1.8404e-11, device='cuda:0')
L1: [8053.2275]	L2: [33.471447]	Linf: [0.8627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=15.2%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.6%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=43.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 43.6% (timestep 4)
Min contribution: 7.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 698 pred_label: 698 pred_clean_logit 0.9917282462120056
prompt generate:  palace  	labels:  [[698]]
decoder:  [49406, 6381, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([668], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([698], device='cuda:0') tensor(3.6996e-14, device='cuda:0')
L1: [3546.8472]	L2: [14.565866]	Linf: [0.4]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=22.4%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=59.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.3% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 649 pred_label: 649 pred_clean_logit 0.9970318078994751
prompt generate:  megalith  	labels:  [[649]]
decoder:  [49406, 37650, 1757, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([386], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([649], device='cuda:0') tensor(8.8200e-17, device='cuda:0')
L1: [5568.2397]	L2: [20.931774]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.0%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.3%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=57.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 57.3% (timestep 4)
Min contribution: 3.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 663 pred_label: 663 pred_clean_logit 0.9970220923423767
prompt generate:  monastery  	labels:  [[663]]
decoder:  [49406, 21850, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([442], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([663], device='cuda:0') tensor(9.4039e-19, device='cuda:0')
L1: [7861.25]	L2: [30.057514]	Linf: [0.8]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=23.3%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=54.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.9% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 989 pred_label: 989 pred_clean_logit 0.9998531341552734
prompt generate:  hip  	labels:  [[989]]
decoder:  [49406, 6584, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([577], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([989], device='cuda:0') tensor(1.7455e-29, device='cuda:0')
L1: [2831.6008]	L2: [11.6621]	Linf: [0.45882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000003, Std=0.000002, Contribution=11.8%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=24.3%
Timestep  4: Avg Loss=0.000016, Std=0.000005, Contribution=56.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.0% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 97 pred_label: 97 pred_clean_logit 0.842998206615448
prompt generate:  drake  	labels:  [[97]]
decoder:  [49406, 8958, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([12], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([97], device='cuda:0') tensor(5.8823e-23, device='cuda:0')
L1: [16476.023]	L2: [59.83043]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=27.0%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 385 pred_label: 385 pred_clean_logit 0.900352418422699
prompt generate:  Indian elephant  	labels:  [[385]]
decoder:  [49406, 3606, 10299, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([163], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([385], device='cuda:0') tensor(4.1970e-24, device='cuda:0')
L1: [7704.8633]	L2: [31.888819]	Linf: [0.8352941]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.9%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.4%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=55.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 55.7% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 780 pred_label: 780 pred_clean_logit 0.9930059909820557
prompt generate:  schooner  	labels:  [[780]]
decoder:  [49406, 2493, 6071, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([724], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([780], device='cuda:0') tensor(2.8310e-09, device='cuda:0')
L1: [10929.365]	L2: [40.209015]	Linf: [0.7058824]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.6%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=54.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.4% (timestep 4)
Min contribution: 2.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 741 pred_label: 741 pred_clean_logit 0.6529601216316223
prompt generate:  prayer rug  	labels:  [[741]]
decoder:  [49406, 6583, 19220, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([884], device='cuda:0') tensor(0.9987, device='cuda:0')
after_true: tensor([741], device='cuda:0') tensor(1.3880e-12, device='cuda:0')
L1: [17574.066]	L2: [61.394073]	Linf: [0.89411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=27.7%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=50.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.9% (timestep 4)
Min contribution: 3.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 720 pred_label: 720 pred_clean_logit 0.7477449774742126
prompt generate:  pill bottle  	labels:  [[720]]
decoder:  [49406, 19226, 5392, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([838], device='cuda:0') tensor(0.9994, device='cuda:0')
after_true: tensor([720], device='cuda:0') tensor(4.2230e-13, device='cuda:0')
L1: [5198.419]	L2: [23.898865]	Linf: [0.6588235]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=6.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=21.6%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=49.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.3% (timestep 4)
Min contribution: 6.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 348 pred_label: 348 pred_clean_logit 0.5792075395584106
prompt generate:  ram  	labels:  [[348]]
decoder:  [49406, 2007, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([341], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([348], device='cuda:0') tensor(4.2197e-09, device='cuda:0')
L1: [10577.668]	L2: [40.108402]	Linf: [0.6509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=1.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=12.0%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000018, Std=0.000004, Contribution=56.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.3% (timestep 4)
Min contribution: 1.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 442 pred_label: 873 pred_clean_logit 0.0050141713581979275
prompt generate:  bell cote  	labels:  [[873]]
decoder:  [49406, 3718, 20751, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([698], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([442], device='cuda:0') tensor(1.5844e-13, device='cuda:0')
L1: [6187.381]	L2: [27.32185]	Linf: [0.7411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=7.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.5%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=44.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.6% (timestep 4)
Min contribution: 7.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 908 pred_label: 895 pred_clean_logit 0.35839611291885376
prompt generate:  wing  	labels:  [[895]]
decoder:  [49406, 1340, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([895], device='cuda:0') tensor(0.9955, device='cuda:0')
after_true: tensor([908], device='cuda:0') tensor(7.6479e-07, device='cuda:0')
L1: [6944.1694]	L2: [25.72819]	Linf: [0.69803923]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.0%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=53.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.7% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 883 pred_label: 883 pred_clean_logit 0.9551615715026855
prompt generate:  vase  	labels:  [[883]]
decoder:  [49406, 20431, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([738], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([883], device='cuda:0') tensor(1.4137e-19, device='cuda:0')
L1: [8211.769]	L2: [35.60825]	Linf: [0.7921569]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=11.2%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.8%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=56.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.7% (timestep 4)
Min contribution: 3.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 949 pred_label: 949 pred_clean_logit 0.9999805688858032
prompt generate:  strawberry  	labels:  [[949]]
decoder:  [49406, 10233, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([868], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([949], device='cuda:0') tensor(3.6160e-07, device='cuda:0')
L1: [10678.568]	L2: [40.958454]	Linf: [0.84705883]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.8%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=8.7%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.5%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=25.0%
Timestep  4: Avg Loss=0.000002, Std=0.000001, Contribution=46.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.0% (timestep 4)
Min contribution: 5.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 787 pred_label: 787 pred_clean_logit 0.9997919201850891
prompt generate:  shield  	labels:  [[787]]
decoder:  [49406, 8670, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([455], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([787], device='cuda:0') tensor(6.3452e-21, device='cuda:0')
L1: [16351.421]	L2: [56.63945]	Linf: [0.9019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=27.1%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.2% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 637 pred_label: 707 pred_clean_logit 0.04210175573825836
prompt generate:  mailbox  	labels:  [[707]]
decoder:  [49406, 31482, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([707], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([637], device='cuda:0') tensor(5.6673e-38, device='cuda:0')
L1: [10530.255]	L2: [40.399494]	Linf: [0.73333335]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000009, Std=0.000003, Contribution=51.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.4% (timestep 4)
Min contribution: 4.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 287 pred_label: 287 pred_clean_logit 0.9528716802597046
prompt generate:  lynx  	labels:  [[287]]
decoder:  [49406, 28941, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([448], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([287], device='cuda:0') tensor(1.2728e-18, device='cuda:0')
L1: [13321.732]	L2: [45.95503]	Linf: [0.7176471]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=1.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=4.7%
Timestep  2: Avg Loss=0.000005, Std=0.000002, Contribution=13.4%
Timestep  3: Avg Loss=0.000010, Std=0.000004, Contribution=28.4%
Timestep  4: Avg Loss=0.000018, Std=0.000006, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 1.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 672 pred_label: 672 pred_clean_logit 0.9999603033065796
prompt generate:  mountain tent  	labels:  [[672]]
decoder:  [49406, 3965, 10782, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([879], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([672], device='cuda:0') tensor(1.0627e-16, device='cuda:0')
L1: [7529.5103]	L2: [31.169834]	Linf: [0.827451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.9%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 976 pred_label: 976 pred_clean_logit 0.9956900477409363
prompt generate:  promontory  	labels:  [[976]]
decoder:  [49406, 644, 749, 4214, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([972], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([976], device='cuda:0') tensor(9.6827e-10, device='cuda:0')
L1: [4975.655]	L2: [19.738018]	Linf: [0.5803921]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=5.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=25.1%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 566 pred_label: 566 pred_clean_logit 0.9997565150260925
prompt generate:  French horn  	labels:  [[566]]
decoder:  [49406, 3461, 9607, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([513], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([566], device='cuda:0') tensor(2.3247e-11, device='cuda:0')
L1: [7349.09]	L2: [36.708527]	Linf: [0.94509804]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000003, Std=0.000002, Contribution=23.4%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=52.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.0% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 917 pred_label: 917 pred_clean_logit 0.998875081539154
prompt generate:  comic book  	labels:  [[917]]
decoder:  [49406, 4962, 1116, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([704], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([917], device='cuda:0') tensor(1.1350e-17, device='cuda:0')
L1: [13500.6]	L2: [53.784855]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=7.2%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=10.0%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.6%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000004, Std=0.000002, Contribution=44.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 44.5% (timestep 4)
Min contribution: 7.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 715 pred_label: 715 pred_clean_logit 0.9999849796295166
prompt generate:  pickelhaube  	labels:  [[715]]
decoder:  [49406, 901, 2825, 5152, 655, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([711], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([715], device='cuda:0') tensor(1.9781e-12, device='cuda:0')
L1: [7432.729]	L2: [30.093285]	Linf: [0.65882355]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.0%
Timestep  3: Avg Loss=0.000005, Std=0.000001, Contribution=25.4%
Timestep  4: Avg Loss=0.000010, Std=0.000002, Contribution=52.8%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.8% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 301 pred_label: 301 pred_clean_logit 0.9983144998550415
prompt generate:  ladybug  	labels:  [[301]]
decoder:  [49406, 40038, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([584], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([301], device='cuda:0') tensor(4.5856e-10, device='cuda:0')
L1: [3933.5803]	L2: [16.491182]	Linf: [0.63529414]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.3%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=53.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.3% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 476 pred_label: 676 pred_clean_logit 0.07343071699142456
prompt generate:  carousel  	labels:  [[676]]
decoder:  [49406, 36665, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([172], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([476], device='cuda:0') tensor(1.7198e-15, device='cuda:0')
L1: [6271.29]	L2: [24.886847]	Linf: [0.6039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=4.8%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.9%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.6%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=24.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 4.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 560 pred_label: 560 pred_clean_logit 0.8014358282089233
prompt generate:  football helmet  	labels:  [[560]]
decoder:  [49406, 1882, 11122, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([880], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([560], device='cuda:0') tensor(1.6706e-28, device='cuda:0')
L1: [8270.231]	L2: [31.625717]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.0%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.4%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=48.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.7% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 323 pred_label: 323 pred_clean_logit 0.35187309980392456
prompt generate:  monarch  	labels:  [[323]]
decoder:  [49406, 22619, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([96], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([323], device='cuda:0') tensor(2.1851e-15, device='cuda:0')
L1: [6759.511]	L2: [26.075857]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.8%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.5%
Timestep  4: Avg Loss=0.000013, Std=0.000004, Contribution=54.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.0% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 417 pred_label: 417 pred_clean_logit 0.9999984502792358
prompt generate:  balloon  	labels:  [[417]]
decoder:  [49406, 13634, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([417], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([417], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [3455.8904]	L2: [14.491556]	Linf: [0.6392157]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.6%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=12.8%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=22.4%
Timestep  4: Avg Loss=0.000003, Std=0.000001, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 4.6% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 668 pred_label: 405 pred_clean_logit 0.04079585149884224
prompt generate:  mosque  	labels:  [[405]]
decoder:  [49406, 12694, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([832], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([668], device='cuda:0') tensor(7.0319e-13, device='cuda:0')
L1: [3173.2273]	L2: [17.895039]	Linf: [0.60784316]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=6.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=9.0%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.9%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.3%
Timestep  4: Avg Loss=0.000006, Std=0.000003, Contribution=46.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.9% (timestep 4)
Min contribution: 6.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 142 pred_label: 142 pred_clean_logit 0.9990795850753784
prompt generate:  dowitcher  	labels:  [[142]]
decoder:  [49406, 639, 33684, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([141], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([142], device='cuda:0') tensor(6.8180e-09, device='cuda:0')
L1: [3471.392]	L2: [15.590299]	Linf: [0.6627451]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.6%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.8%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 3.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 84 pred_label: 84 pred_clean_logit 0.9999597072601318
prompt generate:  peacock  	labels:  [[84]]
decoder:  [49406, 661, 9463, 868, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([84], device='cuda:0') tensor(0.9999, device='cuda:0')
after_true: tensor([84], device='cuda:0') tensor(0.9999, device='cuda:0')
L1: [11857.572]	L2: [40.74388]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=6.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=9.0%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=14.5%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=24.0%
Timestep  4: Avg Loss=0.000000, Std=0.000000, Contribution=46.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 46.0% (timestep 4)
Min contribution: 6.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 304 pred_label: 304 pred_clean_logit 0.963917076587677
prompt generate:  leaf beetle  	labels:  [[304]]
decoder:  [49406, 7232, 16534, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([305], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([304], device='cuda:0') tensor(1.4232e-10, device='cuda:0')
L1: [6315.4473]	L2: [28.951124]	Linf: [0.8901961]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=4.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.7%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=13.7%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.7%
Timestep  4: Avg Loss=0.000005, Std=0.000002, Contribution=49.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.5% (timestep 4)
Min contribution: 4.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 520 pred_label: 520 pred_clean_logit 0.9963439106941223
prompt generate:  crib  	labels:  [[520]]
decoder:  [49406, 23271, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([516], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([520], device='cuda:0') tensor(4.2210e-11, device='cuda:0')
L1: [6156.926]	L2: [25.953102]	Linf: [0.6431373]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000001, Contribution=5.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.7%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.1%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=22.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=51.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.0% (timestep 4)
Min contribution: 5.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 770 pred_label: 770 pred_clean_logit 0.926295816898346
prompt generate:  running shoe  	labels:  [[770]]
decoder:  [49406, 2761, 7342, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([630], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([770], device='cuda:0') tensor(2.8867e-13, device='cuda:0')
L1: [3545.1648]	L2: [19.909609]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.2%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.2%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=21.6%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=60.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 60.6% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 476 pred_label: 476 pred_clean_logit 0.9999909400939941
prompt generate:  carousel  	labels:  [[476]]
decoder:  [49406, 36665, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([476], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([476], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [9196.717]	L2: [39.014687]	Linf: [0.9843137]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=3.8%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000000, Contribution=13.4%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=24.6%
Timestep  4: Avg Loss=0.000006, Std=0.000001, Contribution=50.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 50.7% (timestep 4)
Min contribution: 3.8% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 528 pred_label: 528 pred_clean_logit 0.9999998807907104
prompt generate:  dial telephone  	labels:  [[528]]
decoder:  [49406, 11381, 17243, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([528], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([528], device='cuda:0') tensor(1., device='cuda:0')
L1: [4350.1533]	L2: [19.599243]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.9%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.6%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.5%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000008, Std=0.000002, Contribution=54.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 54.2% (timestep 4)
Min contribution: 2.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 719 pred_label: 719 pred_clean_logit 0.9999986886978149
prompt generate:  piggy bank  	labels:  [[719]]
decoder:  [49406, 28245, 2723, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([719], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([719], device='cuda:0') tensor(1.0000, device='cuda:0')
L1: [7216.506]	L2: [27.920397]	Linf: [0.7647059]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=7.4%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=11.0%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=16.0%
Timestep  3: Avg Loss=0.000001, Std=0.000000, Contribution=23.6%
Timestep  4: Avg Loss=0.000002, Std=0.000000, Contribution=42.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 42.1% (timestep 4)
Min contribution: 7.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 671 pred_label: 671 pred_clean_logit 0.5509478449821472
prompt generate:  mountain bike  	labels:  [[671]]
decoder:  [49406, 3965, 3701, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([444], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([671], device='cuda:0') tensor(5.2481e-14, device='cuda:0')
L1: [11768.546]	L2: [43.11804]	Linf: [0.9411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000008, Std=0.000003, Contribution=49.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.7% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 847 pred_label: 847 pred_clean_logit 0.9912029504776001
prompt generate:  tank  	labels:  [[847]]
decoder:  [49406, 6172, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([471], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([847], device='cuda:0') tensor(7.8965e-12, device='cuda:0')
L1: [7229.639]	L2: [28.805674]	Linf: [0.7254902]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000004, Std=0.000001, Contribution=13.2%
Timestep  3: Avg Loss=0.000008, Std=0.000002, Contribution=26.6%
Timestep  4: Avg Loss=0.000015, Std=0.000004, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 458 pred_label: 458 pred_clean_logit 0.9568461775779724
prompt generate:  brass  	labels:  [[458]]
decoder:  [49406, 11655, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([704], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([458], device='cuda:0') tensor(7.1756e-12, device='cuda:0')
L1: [7961.3535]	L2: [31.038157]	Linf: [0.57254905]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=7.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=9.1%
Timestep  2: Avg Loss=0.000001, Std=0.000000, Contribution=13.4%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=21.9%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=48.5%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.5% (timestep 4)
Min contribution: 7.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 880 pred_label: 977 pred_clean_logit 0.02797248400747776
prompt generate:  unicycle  	labels:  [[977]]
decoder:  [49406, 7648, 38089, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([977], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([880], device='cuda:0') tensor(6.2325e-13, device='cuda:0')
L1: [5933.9414]	L2: [24.7546]	Linf: [0.7019608]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.5%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=13.5%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.7%
Timestep  4: Avg Loss=0.000007, Std=0.000002, Contribution=51.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.3% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 389 pred_label: 389 pred_clean_logit 0.9923037886619568
prompt generate:  barracouta  	labels:  [[389]]
decoder:  [49406, 40835, 35187, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([391], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([389], device='cuda:0') tensor(6.9950e-19, device='cuda:0')
L1: [9209.302]	L2: [35.03931]	Linf: [0.7882353]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.7%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.7%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=12.9%
Timestep  3: Avg Loss=0.000006, Std=0.000002, Contribution=25.8%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=53.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.0% (timestep 4)
Min contribution: 2.7% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 649 pred_label: 483 pred_clean_logit 0.08512304723262787
prompt generate:  megalith  	labels:  [[483]]
decoder:  [49406, 37650, 1757, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([500], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([649], device='cuda:0') tensor(6.7429e-14, device='cuda:0')
L1: [12202.33]	L2: [45.260365]	Linf: [0.8039216]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.2%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=10.4%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.9%
Timestep  4: Avg Loss=0.000012, Std=0.000004, Contribution=59.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 59.1% (timestep 4)
Min contribution: 2.2% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 976 pred_label: 976 pred_clean_logit 0.9963755011558533
prompt generate:  promontory  	labels:  [[976]]
decoder:  [49406, 644, 749, 4214, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([978], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([976], device='cuda:0') tensor(1.0893e-10, device='cuda:0')
L1: [5816.902]	L2: [23.137562]	Linf: [0.84313726]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=6.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=12.3%
Timestep  3: Avg Loss=0.000003, Std=0.000001, Contribution=23.2%
Timestep  4: Avg Loss=0.000006, Std=0.000002, Contribution=53.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.1% (timestep 4)
Min contribution: 4.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 362 pred_label: 362 pred_clean_logit 0.9997445940971375
prompt generate:  badger  	labels:  [[362]]
decoder:  [49406, 22363, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([383], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([362], device='cuda:0') tensor(5.4550e-20, device='cuda:0')
L1: [15581.194]	L2: [52.82901]	Linf: [0.7529412]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.4%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.8%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=13.4%
Timestep  3: Avg Loss=0.000007, Std=0.000003, Contribution=26.7%
Timestep  4: Avg Loss=0.000013, Std=0.000005, Contribution=51.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.6% (timestep 4)
Min contribution: 2.4% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 981 pred_label: 981 pred_clean_logit 0.9311038851737976
prompt generate:  ballplayer  	labels:  [[981]]
decoder:  [49406, 3807, 2477, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([977], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([981], device='cuda:0') tensor(1.4100e-11, device='cuda:0')
L1: [5803.7524]	L2: [23.639782]	Linf: [0.78039217]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=5.0%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=7.9%
Timestep  2: Avg Loss=0.000001, Std=0.000001, Contribution=14.5%
Timestep  3: Avg Loss=0.000002, Std=0.000001, Contribution=23.6%
Timestep  4: Avg Loss=0.000004, Std=0.000001, Contribution=49.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 49.0% (timestep 4)
Min contribution: 5.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 920 pred_label: 766 pred_clean_logit 0.029382331296801567
prompt generate:  traffic light  	labels:  [[766]]
decoder:  [49406, 3399, 1395, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([556], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([920], device='cuda:0') tensor(2.2035e-17, device='cuda:0')
L1: [5492.3687]	L2: [23.099787]	Linf: [0.745098]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.8%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=24.5%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=51.9%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.9% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 743 pred_label: 743 pred_clean_logit 0.981243908405304
prompt generate:  prison  	labels:  [[743]]
decoder:  [49406, 6622, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([674], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([743], device='cuda:0') tensor(3.7662e-26, device='cuda:0')
L1: [6500.5923]	L2: [23.02566]	Linf: [0.48235294]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000001, Std=0.000000, Contribution=4.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=9.4%
Timestep  3: Avg Loss=0.000004, Std=0.000001, Contribution=21.5%
Timestep  4: Avg Loss=0.000011, Std=0.000003, Contribution=62.2%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 62.2% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 0.0%
gt_label: 917 pred_label: 788 pred_clean_logit 0.0893533006310463
prompt generate:  comic book  	labels:  [[788]]
decoder:  [49406, 4962, 1116, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([837], device='cuda:0') tensor(0.9996, device='cuda:0')
after_true: tensor([917], device='cuda:0') tensor(2.5691e-30, device='cuda:0')
L1: [10134.547]	L2: [39.19813]	Linf: [0.9411765]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.3%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.4%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=13.0%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=27.6%
Timestep  4: Avg Loss=0.000015, Std=0.000005, Contribution=51.7%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 51.7% (timestep 4)
Min contribution: 2.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 962 pred_label: 962 pred_clean_logit 0.9360916018486023
prompt generate:  meat loaf  	labels:  [[962]]
decoder:  [49406, 6480, 18273, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([467], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([962], device='cuda:0') tensor(4.3798e-15, device='cuda:0')
L1: [9634.617]	L2: [34.90067]	Linf: [0.8117647]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.3%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=6.1%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=12.7%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=25.6%
Timestep  4: Avg Loss=0.000010, Std=0.000003, Contribution=52.3%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 52.3% (timestep 4)
Min contribution: 3.3% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 546 pred_label: 546 pred_clean_logit 0.99994957447052
prompt generate:  electric guitar  	labels:  [[546]]
decoder:  [49406, 5031, 5084, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 100.0%
after_pred: tensor([546], device='cuda:0') tensor(0.9996, device='cuda:0')
after_true: tensor([546], device='cuda:0') tensor(0.9996, device='cuda:0')
L1: [4221.745]	L2: [23.097265]	Linf: [0.7215686]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000000, Std=0.000000, Contribution=9.9%
Timestep  1: Avg Loss=0.000000, Std=0.000000, Contribution=11.9%
Timestep  2: Avg Loss=0.000000, Std=0.000000, Contribution=15.6%
Timestep  3: Avg Loss=0.000000, Std=0.000000, Contribution=21.6%
Timestep  4: Avg Loss=0.000001, Std=0.000000, Contribution=41.0%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 41.0% (timestep 4)
Min contribution: 9.9% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 819 pred_label: 819 pred_clean_logit 0.7729704976081848
prompt generate:  stage  	labels:  [[819]]
decoder:  [49406, 2170, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([620], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([819], device='cuda:0') tensor(3.6079e-32, device='cuda:0')
L1: [9855.32]	L2: [44.438255]	Linf: [0.9607843]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=4.1%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=7.4%
Timestep  2: Avg Loss=0.000002, Std=0.000001, Contribution=14.1%
Timestep  3: Avg Loss=0.000004, Std=0.000002, Contribution=25.9%
Timestep  4: Avg Loss=0.000007, Std=0.000003, Contribution=48.4%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 48.4% (timestep 4)
Min contribution: 4.1% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 324 pred_label: 324 pred_clean_logit 0.9673987030982971
prompt generate:  cabbage butterfly  	labels:  [[324]]
decoder:  [49406, 18407, 9738, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([986], device='cuda:0') tensor(1., device='cuda:0')
after_true: tensor([324], device='cuda:0') tensor(9.7106e-16, device='cuda:0')
L1: [6313.091]	L2: [23.374659]	Linf: [0.63529414]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=2.5%
Timestep  1: Avg Loss=0.000002, Std=0.000001, Contribution=5.5%
Timestep  2: Avg Loss=0.000004, Std=0.000002, Contribution=12.4%
Timestep  3: Avg Loss=0.000008, Std=0.000003, Contribution=26.0%
Timestep  4: Avg Loss=0.000017, Std=0.000005, Contribution=53.6%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 53.6% (timestep 4)
Min contribution: 2.5% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis

✓ Using AttentionControlEditLearnable
  Detach weights: True (prevents gradient pathology)

Accuracy on benign examples: 100.0%
gt_label: 912 pred_label: 912 pred_clean_logit 0.9374397993087769
prompt generate:  worm fence  	labels:  [[912]]
decoder:  [49406, 10945, 12679, 49407] [49406, 49407]

✓ Using learnable timestep weights
  Weight network learning rate: 1e-4
  Initial weights (self-attn): [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
Accuracy on adversarial examples: 0.0%
after_pred: tensor([765], device='cuda:0') tensor(1.0000, device='cuda:0')
after_true: tensor([912], device='cuda:0') tensor(9.9982e-17, device='cuda:0')
L1: [4718.482]	L2: [17.813414]	Linf: [0.5372549]

==================================================
PER-TIMESTEP LOSS STATISTICS
==================================================
Timestep  0: Avg Loss=0.000001, Std=0.000000, Contribution=3.0%
Timestep  1: Avg Loss=0.000001, Std=0.000001, Contribution=5.6%
Timestep  2: Avg Loss=0.000003, Std=0.000001, Contribution=11.5%
Timestep  3: Avg Loss=0.000005, Std=0.000002, Contribution=23.8%
Timestep  4: Avg Loss=0.000012, Std=0.000003, Contribution=56.1%

Total timesteps: 5
Uniform weight would be: 20.00%
Max contribution: 56.1% (timestep 4)
Min contribution: 3.0% (timestep 0)
==================================================

✓ Saved: test_learnable_detached/timestep_analysis/loss_per_timestep.png
✓ Saved: test_learnable_detached/timestep_analysis/loss_heatmap.png
✓ Saved: test_learnable_detached/timestep_analysis/average_loss_per_timestep.png

✓ Timestep analysis saved to: test_learnable_detached/timestep_analysis

============================================================
LEARNABLE TIMESTEP WEIGHTS SUMMARY
============================================================

--- Self-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0502       +0.0002
1          0.0800       0.0809       +0.0009
2          0.1300       0.1309       +0.0009
3          0.2400       0.2436       +0.0036
4          0.5000       0.4944       -0.0056

Max change at timestep 4
Total weight shift: 0.0111

--- Cross-Attention Weights ---
Timestep   Initial      Learned      Change      
----------------------------------------------
0          0.0500       0.0493       -0.0007
1          0.0800       0.0798       -0.0002
2          0.1300       0.1293       -0.0007
3          0.2400       0.2418       +0.0018
4          0.5000       0.4998       -0.0002

Max change at timestep 3
Total weight shift: 0.0036
============================================================

✓ Saved: test_learnable_detached/timestep_analysis/learned_weights_comparison.png

==================================================
LEARNED vs INITIAL WEIGHTS COMPARISON
==================================================

Self-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.05018141 0.08091635 0.13086478 0.2435936  0.4944438 ]
  Max change at timestep 4
  Total weight shift: 0.0111

Cross-Attention Weights:
  Initial:  [0.05 0.08 0.13 0.24 0.5 ]
  Learned:  [0.04931873 0.07977413 0.12928751 0.24177761 0.499842  ]
  Max change at timestep 3
  Total weight shift: 0.0036
==================================================


✓ Learned weights visualization saved to: test_learnable_detached/timestep_analysis
Clean acc: 0.0%
Adv acc: 0.0%

*********Transfer to resnet********
Accuracy on benign examples: 92.7%
Accuracy on adversarial examples: 60.099999999999994%

*********Transfer to vgg********
Accuracy on benign examples: 88.7%
Accuracy on adversarial examples: 58.3%

*********Transfer to mobile********
Accuracy on benign examples: 86.9%
Accuracy on adversarial examples: 56.2%

*********Transfer to inception********
Accuracy on benign examples: 80.5%
Accuracy on adversarial examples: 11.899999999999999%

*********Transfer to convnext********
Accuracy on benign examples: 97.0%
Accuracy on adversarial examples: 77.8%

*********Transfer to vit********
Accuracy on benign examples: 93.7%
Accuracy on adversarial examples: 74.5%

*********Transfer to swin********
Accuracy on benign examples: 95.89999999999999%
Accuracy on adversarial examples: 75.8%

*********Transfer to deit-b********
Accuracy on benign examples: 94.5%
Accuracy on adversarial examples: 75.5%

*********Transfer to deit-s********
Accuracy on benign examples: 94.0%
Accuracy on adversarial examples: 71.5%

*********Transfer to mixer-b********
Accuracy on benign examples: 82.5%
Accuracy on adversarial examples: 60.199999999999996%

*********Transfer to mixer-l********
Accuracy on benign examples: 76.5%
Accuracy on adversarial examples: 55.900000000000006%
FID:  62.096748726980536

*********fid: 62.096748726980536********
